%% LaTeX Paper Template, Flip Tanedo (flip.tanedo@ucr.edu)
%% GitHub: https://github.com/fliptanedo/paper-template-2022

% \documentclass[11pt]{article} %% Not for Lecture Notes
\documentclass[12pt, oneside]{report}    %% Has chapters

\input{FlipLectureMacros}       %% Lecture note formatting, load first
\input{FlipPreamble}			%% \usepackages, formatting
\input{FlipMacros}              %% Flip's standard macros
\input{FlipMacros_Comments}     %% Flip's macros for comments
\input{FlipMacros_Teaching}     %% Flip's macros for course notes
\input{Flip_listings}           %% Styling for code blocks
\input{FlipAdditionalHeader}    %% Modify this for each project
\input{FlipPreambleEnd}         %% packages that have to be at the end

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% LECTURE NOTES SETTINGS %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \linenumbers                  %% print line numbers (lineno package)
\graphicspath{{figures/}}       %% figure folder
\addbibresource{FlipBib.bib}    %% Define BibLaTeX source(s)
\addbibresource{FlipSUSY.bib}

%% LEAVE THESE HERE 

\geometry{                      %% large margin for side notes
    paper=letterpaper, 
    hmargin={1cm,7.25cm},       %% 6.25cm space on right
    vmargin={2cm,2cm}, 
    marginparsep=.5cm, 
    marginparwidth=5.75cm
}

%% Def. full width; uses changepage package; 6.25cm to match hmargin difference;
\newenvironment{wide}{\begin{adjustwidth}{0cm}{-6.25cm}}{\end{adjustwidth}}


% Reset the sidenote number each section 
\let\oldsection\section
\def\section{%
  \setcounter{sidenote}{1}%
  \oldsection
}


\begin{document}

\newgeometry{margin=2cm}                   % plain geometry for frontmatter
\newcommand{\FlipTR}{UCR-TR-2024-FLIP-P165} % TR#, pdfsync may fail on 1st page
\thispagestyle{firststyle} 	               % TR#; otherwise use \thispagestyle{empty}
\pagenumbering{gobble}                     % no page number on first page 

%%%%%%%%%%%%%%%%%%%%%%%%
%%%  FRONTMATTER    %%%%
%%%%%%%%%%%%%%%%%%%%%%%%


\begin{center}
    {\large \textsf{UC Riverside Physics 165, Spring 2024} \par}
    {\huge \textbf{Introduction to Particle Physics} \par}\vspace{.5em}
    {\large {Kinematics and Dynamics of the Standard Model} \par}
    \vskip .5cm
\end{center}

\input{FlipAuthors}

\vspace{2em}\noindent
An introduction to elementary particle physics: the study of the fundamental constituents of matter and the forces that dictate their interactions. We focus on building a theoretical understanding of the Standard Model of particle physics based on Feynman diagrams. 

\vspace{5em}
\begin{center}
\includegraphics[width=.3\textwidth]{figures/P5BW.pdf}  
\end{center}  


% \vspace{2em}
\vspace*{\fill}

\noindent
\textsf{Last Compiled: \today}

\noindent
\textsf{Image: \acro{P5} Logo, Sandbox Studio}


\noindent
\textsf{CC BY-NC-SA 4.0}~\ccbyncsa 

\noindent % Course notes URL
% \url{https://github.com/fliptanedo/P231-2023-Math-Methods}

%% Front page logos
% \vspace*{\fill}
\begin{center}
\includegraphics[height=.1\textwidth]{figures/FlipAmbigram.png}
\hspace{5em}
\includegraphics[height=.1\textwidth]{figures/UCRPnA_banner.png}
\end{center}

\newpage

\small
\setcounter{tocdepth}{2}
\tableofcontents
\normalsize
\clearpage
\restoregeometry        %% Return to lecture note geometry 
\pagenumbering{arabic}  %% Turn on regular page numbers


%%%%%%%%%%%%%%%%%%%%%
%%%  THE CONTENT  %%%
%%%%%%%%%%%%%%%%%%%%%

% % \chapter{Things I'm working on}

% % \url{https://github.com/fmarotta/kaobook/issues/15}
% % % Because sidecite dosn't work
% % %\sidecite{Feng:2016ijc}

% % \input{examples_lecture}

% % % \chapter{Paper examples}

% % % Here are the standard examples I use for my \texttt{paper} template. I include them here to check that nothing has broken. These do not make use of the margin at all. You can see what happens when some text spills into the margin unintentionally.

% \input{examples}
% \input{examples_teaching}
% % % \input{examples_listings}
% \input{examples_bestpractices}
% \input{examples_refs}
% \input{examples_lecture}

% % %% CHAPTER SUBAPPENDIX %% if using report class
% % \begin{subappendices}
% % \section{Subappendix}\label{sec:subappendix:eg}
% % This chapter has its own special appendix.
% % \end{subappendices}

\chapter{The Course}

\section{Our Goal}

The goal of this course is to teach the \emph{theoretical framework} of particle physics. The underlying structure of this discipline is called \textbf{quantum field theory} and is the union of special relativity and quantum mechanics. Over one-quarter course we tell the story of leptons, quarks, and various gauge bosons---but what I \emph{really} want to convey to you is how quantum field theory works. 

Ordinarily, quantum field theory is a graduate-level course that you take after taking not only upper division quantum mechanics, but graduate-level quantum mechanics, electrodynamics, statistical mechanics/field theory, with smatterings of courses that hammer home special relativity (perhaps in general relativity course) and bits of complex analysis. Even then, the course has a reputation for being challenging because it demands a level of physical sophistication to appreciate.\sidenote[][-5em]{Usually we tell our graduate students to expect to take quantum field theory a few times in order to prepare to spend the rest of their research careers continuing to chip away at the frontier of human knowledge in this field. I am reminded of the [lightly paraprhased] quote by theorist Nima Arkani-Hamed: ``You can learn quantum mechanics in a few weeks. But you need to dedicate a lifetime of research to hope to understand quantum field theory.''} 

This course is an attempt to give a working knowledge of the big picture. You will see how Feynman diagrams are both a perturbative expansion of a transition amplitude \emph{and} a useful mnemonic for the story of particle scattering. You will see how indices are a physicist's crutch to mathematically implement symmetries. Along the way, you may come to appreciate corners of quantum mechanics and relativity that otherwise may slip the usual undergrad curriculum. 

Most of call, \emph{this course is a bridge}. For those who are interested in theoretical physics of any type\sidenote{In some sense, all theoretical physicists are quantum field theorists. Yes, even condensed matter theorists.} or those interested in particle physics of any type\sidenote{Including experimental particle physics and astro-particle physics.}: I want you to leave this course knowing how one \emph{uses} quantum field theory in particle physics so that if you go to graduate school, you will already have the bird's-eye-view of how different technical ideas come together. Alternatively, for those who know that their passions are not in this discipline: I want you to appreciate what the scaffolding of quantum field theory buys us as physicists, so that when you go off to become your future self, you are an informed ambassador of physics.

\section{What we miss}

This is \emph{not} a `modern physics course---what I mean by that are courses that are glorified ``physics for poets'' courses that offer ideas without mathematical rigor. Instead, this course is \emph{all about} understanding the mathematical rigor, even though we will not derive every step (leaning instead on analogies as appropriate) and even though the purpose of the course is not to see who can calculate the most tedious cross section.

A course like this can span multiple terms and focus on many different aspects of particle physics. Given that we have \emph{one} term and that we want to start by assuming the bare minimum, we have to make deliberate cuts to what we investigate. Rather than trying to do a little bit of everything, we will dive deeply into the theory and sacrifice the following:
\begin{itemize}
    \item The experimental foundation of particle physics. This is the biggest sacrifice because physics is ultimately an \emph{empirical} science and practitioners need to be grounded in experiment.\sidenote{Even theorists.} We excise this aspect in part because I would struggle to do it justice, but also because we are in a moment where the types of experiments that particle physicists do has evolved rapidly over the last decade.\sidenote{\tacro{UCR} students are encouraged to reach out to members of our experimental particle cosmology group to learn more about this.}
    \item The history of particle physics. I did not appreciate this as a student, but good physicists understand how those who came before them had their key \emph{aha!} moments: what what puzzles where they thinking about, how did they make progress?\sidenote{This is different from a hagiography of physics heroes. Most of our physics heroes are flawed human beings and most of the heroism is rooted in a broader collective of people than our stories usually tell.}
    \item Computational tools. Particle physicists were the original `big data' scientists with a huge throughput of data in particle colliders. Experience with some of the computational tools are a great way to get into undergraduate research in this field. I regret that this is something that we cannot fit into this course, but I encourage those interested in this field to be prepared to do computational work.
\end{itemize}

\section{Prerequisites}

I have done my best to minimize the prerequisite knowledge for this course. At the bare minimum, we require the following:
\begin{enumerate}
    \item This means you have had first-year physics and did well.\sidenote{At the very least, if you took first-year physics now you would ace it.}
    \item Analytical mechanics at the level of having some familiarity with Lagrangian mechanics and variational principles.
    \item At least two quarters of quantum mechanics so that you are familiar with bras, kets, operators, superposition, and amplitudes. You should be comfortable with angular momentum and spin.
    \item Some introduction to special relativity so that you are familiar with the principles of length contraction and time dilation.
    \item Linear algebra at the level of Physics 17 at \acro{UCR}.\sidenote{The course notes for Physics 17 may be a useful reference.\footnotemark}\footnotetext{\url{https://sites.google.com/ucr.edu/physics017/}}
\end{enumerate}

In a perfect world, you would also have the following background:
\begin{itemize}
    \item A solid background in linear algebra and some familiarity with how this relates to the representation of groups. It would help if you do not cringe at the word \emph{tensor}. It would be even better if you knew what makes a tensor a tensor as opposed to a multi-dimensional array of numbers.
    \item Some familiarity with the notion of a generator of a transformation and its exponentiation, for example from a quantum mechanics course.
    \item An idea of what a Green's function is.\sidenote{The course notes for Physics 231 may be a useful reference.\footnotemark}\footnotetext{\url{https://sites.google.com/ucr.edu/p231/}} We will not use this word too often, but understanding what it means usually correlates to a mathematics and physics background that will be helpful.
    \item Some introduction to relativistic quantum mechanics; for example, knowing the Dirac and the Klein-Gordon equations.
    \item Know what a cross section is from a mechanics course or, even better, Fermi's Golden Rule from a quantum mechanics course.
\end{itemize}
We do not live in a perfect world and it is much better to take the pioneering spirit of jumping in. As one of my undergraduate mentors told me, \emph{enthusiasm makes up for a lot of things.}\sidenote{Enthusiasm can be measured by how much time do you set aside to learn the \emph{extra} stuff that you need to best appreciate this course.}

\section{What it takes to succeed in this course}

\paragraph{Do your homework} I tell the Physics 39 classes that the best advice I can give is to \emph{do your homework}.\sidenote{Whenever I do this, I think about the Mary Schmich essay and Baz Luhrmann song, ``Wear Sunscreen.'' The song plays in the back of my head every time I talk about homework.\footnotemark}\footnotetext{\url{https://en.wikipedia.org/wiki/Wear_Sunscreen}} Trust me, I get no particular joy assigning or reviewing your homework---unlike many other topics I may teach, I actually know this shit. The value of homework is \emph{practice}.\footnote{\url{https://www.youtube.com/watch?v=p-BR1mXwtB0}} This is my commitment to you to cobble together an opportunity for \emph{you} check your understanding, to learn more (and more meaningfully), and to develop your own style of \emph{doing physics}. Part of my commitment to you is to create a space---our class---where we can work together on these meaningful exercises. I encourage you to do the homework, this is where you \emph{become a physicist}.

\paragraph{Ask questions} This course can be technical, it draws on different branches of physics, and even then it is just scratching the surface of some of the biggest open questions in science. If you engage with the material deeply enough, I \emph{expect you to be confused}. I am often confused. Do everyone a favor and ask during class. If you are embarrassed, I suggest phrasing your question as follows:
\begin{quote}
Is it obvious that...?
\end{quote}
When you ask it this way, the question is no longer about you being confused, it is about what is the most insightful way to think about a topic.

\paragraph{How to answer questions} The best part of a class is the community that we build together. I may be the person in the class who is most familiar with this material, but you and your classmates are the ones who are familiar with the journey that you're on---and there is a lot that I learn from your journey. As such, expect me to \emph{ask you questions}. This can be scary, but know that when I ask a question, I am not testing \emph{you} and what you have learned, I am testing \emph{me} and what I need to teach. If you find yourself on the business end of a question during class, consider the following options:
\begin{itemize}
    \item If you know the answer, give the answer and a justification.
    \item If you are not sure but think you know the answer, give the answer and a justification. You can even say that you are not sure and give reasons to be skeptical.\sidenote{This is part of the scientific method.} This is useful for me as well.
    \item If you have no idea what the answer is, then say so and explain what is confusing about the question. If you do not understand the question, then say that you do not understand the question and then ask a specific question for clarification. 
\end{itemize}% be ready to answer questions
% be critical: why are we doing this
% do your homework \url{https://www.youtube.com/watch?v=sTJ7AzBIJoI}


\section{Significant figures}

Most of the big ideas in this course do not require precise numbers. Usually we can get by with one significant figures---the mass of the proton is 1~\GeV{}. Sometimes we can get by with \emph{zero} significant figures---the Planck scale is on the order\sidenote{The `big-O' notation $\mathcal O$ means `order of magnitude. Because our study of particle physics spans the very small to the very large, you would be wise to be comfortable with this notation.} of $\mathcal O(10^{19}\,\text{\GeV{}})$. In fact, you should start every problem by thinking about the order of magnitude before you think about any significant figures. 

The only time where we will have to get into the weeds and sort one more than one significant figure is when we need to take the difference of two numbers and it matters whether the difference is positive or negative.\sidenote{Of course, this is simply saying that we care about the difference to one significant figure.}
\begin{example}
A good example of this is the mass of the proton versus the mass of the neutron. These, in turn, are due to small differences in the mass of the up versus the down quarks. The masses are:
\begin{align}
    m_\text{p} &= 938.3~\text{MeV}
    &
    m_\text{n} &= 939.6~\text{MeV}
\end{align}
and their mass difference is on the order of a percent of the masses. If proton were heavier than the neutron---a change in the at the \emph{third} significant figure---then the universe as you know it would be radically different. How different? For starters, instead of hydrogen atoms we would have neutrons---and we can say goodbye to chemistry.\sidenotemark
\end{example}\sidenotetext[][-7.5em]{This and related observations are described beautifully in Robert Cahn's article ``The eighteen arbitrary parameters of the standard model in your everyday life,'' which I strongly recommend that everyone read. Cahn is also the author of a great book on representation theory for those learning the subject on their own\footnotemark.}
\footnotetext{\cite{Cahn:1996ag}; and \cite{cahn2006semi}}


\section{These notes}

This is a first draft of these lecture notes. You can expect both outright errors and explanations that may not be fully satisfying. Please bring up any questions to me at your soonest convenience. 

I also have a tendency towards marginalia---sidenotes and footnotes. It is a habit I pick up from my favorite textbook authors (Tony Zee in particular); I feel like it brings a bit of the flavor of the course into the text. They also reflect my occasionally scatter-brained enthusiasm for this subject. If you are in a particular hurry, you can safely skip the side notes. I have tried to include references on the page that we use them rather than in a comprehensive bibliography in the back. Students who are especially dedicated to this subject are encouraged to pursue as many of these references as they are able to. 

\section{References}
Unfortunately there is not a perfect book on particle physics at this level.\sidenote{Jeff Richman at \acro{UCSB} is working on one that may be close. At the time of this writing that book is not yet complete.} Here are a few that you may consider. 

\subsection{Particle Physics}
\begin{itemize}
    \item \cite{Griffiths:2008zz}
    \item \cite{Larkoski:2019jnv}
    \item \cite{Peskin:2019iig}
    \item \cite{Cahn:1989by}
    \item \cite{Goldberg:2017dlc}
    \item \cite{Bettini:2008zz}
\end{itemize}

\subsection{Introductions to Quantum Field Theory}
Recently there has been an explosion in the number of ``quantum field theory for undergraduates'' textbooks. Here are a few that I think are particularly effective for further study. The books all start at the level assumed for this course, but each goes much deeper into the subject and wold be well suited for anyone interested in pursuing theoretical research in graduate school.
\begin{itemize}
    \item \cite{Schwichtenberg:2018dri}
    \item \cite{schwichtenberg2020no}
    \item \cite{Lancaster:2014pza}
    \item \cite{donoghue2022prelude}
    \item \cite{Zee:2010qce}
    % \item \cite{Perkins:2003pp}
    \item \cite{Feynman:1986er}
    \item \cite{Veltman:1994wz}
\end{itemize}

\subsection{Bird's eye view of particle physics}

\begin{itemize}
    \item The ``Pathways to Innovation and Discovery in Particle Physics'' Report of the 2023 Particle Physics Project Prioritization Panel is a great reference for the present state of the discipline.\footnote{\url{https://www.usparticlephysics.org/2023-p5-report/}}\sidenote{For those pursuing graduate study in particle physics: this document outlines scientific priorities of \acro{US} particle physics funding agencies. These priorities tend to align with the topics where research groups are looking for new graduate students. You may want to read the relevant parts carefully.}
    \item Fermilab and \acro{SLAC}, two of our flagship national laboratories in particle physics, have a for-the-public online magazine, \emph{Symmetry: Dimensions of Particle Physics}. This is a great starting point to dig a bit deeper into what is going in in particle physics.\footnote{\url{https://www.symmetrymagazine.org}} You may also find a discussion of more mathematical topics in some of the articles in \emph{Quanta Magazine}\footnote{\url{https://www.quantamagazine.org/physics/}}.
    \item There are a few well-known histories of particle physics ostensibly written for the general public. These include \emph{The Rise of the Standard Model}\autocite{hoddeson1997rise} and \emph{Inward Bound}\autocite{pais1988inward}. 
    \item In many ways, this field still exists in the shadow of the Superconducting Supercollider. The definitive history of this unfortunate saga is the book \emph{Tunnel Visions}\autocite{riordan2015tunnel}. YouTube documentarian BobbyBroccoli has an excellent movie-length three-part synopsis.\footnote{\url{https://www.youtube.com/watch?v=3xSUwgg1L4g}}
    \item There have been a few celebratory conference on the Standard Model. Steven Weinberg's 2003 talk\sidenote{\arXiv{hep-ph/0401010}} is a succinct history of both the successes and false directions---it is a nice chronological scaffolding to see how some of the big ideas in particle physics came to be. There is a great video archive of talks from the \acro{SM\@50} conference at Case Western in 2018\footnote{\url{https://www.youtube.com/playlist?list=PLBELrG1nZ2U6H3I1il4NhNVNcdUVUE5Ye}} and the 50 Years of \acro{QCD} conference at \acro{UCLA} in 2023\footnote{\url{https://www.youtube.com/playlist?list=PLjqOpQgpjtKoy21wrZ9hPnYM1KN97WYJH}}.
\end{itemize}
\begin{exercise}
Perhaps it is a bit silly that the celebration of 50 years of quantum chromodynamics---a \emph{part} of the Standard Model---was a few years after the celebration of the Standard Model. As an exercise, explain the chronology of what specific events were being celebrated at each event.
\end{exercise}

\chapter{Introduction}

This is a course on the theory of the Standard Model of particle physics. It is a theory so successful that it is called the \emph{Standard Model} with capital letters. Among its crowning achievements is the discovery of the Higgs boson~\autocite{CMS:2012zhx, ATLAS:2012ae} and the verification of the electron's anomalous magnetic moment~\autocite{Fan:2022eto}---the most precisely predicted and measured number in nature.\sidenote{The error is less than a part per trillion.}

This chapter is an \emph{amouse bouche} for the course. We review some of the key themes and big ideas to prepare you for a systematic study in subsequent chapters. This chapter may dip into some jargon and hint at some of the deeper undercurrents of quantum field theory. I include them here not to discourage you, but to whet your appetite for the journey ahead.

\section{What is Particle Physics}

Particle physics has had a few different names. It used to be called \emph{subatomic physics} because it is the study of things that are smaller than the atom. But then nuclear physics split off as a discipline\sidenote{By the end of this course, you may come to appreciate why this is the case.\footnotemark}\footnotetext{Nuclear physics works with \emph{effective theory} of hadrons at the \GeV{} scale. This theory is distinct from the Standard Model because it is precisely the regime where the theory of quarks is non-perturbative and alternative descriptions are necessary.} and what does it mean for a particle to be `smaller' anyway?

\begin{exercise}
If someone who is not a physicist asked you what the size of the electron is, what would you say? Go ahead and look up the radius of an electron. What does this number mean? What about a photon? What is the `size' of a quantum of light?\sidenotemark
\end{exercise}\sidenotetext[][-3em]{Confused? Good. You're thinking.}

Another historical name for particle physics is \emph{high-energy physics}. This is because our experimental apparatuses are traditionally colliders where we smash together particles at high energies. 
\begin{exercise}
What does it mean for a particle to have a ``high energy''? What is this energy being compared to? The kinetic energy of a mosquito flapping its wings is negligible for most human-scale activities, but it is quite substantial when smashing together two electrons.
\end{exercise}
This is because high energy colliders are actually microscopes. Go ahead and review Rutherford scattering in your favorite quantum mechanics book. Rutherford scattering is the famous experiment that lead to the discovery of nuclei by shining an electron beam onto a gold foil target. 
\begin{exercise}
How is the energy of the electron beam related to the spatial resolution of the experiment?
\end{exercise}
In this way, one may be forgiven for conflating particle physics with \emph{collider} physics. Indeed, particle physics is still a field that looks to the Large Hadron Collider as one of its Meccas. However, unlike the case even twenty years ago, modern particle physics is far more diverse than `just' high-energy [collider] physics.\sidenote[][-5em]{Theorist Hitoshi Murayama once said that this field stretches ``\emph{from the smallest scales to the largest, from the heavens to the hell}.'' By this he was referring to the most fundamental particles, the cosmological evolution of the entire universe, space-based telescopes, and underground detectors.} As of the time of this writing, a pretty good summary of the field is the 2023 Particle Physics Project Prioritization Panel (\acro{P5}) report.\footnote{\url{https://www.usparticlephysics.org/2023-p5-report/}} The report is the guiding document for the Department of Energy and National Science Foundation---the primary funding agencies for particle physics in the \acro{US}---for the key questions that particle physics seeks to answer over the coming decade.

So I am calling this field \textbf{particle physics}. Even this name is debatable: while the objects that we \emph{observe} are \emph{particles}---usually energy and momentum eigenstates, perhaps described by some sort of creation operator $a^\dag$---the underlying mathematical objects in our theory are \emph{quantum fields}. Even then, some phenomena in particle physics seem to probe the decidedly `wavey' limit of a quantum field.\footnote{See, for example, wave dark matter, \arXiv{2101.11735}.} You could call this ``applied quantum field theory,'' but applications of quantum field theory are much broader than particle physics. So for our purposes, let's call it particle physics and not get too hung up on minutiae.

So what is particle physics? \begin{quote}In this course, particle physics is the branch of science that seeks to build a model quantum field theory that describes the elementary constituents of nature and their fundamental interactions.\end{quote} We should parse a few key words here:
\begin{itemize}
    \item Quantum field theory is a theory-of-theories. The Standard Model of particle physics is \emph{a} quantum field theory in the same way that the hydrogen atom is a model quantum mechanical system. 
    \item We are building \emph{models}. A model is a mathematical description of an actual system. The mathematical description is usually idealized and hence simplified. The model is a way to learn about how underlying principles (usually symmetries) can lead to particular phenomena. See Fig.~\ref{fig:MilleniumFalcon}.
    \item We talk about the \emph{elementary constituents} of nature. In our model, these are quantum fields. Excitations of these fields are what we call elementary particles. The name is meant to evoke some sense of indivisibility, but this is not at all necessarily the case.\sidenote[][-3em]{I once read a story about a woman on a plane who was bragging about how brilliant her son is. When she saw her seatmate reading a book, \emph{Elementary Particle Physics}, she said ``hmph! Well, my son studies \emph{advanced} particle physics.''} For example, it can be convenient to write models where protons and neutrons are elementary, even though we know that they are not. 
    \item Finally, the \emph{fundamental interactions} between particles is conventionally what are called forces. We shall see in this class in particle physics, there is no strict distinction between particle and force---they are all described by quantum fields whose excitations are particles.\sidenote{In particle physics, everything is a particle. In contrast, to astronomers, subatomic scientists are either particle physicists or a metallurgists.\footnotemark}\footnotetext{\url{https://en.wikipedia.org/wiki/Metallicity}} 
\end{itemize}
\begin{figure}%[th]
    % \centering
    \sidecaption[][-2\baselineskip]{%
        What is the difference between these two? One is a screenshot of the Millennium Falcon from \emph{Wookiepedia}, the other is a picture of a \emph{model} of the Millenium Falcon from Lego. Physicists build models of nature. We hope that the model may illuminate principles of how nature works, but we do not confuse the model as a prescription for how nature must behave.
        \label{fig:MilleniumFalcon}
    }
    \includegraphics[width=\textwidth]{figures/MillenniumFalcon.png}
\end{figure}
These ingredients come together through a tool called a Feynman diagram.

\section{Diagrammar}

Fig.~\ref{fig:ee:gamma:gamma:example} is an example of a Feynman diagram.
\begin{marginfigure}%[th]
    \includegraphics[width=.8\textwidth]{figures/feyn_eegaga.pdf}
    \captionsetup{font={scriptsize,sf}}
    \caption{Example of a Feynman diagram. Here an electron and a positron annihilate into a pair of photons.}
    \label{fig:ee:gamma:gamma:example}
\end{marginfigure}
Feynman diagrams are a perturbative expansion of the quantum mechanical amplitude for a something to happen. You may recall that the quantum amplitude is a ``square root of the probability\footnote{This notion comes from quantum mechanics where the probability of observing a state $\ket{\Psi}$ is $\langle \Psi | \Psi\rangle = |\Psi|^2$. In quantum field theory we typically talk about \emph{cross sections}, $\sigma$. The relation between the amplitude $\mathcal M$ and cross section is $\sigma \sim |\mathcal M|^2$ and contains kinematic factors. We determine these kinematic factors in subsequent chapters.}.'' The statement that diagrams are a \emph{perturbative expansion} means that there is some small parameter for which we are performing a Taylor expansion\sidenote{Formally the amplitudes are complex and may contain singularities. It is thus more appropriate to say that this is a \emph{Laurent expansion}. One of the `deep' ideas in quantum field theory is the intimate relationship of \emph{analyticity} (complex differentiability) to physical properties. To dig deeper, see my Physics 231 notes.\footnotemark}\footnotetext{\url{https://sites.google.com/ucr.edu/p231/}}. In the standard case, this perturbative expansion is usually an expansion in couplings.

By \textbf{coupling} I mean a parameter of the theory that determines how much some particles interact with each other. When the coupling is large, the interaction is very strong. When the coupling is small, the interaction is very weak. One coupling that you may be familiar with is the electrodynamic coupling, $e$. You are probably most familiar seeing $e$ as an ingredient in the fine structure constant, 
\begin{align}
    \alpha = \frac{1}{\hbar c \varepsilon_0} \frac{e^2}{4\pi} \approx \frac{1}{137} \ .
\end{align}
The first factor of $(\hbar c \varepsilon_0)^{-1}$ are relics of using silly units. When we use natural units---see Sec.~\ref{sec:units:dimensions}---these are set to one. You can see that $1/137$ is a small number, so it at least makes sense that if we had some amplitude $\mathcal M(\alpha)$ that is a function of the electrodynamic couplings through $\alpha$ that we could imagine doing the perturbative expansion
\begin{align}
    \mathcal M = \mathcal M_0 + \alpha \mathcal M_1  + \alpha^2 \mathcal M_2 + \cdots \ ,
    \label{eq:amplitude:perturbative:expansion}
\end{align}
and then dropping any subleading terms since we expect them to be percent-level corrections. If the couplings are large, then this expansion breaks down because subsequent terms are not small. In fact, this is what happens with the strong interactions (quantum chromodynamics), the force that holds nuclei together. Thus there are regimes where the usual Feynman expansion fails: it seems like we should not use these diagrams to describe the interactions of the quarks and gluons that are `inside' a proton.
\begin{example}
I seem to have implied that Feynman diagrams do not work for the strong interaction. Despite this, collider physicists working on the Large Hadron Collider `speak' the language of Feynman diagrams. They'll even draw diagrams that involve the strong force. What gives? Apparently I haven't told you the whole story...
\end{example}
Note that I wrote \emph{couplings} not the common phrase \emph{coupling constants}. That is because---brace yourselves---these couplings are generally \emph{not} constant. In fact, they depend on the energy scale at which you probe them. If I smash together color-charged particles\sidenote[][]{In this class and in this field, we write \emph{colored} to mean color-charged, or charged with respect to the strong force. See Chapter~5 of \emph{The Disordered Cosmos} for an anthropological discussion.\footnotemark}\footnotetext{\cite{prescod2021disordered}} at high energies, the analogous fine structure parameter for the strong force, $\alpha_\textnormal{s} = g_\textnormal{s}^2/4\pi$ depends on the characteristic energy scale\footnote{We write $\sqrt{Q^2}$ rather than $E$ because $Q^2$ is a Lorentz-invariant quantity, as we explain below in our review of special relativity.} $\sqrt{Q^2}$ at which one probes the interaction, see Fig.~\ref{fig:aS:running:from:1604.08082}. 
\begin{marginfigure}%[th]
    \includegraphics[width=.8\textwidth]{figures/aSrun_1604.08082.png}
    \captionsetup{font={scriptsize,sf}}
    \caption{Approximate value of the strong force fine structure parameter, $\alpha_\textnormal{s}$. Lines correspond to slightly different calculations. The horizontal axis is the square of the characteristic energy scale at which $\alpha_\textnormal{s}$ is being measured. From Fig.~3.2 of \arXiv{1604.08082}.}
    \label{fig:aS:running:from:1604.08082}
\end{marginfigure}
This idea should be shocking the first time that you see it. The `coupling constants' are not constant at all. The meaning of this oddity is an idea called \emph{renormalization} and is rooted in making sense of what the \emph{actual} small parameter is in perturbation theory: it turns out not to be the fine structure constant, but the fine structure constant times a function of the kinematics of a process. This means that at sufficiently high energies, we can meaningfully talk about Feynman diagrams of quarks exchanging gluons. However, at low energies, these diagrams lose their meaning. If you were paying attention in the previous sub-section, this is the regime where particle physics becomes nuclear physics.
\begin{example}
This reminds me of the difference between a \emph{physicist} and a \emph{physics fan}. A physics fan is someone who thinks that $1/137$ is a fundamental constant of the universe and so should be tattooed on their body. A physicist stops to think: \emph{Where does this number come from?} and proceeds to learn about the scale-dependence of the electric coupling. In fact, in this course you will find that the electric coupling is not even a fundamental parameter but a combination of more fundamental parameters. I do not care whether or not you are a physics fan, but my goal is to train you as a physicist.
\end{example}

\begin{exercise}
On the subject of couplings: is the gravitational coupling \emph{large} or \emph{small} relative to the electromagnetic coupling? You may recall from popular physics that one of these is [surprisingly?] much stronger than the other. Try to make this quantitative by comparing two numbers. \textsc{Hint}: this is a bit of a trick question. Try writing out the gravitational fine structure constant and argue why it appears that you cannot meaningfully compare it to the electromagnetic coupling.
\end{exercise}

Feynman diagrams are graphs that represent a mathematical expression for a complex number. The graphs are trajectories in spacetime that we read from left to right. Each line in a diagram represents a particle. The lines may have decorations or labels that indicate their identity. In Fig.~\ref{fig:ee:gamma:gamma:example} the two lines on the left are an electron and a positron. The two wiggly lines on the right are each photons. Each vertex (intersection of lines) represents a factor of the coupling. In Fig.~\ref{fig:ee:gamma:gamma:example} the two vertices mean that this diagram contains two powers of the electric coupling, $e$. Thus this diagram contributes to the $\mathcal O(e^2) = \mathcal O(\alpha)$ term in the expansion of the amplitude $\mathcal M(e^+e^-\to \gamma\gamma)$ in \eqref{eq:amplitude:perturbative:expansion}. The notation $\mathcal M(e^+e^-\to \gamma\gamma)$ simply means the amplitude for an electron $e^-$ and a positron $e^+$ to turn into two photons, $\gamma\gamma$.

Something else that may be familiar from quantum mechanics: amplitudes sum together. This is the origin of quantum interference and all of the fun parts of quantum physics. Our perturbative expansion \eqref{eq:amplitude:perturbative:expansion} is one example of such a sum. However there are usually multiple diagrams that contribute at a given order in perturbation theory. One of the brilliant things about these diagrams is that they have a complementary interpretation: as a \emph{sum over histories}. This is an idea that we emphasize in our review of quantum mechanics, but the idea is this: 
\begin{quote}
The amplitude to go from some initial state to some final state is represented by the sum of all Feynman diagrams that connect the initial state to the final state. Each individual Feynman diagram in the sum represents a possible history that the initial state could have taken to reach the final state.
\end{quote}
This sum over histories interpretation is outrageous the first time you see it but is ultimately an extension of the principle of least time that underlies Snell's law in optics. The generalization to a principle of least action is the core of Lagrangian mechanics and was in fact Feynman's Ph.D thesis\autocite{feynman2005feynman}. 

The diagrams are simply a tool. Feynman's long time physics rival and co-Nobel prize winner, Julian Schwinger, was a master of calculating amplitudes in quantum field theory \emph{without} any diagrams. In one interpretation of history, Feynman's main contribution at this stage of physics history was bringing that calculational technology to the masses by giving each term an intuitive meaning.\sidenote{It is no surprise that he is also (mis-)attributed as the spokesperson of the ``shut up and calculate'' school of quantum physics.\footnotemark}\footnotetext{\cite{10.1063/1.1768652}} Veltman has a nice physics-oriented history of the spread of Feynman diagrams in his book \emph{Diagrammatica}\autocite{Veltman:1994wz}. This book should not be confused with a set of lecture notes he co-wrote with 
't~Hooft called ``Diagrammar\autocite{tHooft:1973wag},'' which inspired the name of this section.
% Not for this class, but also interesting: https://arxiv.org/abs/2109.06889
% Diagrammar of physical and fake particles and spectral optical theorem
%  Anselmi


As a final note: there is far more to quantum field theory than Feynman diagrams. As a perturbative expansion, Feynman diagrams represent the \emph{easiest} part of quantum field theory. But just as there are functions that cannot be meaningfully Taylor expanded\sidenote{Try expanding $\exp(-x^{-2})$ around the point $x_0 = 0$. Every term at every order vanishes, even though the function is well defined and non-zero away from the origin. The quantum field theory analog is something called an instanton and is beyond the scope of this course.}, there are vast swaths of field theory that are intrinsically \emph{non-perturbative}. Quantum chromodynamics at low energies---where we must turn to methods in nuclear physics---is one example. We make this caveat to emphasize that although we lean heavily on the diagrammatic interpretation of particle physics, we are still just scratching the surface.



% HW: muon shot. 
% Idea: every homework is a story



\section{Kinematics and Dynamics}

I may be the only person who makes a big deal about this, but we can separate our study of particle physics into two parallel tracks: {kinematics} and {dynamics}. You probably know that these words ``have to do with physics,'' but the distinction between them is rarely delineated. In fact, I suspect I may be making it up---in which case, here are the working definitions for this class. 

\textbf{Kinematics}\index{kinematics} has to do with the motion of particles through space and time. The kinematics of a scattering process relates to the momentum and energy of those particles. The conservation of energy and momentum are also kinematical facts\sidenote{Though their derivation through Noether's theorem is arguably a statement about dynamics.}. The thread of physics that is most relevant to this study is \emph{relativity}, and in particular the flat-spacetime version known as \emph{special relativity}.\sidenote{In contrast, general relativity is the study non-flat spacetimes. One can argue that it is the \emph{dynamics} of spacetime itself.}

\textbf{Dynamics}\index{dynamics}, on the other hand, has to do with the rules for how particles interact. When we talk about a theory or a model of particle physics, we usually mean a description of the dynamics. These are encoded in the action or Lagrangian of a theory. The dynamics of a theory draws primarily from the rules of \emph{quantum mechanics}.

Feynman diagrams are an output of the dynamics of a theory. However, a Feynman diagram is only physically meaningful if it obeys the rules of the kinematics of a theory. Kinematics are an additional consideration when we convert the squared amplitude into something physically measurable.
\begin{example}
You can draw a Feynman diagram for a process like $\gamma \to e^+e^-$ by which a photon decays into an electron--positron pair. You could even calculate the amplitude for this process to happen. However, this process is kinematically forbidden because it cannot simultaneously conserve energy and momentum. The amplitude is nonzero, but the decay rate is forced to be zero by kinematics.
\end{example}
\begin{exercise}
Show that both energy and momentum cannot be conserved in $\gamma \to e^+e^-$. There are many ways to do this, including some that are more slick than others. If you are stuck, come back to this exercise after our review of special relativity.
\end{exercise}

In this course, you can think of dynamics as the set of rules\sidenote{Called \emph{Feynman rules}.} that tell us how we may construct Feynman diagrams. These rules are an encoding of the Lagrangian of the theory.  You can think of kinematics as conditions on the energies and momenta of the initial and final states of an amplitude---these are the external lines of a diagram. Notably, kinematic constraints do not apply to the particles on the \emph{inside} of a Feynman diagram. Lines that obey the kinematic constraints are called \textbf{on shell}, while those that do not are called \textbf{off shell}.\sidenote{What is the \emph{shell}? It is the hypersurface the four-dimensional space of energy and momentum that satisfies the Einstein relation, $E^2 = m^2c^4 + p^2 c^2$ for a particle of mass $m$, energy $E$, and three-momentum $p$.} With this jargon, we say that external lines on a Feynman diagram represent parts of the initial or final states of a process and must be on shell. Internal lines are, in general, off shell.

\subsection{Symmetry}

The notion of \emph{symmetry} plays a central role for both the kinematics and the dynamics. The mathematical description of symmetry is called group theory and the way in which symmetries act on objects is called representation theory.\sidenote{I am name-dropping subjects because I am often asked what subjects should an aspiring theoretical physicist master.} The tables of Clebsch--Gordan coefficients that you may have invoked in your study of addition of angular momentum in quantum mechanics is an output of the representation theory of the group of three-dimensional rotations. In this course we are specifically interested in the representation theory of continuous groups---symmetries like rotations where you can transform by an arbitrary amount---called \emph{Lie groups}.\sidenote{Pronounced `lee.'} As humble physicists\sidenote{Oppenheimer: Well, if that’s how you treat a lieutenant colonel than I hate to see how you treat a humble physicist.\\Leslie Groves: If I ever meet one I'll let you know. (From \emph{Oppenheimer}, 2023)} the way we work with symmetries is to introduce indices. Objects that carry these indices are called \textbf{tensors}.

In special relativity (kinematics) the simplest tensors are four-vectors. They are called four-vectors because they are vectors that have four components. For example, the four-momentum of a particle may be written $p^\mu$. The index is $\mu$. There is a related object called $p_\mu$ with a lower index. These are related by a tensor called the metric tensor, which for our purposes we write $\eta_{\mu\nu}$. The metric gives us a way to define an inner product. This should all sound familiar from linear algebra because this \emph{is} linear algebra. In representation theory, the objects that get rotated\sidenote{By `rotate' I mean a general symmetry transformation. For the case of special relativity, one can have boosts in addition to rotations.} are vectors in a vector space. If you ever wonder why I teach Physics 17 the way that I do, it is because I want students to be primed to understand representation theory as it appears in physics.

Maybe the phrase `inner product' caught your ear. This is the same idea that comes up in quantum mechanics. In fact, now you may recall that quantum mechanics really boils down to complex linear algebra. In fact, many ideas in quantum mechanics are ultimately group theoretical. For example, the commutator is the natural multiplication operation between elements of a group.\sidenote{Check that while this may be surprising, it is sensible. The commutator of two operators is another operator in the same way that the multiplication of two things of a given type should be another thing of the same type.} Furthermore, finite transformations are the exponentiation of infinitesimal transformations. For example, the Hamiltonian $\hat H$ is the generator of translations in time. A finite translation in time is
\begin{align}
    \hat U(t) = e^{-i \hbar t\hat H} \ .
    \label{eq:Ut:time:H}
\end{align}
\flip{check the $\hbar$}
In particle physics we will meet several \textbf{internal symmetries} that mathematically describe the rotation of an object in different vector spaces. These do \emph{not} correspond to spacetime rotations or boosts. Instead, they may represent a rotation between quarks of different color charges.\sidenote{We define these carefully below where we discuss quantum chromodynamics. For this introduction just humor me and go with the flow to appreciate the big idea.} The infinitesimal generators of these transformations take the form\footnote{I am using `physicist' shorthand here and referring to a tensor by its components. Supercilious mathematicians sneer at us for this. Formally, $A\aij{i}{j}$ is not a matrix, it is the $i$--$j$ \emph{component} of a matrix A. Physicists justify our sloppiness because anyone who is paying attention should understand what we mean and, more importantly, by keeping the indices explicit we can see how the tensor transforms.}
\begin{align}
(T^A)\aij{i}{j}\ ,    
\end{align}
where we recognize three indices. The index $A$ is called an adjoint index and tells you which direction you are rotating. For the rotation group, $A$ takes values from 1 to 3 corresponding to rotations about the $x$, $y$, and $z$ axes. All other rotations are combinations of these. The other two indices, $i$ and $j$ depend on the \emph{representation} of the object that we are rotating. 
\begin{example}
In quantum chromodynamics we there are eight generators of so-called color symmetry. This means $A$ takes values from 1 through 8. This group is called \acro{SU(3)}, which stands for the set of $3\times 3$ special unitary matrices.\sidenotemark A quark has indices that I conventionally write with lowercase letters from the middle of the Roman alphabet that take values $m$ from 1 to 3 corresponding to red, blue, and green. The matrix $(T^4)\aij{m}{n}$ represents a particular rotation around the $A=4$ axis. A finite transformation by angle $\theta$ takes the form 
\begin{align}
    q^m \to \sum_n e^{i \theta (T^4)\aij{m}{n} } q^n \equiv \sum_n U(\theta)\aij{m}{n}q^n \ ,
\end{align}
where the sum over $n$ is what we expect from matrix multiplication.
\end{example}\sidenotetext[][]{Special means unit determinant. Unitary, as you may recall from quantum mechanics, means that the hermitian conjugate is its inverse.}

This is all to say that indices feature front-and-center in this course. They are a crutch for us to talk about the underlying symmetries that govern both the kinematics and dynamics of particle physics. We will spend a good chunk of this course building familiarity with how to interpret and manipulate indices. This is a mathematical skill that is far more general than particle physics itself.





\section{Natural Units}
\label{sec:units:dimensions}

By this stage of your physics career you are an expert at converting units. The trick is to multiply be one in different forms. Suppose you have some unit $x$ that is related to unit $y$ by some prefactor,
\begin{align}
    x = a y \ . \label{eq:unit:conversion}
\end{align}
Then you can derive that
\begin{align}
    1 = \frac{ay}{x} = {x}{ay} \ .
    \label{eq:multiply:by:one:unit:conversion}
\end{align}
Then if some quantity is, say, $3.4\,x$, you know that you can write it out in terms of $y$ simply by multiplying by one, cleverly written:
\begin{align}
    3.4\,x = 3.4\times 1 \times x = 3.1 \times \frac{ay}{\cancel{x}} \times \cancel{x}
    = (3.4a)\, y \ .
\end{align}
\eqref{eq:multiply:by:one:unit:conversion} tells us that there is a universal, unambiguous constant ratio that relates unit $x$ to unit $y$. 


\begin{example}
Suppose someone tells you the number of feet in a mile,
\begin{align}
    1~\text{mile} = 5280~\text{feet} \ .
\end{align}
This number just so happens to be the mass of the $B$ meson in \acro{MeV}.
You can derive that
\begin{align}
    1 = 5280~\frac{\text{feet}}{\text{mile}}
    = \frac{1}{5280}~\frac{\text{mile}}{\text{feet}} \ .
\end{align}
From this you can deduce that a distance of $1.5$ miles is
\begin{align}
    1.5\,\text{mile} = 
    1.5\,\cancel{\text{mile}} \times \left(5280~\frac{\text{feet}}{\cancel{\text{mile}}}\right) = 
    7920~\text{feet} 
    \approx 8000~\text{feet} 
    \ .
\end{align}
\end{example}

If this all looks completely simple then \emph{good}, it is supposed to. There is nothing deep or mysterious about changing units. Let us really put it to work. \textbf{Natural units}\index{natural units} are a convenient choice that boils down to the following identifications:
\begin{align}
    c &=1  &
    \hbar &= 1
    \ .
\end{align}
That's right. The speed of light $c$ and reduced Planck's constant $\hbar$ are set to one. This may bother you. After all, you know from past coursework that these are \emph{not} dimensionless quantities:
\begin{align}
    c &= 3\times 10^{8}\,\frac{\textnormal{m}}{\textnormal{s}}
    &
    \hbar &= 1\times 10^{-34}\,\frac{\textnormal{m}^2 \textnormal{kg}}{\textnormal{s}} \ .
    \label{eq:c:hbar:SI}
\end{align}
Setting $c = 1$ would then mean that there is an unambiguous way conversion between length and time, as if these were measuring the ``same thing.'' But length is measured by rulers and time is measured by clocks: how are these the same? They are the same \emph{precisely} because nature\sidenote{All our observations since the Michelson--Morley experiment are consistent with a constant speed of light and this is built into our theory of special relativity. Theoretically this is an aesthetic unification of space and time that laid the foundation of general relativity, which in turn has passed every experimental prediction.} gives us a universal, unambiguous constant ratio that relates units of length into units of time. This constant is the speed of light.
\begin{example}
A lightyear is a unit of distance. It is defined to be the distance traversed by a particle traveling at the speed of light,
\begin{align}
    \text{lightyear} = c\, \text{year} \ ,
\end{align}
where we see that the speed of light in natural units $c=1$ plays the role of a conversion factor in \eqref{eq:unit:conversion}. 
\end{example}
% Naive dimensional analysis
% \autocite{Manohar:1983md,Georgi:1986kr,Georgi:1992dw}
Identifying the speed of light as a conversion factor ends up relating another set of dimensionful quantities. All velocities in natural units are dimensionless. This is because we can simply write any velocity in units of the speed of light.
\begin{example}
The tangential speed of the Earth around the solar system is around $v = 200$\,km/s. In natural units this is a dimensionless number:
\begin{align}
v = 200\,\frac{ \textnormal{km} }{ \textnormal{s} }
=
2\times 10^{5} \, \frac{\textnormal{m}}{\textnormal{s}} 
\times 
\left(\frac{1}{3\times 10^8}\frac{\textnormal{s}}{\textnormal{m}}\right)
= 7 \times 10^{-3} \ .
\end{align}
In natural units, any sensible velocity has magnitude less than one. Otherwise something is traveling faster than the speed of light. 
\end{example}
\begin{exercise}
What goes wrong in physics if a particle can travel faster than the speed of light? \textsc{Hint}: review the relativity of simultaneity. 
\end{exercise}
Velocities are dimensionless in natural units. 
Recall that energy has the units of mass times velocity squared. You may recall this from from 
\begin{align}
    E_\textnormal{kinetic} = \frac{1}{2} mv^2 \ .
\end{align}
You may argue that this formula is only true for kinetic energy. That is true, energy---no matter what the form---is carries the same type of dimension. Because velocities are dimensionless, then the dimensions of energy and the dimensions of mass must be the same. In other words, mass and energy are ``the same thing.'' Given a particle of some mass---say the mass of a proton, $m_\textnormal{p}$---there is an associated energy that is $m_\textnormal{p} \times 1  = m_\textnormal{p} c^2$. This looks remarkably like the non-relativistic limit of the Einstein relation,
\begin{align}
    E = mc^2 \ .
\end{align}
Indeed, in that limit, the Einstein relation just tells us that mass and energy are the same thing. The square of the speed of light plays the role of a conversion factor between them. It is conventional for particle physicists using natural units to measure everything in units of energy. A particularly useful energy scale is 
\begin{align}
    m_\textnormal{p} = 1\,\text{\GeV{}} \ .
\end{align}
To one significant figure, the mass of the proton happens to be about one billion times an electron volt.  
\begin{exercise}
How much do you weigh in \GeV{}? 
\end{exercise}
Sometimes we lapse into other powers of electron volt. Some useful values are the mass of the electron and the mass of the Higgs boson\sidenote{We write $m_h$ to three significant figures because the Higgs is a big deal.}, and the center-of-mass energy of proton-proton collisions at the Large Hadron Collider:
\begin{align}
    m_e &= 0.5\,\text{MeV}
    &
    m_h &= 125\,\text{GeV}
    &
    E_\text{cm} &= 14\,\text{TeV} \ .
\end{align}



What about $\hbar = 1$? Planck's constant carries units of angular momentum\sidenote{These are also the units of action, $S=\int dt\,L$.}, or energy times time. Using the just-established equivalence of mass and energy in natural units, this tells us that
\begin{align}
    \hbar &= 7 \times 10^{-22}\,\textnormal{MeV}\,\textnormal{s}  \equiv 1 \ . 
\end{align}
% \begin{align}
%     \hbar = 10^{-34}\,\frac{\textnormal{m}^2 \textnormal{kg}}{\textnormal{s}}
%     \times 
%     \left(3\times 10^{8}\,\frac{\textnormal{m}}{\textnormal{s}}\right)^{-2}
%     = 
%     10^{-51}\,\textnormal{kg}\,\textnormal{s} \ .
% \end{align}
This means that the fundamental unit of ``quantum-ness'' tells us that time and inverse energy are ``the same thing.'' At this point, you can multiply and divide by $c$ and $\hbar$ as needed to write all dimensionful parameters in units of \GeV{} to some power. 
\begin{example}
An additional conversion is to set the Boltzmann factor, $k_\textnormal{B} =1$. This is the observation that thermal energy is energy and can be measured in \GeV{}.
\end{example}
We provide a useful table for conversions to one significant figure.
\begin{table}[ht]
    \renewcommand{\arraystretch}{1.3} % spacing between rows
    \centering
    \sidecaption[Useful conversions to natural units. Adapted from Palash Pal's website.][-2\baselineskip]{%
        Conversion of units using $\hbar = c = k_\textnormal{B} = 1$. The row heading is equal to the table entry times the column heading so that a \GeV{} is a small number of Planck masses, $M_\textnormal{Pl}$.  Adapted from Palash Pal's website.\footnotemark 
  %       \label{table:app:natural:unit:conversion}
    }
    \begin{tabular}{ @{} lllllll @{} } \toprule % @{} removes space
        & \GeV{} & g & K & cm$^{-1}$ & sec$^{-1}$ & M$_\textnormal{Pl}$
        \\ \midrule
        \GeV{} % col
        & % GeV
        & 1$\times 10^{-24}$ % g
        & 1$\times 10^{13}$% K
        & 5$\times 10^{13}$% cm-1
        & 2$\times 10^{24}$% s-1
        & 8$\times 10^{-20}$% Mpl
        \\
        g % col
        & 6$\times 10^{23}$% GeV
        & %$\times 10^{}$% g
        & 7$\times 10^{36}$% K
        & 3$\times 10^{37}$% cm-1
        & 9$\times 10^{47}$% s-1
        & 5$\times 10^{4}$% Mpl
        \\
        K% col
        & 9$\times 10^{-14}$% GeV
        & 2$\times 10^{-37}$% g
        & %$\times 10^{}$% K
        & 4%$\times 10^{}$% cm-1
        & 1$\times 10^{11}$% s-1
        & 7$\times 10^{-33}$% Mpl
        \\
        cm$^{-1}$ % col
        & 2$\times 10^{-14}$% GeV
        & 4$\times 10^{-38}$% g
        & 2$\times 10^{-1}$% K
        & %$\times 10^{}$% cm-1
        & 3$\times 10^{10}$% s-1
        & 2$\times 10^{-33}$% Mpl
        \\
        sec$^{-1}$ % col
        & 7$\times 10^{-25}$% GeV
        & 1$\times 10^{-48}$% g
        & 8$\times 10^{-12}$% K
        & 3$\times 10^{-11}$% cm-1
        & %\times 10^{}$% s-1
        & 5$\times 10^{-44}$% Mpl
        \\
        M$_\textnormal{Pl}$% col
        & 1$\times 10^{19}$% GeV
        & 2$\times 10^{-5}$% g
        & 1$\times 10^{32}$% K
        & 6$\times 10^{32}$% cm-1
        & 2$\times 10^{43}$% s-1
        & %$\times 10^{}$% Mpl
        \\ \bottomrule
    \end{tabular}
  %   \caption[Useful conversions to natural units. Adapted from Palash Pal's website.]
  %   {
  %       Conversion of units using $\hbar = c = k_\textnormal{B} = 1$. The row heading is equal to the table entry times the column heading so that a \GeV{} is a small number of Planck masses, $M_\textnormal{Pl}$.  Adapted from Palash Pal's website.\footnotemark 
        \label{table:app:natural:unit:conversion}
  % }
\end{table}\footnotetext{\url{https://www.saha.ac.in/theory/palashbaran.pal/conv.html}}

\begin{example}[Mnemonics]
You can use your favorite equations in physics as mnemonics for natural units. We already saw how $E=mc^2$ reminds us that energy and mass both carry the same units. You can also invoke Heiseinberg's uncertainty relations
\begin{align}
    \Delta x\,\Delta p &\sim \hbar 
    &
    \Delta E \Delta t &\sim \hbar
\end{align}
to remind us that momentum and distance carry reciprocal units, as do energy and time. Because $c=1$ tells us that distance and time are the same, we find
\begin{align}
    \text{length} \sim \text{time} \sim \frac{1}{\text{mass}} 
    \sim \frac{1}{\text{energy}} \ .
\end{align}
\end{example}

The great thing about natural units is that we just have to keep track of one unit, say \GeV{}. Dimensional analysis is very simple and we introduce the bracket notation:
\begin{align}
    [x] \defeq ``\text{dimensions of }x \ .''
\end{align}
$[x]$ means: what power of energy is the unit of quantity $x$?
\begin{example}
For a distance $\ell$, time $t$, mass $m$, and energy $E$:
\begin{align}
    [\ell] &= -1
    &
    [t] &= -1
    &
    [m] &= 1
    &
    [E] &= 1
    \ .
\end{align}
\end{example}
\begin{exercise}
What are the dimensions of the gravitational constant, $[G_\textnormal{N}]$? \textsc{Hint}: you can use the force law for gravity to figure out the \acro{SI} units of $G_\textnormal{N}$.
\end{exercise}

\begin{exercise}
Show that the units of action are the same as the units of angular momentum. \textsc{Hint}: use the expression for the action with your favorite choice of Lagrangian.
\end{exercise}

\begin{example}[Collider physics as microscopy]
The Large Hadron Collider is a microscope. The center of mass energy of the proton--proton collisions is $E = 10~\textnormal{TeV}$. To convert this into a length scale, we divide by \ .
\begin{align}
    \hbar c = 10^{21}\frac{1}{\textnormal{MeV}\,\textnormal{s}} \times 10^{-8} \frac{\textnormal{s}}{\textnormal{m}}
\end{align}
This gives us
\begin{align}
    E &= 10^7~\textnormal{MeV} \times 10^{21}\frac{1}{\textnormal{MeV}\,\textnormal{s}} \times 10^{-8} \frac{\textnormal{s}}{\textnormal{m}}
    \\
    &= \frac{1}{10^{-20}\,\textnormal{m}} \ .
\end{align}
The length scale associated with $10~\textnormal{TeV}$ is tiny: $10^{-20}~\textnormal{m}$. Compare this to the typical atomic length, $\text{\AA} = 0.1~\textnormal{nm} = 10^{-10}~\textnormal{m}$. The inverse relation $\ell \sim E^{-1}$ makes it clear that increasing the energy decreases the length scale. 
\end{example}

We can understand the $E \sim \ell^{-1}$ relation from ordinary optical microscopy. As we increase the energy of a photon, we increase its frequency and therefore decrease its wavelength, $\lambda$. We need the wavelength of the probe to be \emph{smaller} that the characteristic size features that we are studying, $\lambda \ll \Delta x$. \flip{Insert water waves/rock analogy.}





\chapter{Relativity, Quantum Mechanics}

We begin our study of particle physics with a lightning review of selected topics in special relativity and quantum mechanics.

\section{Kinematics}

The popular Einstein relation, $E = mc^2$, is actually the low [kinetic] energy limit of the `full' relation:
\begin{align}
    E^2 = m^2 c^4 + \vec{p}^2 c^2 \ .
    \label{eq:Einstein:relation:plus}
\end{align}
Equations that relate energy to momentum show up all over physics and have a special name: \textbf{dispersion relations}.\sidenote{As a student I always found this name intimidating because it would keep showing up in very different and increasingly advanced corners of physics. I felt like I must be missing something deep, especially since the word \emph{dispersion} did not seem to obviously fit. Historically, these relate wavelength to frequency. Recall that wave velocity is the product of wavelength and frequency---but wave velocity is purely a property in medium. Wavelength (or wave number) is directly related to momentum---think 
$\sin(kx)$---while frequency is directly related to energy---think $E=\hbar\omega$. These of these parameters are related to absorption (or decay) through complex analysis; these are the celebrated Kramers--Kr\"onig relations. We mention all of this to encourage you to look these ideas up and see how they connect; they are one of the deep threads in physics.} 
\begin{exercise}
It is obvious that \eqref{eq:Einstein:relation:plus} reproduces $E=mc^2$ when $\vec{p}=0$. Show that the leading order correction in the small-$\vec{p}$ limit is simply the non-relativistic kinetic energy of the particle. \textsc{Hint:} start by identifying the \emph{dimensionless} small parameter and Taylor expand.
\end{exercise}
In natural units we set $c=1$. In this relation, $m$ is the mass of a particle while $E$ and $\vec{p}$ are the energy and three-momentum respectively. Let us write this with the kinematic quantities on the same side of the equation:
\begin{align}
    m^2 = E^2 - \vec{p}^2 \ .
    \label{eq:on:shell}
\end{align}
A particle that satisfies this relation is said to be \textbf{on shell}\index{on shell} or \emph{physical}. Anticipating quantum mechanics, another way of saying this is that on shell particles are \emph{observable states}. Personally, I think of `on shell' states as being \emph{nice} states that are relatable to my ordinary human experiences. This is in contrast to \textbf{off shell} particles, which states that are \emph{not} on shell and are intrinsically quantum. Off shell states are not observable and do not make sense classically. 

A scattering process is one where some number of \emph{observed} initial state particles interact quantum mechanically and produce and \emph{observed} number of final state particles. These initial and final states must each be on shell and conserve energy and momentum. 
\begin{newrule}[Kinematics]
A \textbf{physical scattering process} is one with an on shell initial state and an on shell final state. This just means that each particle in the initial and final state are on shell. Furthermore, the total energy $E$ and total three-momentum $\vec{p}$ are conserved through the process. In equations:
\begin{align}
    E_\textnormal{in} &= E_\textnormal{out}
    &
    \vec{p}_\textnormal{in} &= \vec{p}_\textnormal{out}
    &
    m_i^2 = E_i^2 - \vec{p_i}^2 \ ,
\end{align}
where $i$ labels each of the external (initial or final) particles. Technically, we should also specify that $E_i>0$, but for us we can take this as an ``obvious'' fact.\sidenotemark Note that in this notation, $E_\textnormal{in}$ is the sum of the energies of all the initial state particles, and similarly for the other in/out quantities.
\end{newrule}\sidenotetext{From a group theory perspective, positive energy means that we are restricting to the \emph{orthochronus}\index{orthochronus} Lorentz group. This means that particles always move forward in time, no matter what reference frame we are in. The relation between energy positivity and direction in time should be clear from the time evolution operator, \eqref{eq:Ut:time:H} with $\hat H\to E$.}

Suppose you have a particle detector that measures the energy of a particle passing through it---this is called a \emph{calorimeter}. If you also know the mass of the particle, then you can also unambiguously determine the magnitude of the momentum, $|\vec{p}|$.  Alternatively, if you could separately measure the energy and the momentum of a particle, then you can unambiguously infer its mass. This is all obvious because you are using one Einstein relation to relate three variables---mass, energy, and momentum. 

\begin{exercise}
Suppose you have a process where one particle decays into two other particles; these particles do not necessarily have the same masses, but suppose you know all of the masses. You know the energy and momentum of the initial particle, $E_\textnormal{in}$ and $\vec{p}_\textnormal{in}$. You do not know, \emph{a priori}, the energies or momenta of the final state particles. How many unknown scalar quantities are there? How many constraint equations are there? \textsc{Hint}: recall that $\vec{p}$ is a vector with three separate quantities. Argue that there is generically \emph{no} solution to this system unless some parameters (e.g.\ the masses) are just right.
\end{exercise}

\begin{exercise}
Suppose you have a process where two particles come in, and two particles come out. The particles do not necessarily have the same mass, but you know all of the masses. If you know the energies of the initial particles, how many unknowns are there and how many constraint equations are there? Do you expect this system to have a solution? \textsc{Note}: for the purposes of this problem, assume that all energies are positive. This corresponds to satisfying the orthochronus constraint. If you are nervous about this, check that by increasing the energies of the initial particles you can make sure that the final state particles have positive energy. 
\end{exercise}


\section{Special Relativity}

\begin{flipcomment}
This section is a very brief review of the main points. For a more systematic derivation, please see my Physics 17 lecture notes. 
\end{flipcomment}

My favorite refernece to appreciate the geometric structure of special relativity is the book \emph{Very Special Relativity}\autocite{bais2007very}.
\begin{marginfigure}%[th]
    \includegraphics[width=.8\textwidth]{figures/vsr_cover.png}
    \captionsetup{font={scriptsize,sf}}
    \caption{How to learn special relativity.}
    \label{fig:VSR:cover}
\end{marginfigure}
It looks like a miniature coffee table book, but it is a perfect book for physics students who have completed their lower-level coursework.\sidenote{If you can derive every result in the book then you are ready to take general relativity. You should be able to do this over a winter break.}\sidenote{Do not confuse the title of this book with the Cohen--Glashow hypothesis, \arXiv{hep-ph/0601236}, which is a rather different thing.} Once you have mastered this, you can pick up your favorite general relativity textbook for a bit more of the mathematical formalism. Some suggestions: Hartle\autocite{Hartle:2003yu}, Schutz\autocite{schutz2009first}, and Carroll\autocite{Carroll:2004st}. I would be remiss not to also mention the beautiful and elegant tome known lovingly as \acro{MSW}\autocite{misner2017gravitation}; a book so beloved that it had its own 50$^\textnormal{th}$ anniversary celebration.\footnote{\url{https://www.youtube.com/watch?v=a-4-IPBNV60}}
\begin{marginfigure}%[th]
    \includegraphics[width=.8\textwidth]{figures/MSW_cover.png}
    \captionsetup{font={scriptsize,sf}}
    \caption{Published 50 years ago---right around when the Standard Model was established---\tacro{MSW} is still one of the most insightful places to learn and re-learn relativity. }
    \label{fig:MTW:cover}
\end{marginfigure}

The key tenet of special relativity is that the speed of light is constant. You already know from \eqref{sec:units:dimensions} that this constant means that there is a natural conversion between space and time. Indeed, you should already be familiar with the two primary manifestations of this in mechanics:
\begin{itemize}
    \item Time dilation: We measure time to pass more slowly for objects moving relative to our reference frame.
    \item Length contraction: We measure the distance along the direction of motion to be shorter for objects moving relative to our reference frame. 
\end{itemize}
This is formalized with respect to the relative velocity\sidenote{In \tacro{SI} units we would say $\beta = v/c$.} $\beta = v$ and the factor
\begin{align}
    \gamma = \frac{1}{\sqrt{1-\beta^2}} \ .
\end{align}
\begin{exercise}
What is the range of allowed values of $\beta$? What is the range of allowed values for $\gamma$? What is the allowed range of the product $\gamma\beta$?
\end{exercise}
We, as observers, define a stationary reference frame with coordinates $t$ and $x$. For our purposes, let us assume a (1+1)-dimensional spacetime.\sidenote{This notation means one dimension of time and one dimension of space.} Suppose that there is another references frame that is moving at constant velocity relative to ours. Then an observer in that reference frame has a coordinate system $t'$ and $x'$. Fig.~\ref{fig:relativity:axes} plots the axes of this coordinate system on our coordinate system. 
\begin{marginfigure}%[th]
    \includegraphics[width=\textwidth]{figures/rel_axes.pdf}
    \captionsetup{font={scriptsize,sf}}
    \caption{Coordinates of a boosted observer relative to our coordinates.}
    \label{fig:relativity:axes}
\end{marginfigure}
\begin{exercise}
Compare Fig.~\ref{fig:relativity:axes} to the spatial $x$--$y$ plane and the $x'$--$y'$ plane where the primed coordinates are those of an observer rotated by angle $\theta$ relative to the unprimed observer.
\end{exercise}
the coordinates are related by
\begin{align}
    t' &= \gamma t - \gamma\beta x &
    x' &= \gamma x - \gamma\beta t \\
    t &= \gamma t' + \gamma\beta x' &
    x &= \gamma x' + \gamma\beta t' \ .
    \ .
\end{align}
\begin{example}
Suppose the boosted observer has a stick that they measure to be length $\ell'$. That means in a time slice $\Delta t' = 0$ it observes a distance interval $\Delta x' = \ell'$. In our frame, we measure
\begin{align}
    \Delta t &= \gamma \beta \,\Delta \ell'
    &
    \Delta x &= \gamma \,\Delta\ell' \ .
\end{align}
We see that the length that \emph{we} measure $\ell = \Delta x = \gamma\,\Delta\ell'$ is larger than the length that the boosted observer measures, $\ell'$. In other words, the \flip{fix this... I have clearly made a mistake}
\end{example}


\section{Indexology of Special Relativity}

\subsection{Upper Index}

The unification of space and time is manifest in the formalism of \textbf{four vectors}\index{four vector}. At one level, this is a simple generalization of three-component vectors to four-component vectors. For example, an \emph{event} is a position $\vec{x}$ and a time $t$ and we can write it as a four-vector with an upper index:
\begin{align}
    x^\mu \equiv (x^0, x^1, x^2, x^3) = (t,x,y,z) \ .
\end{align}
There are several caveats that we should make at this point since they are not often stated out loud in textbooks:
\begin{itemize}
    \item We use the usual physicist's abuse of notation where we identify an object $x$ with a generic component, $x^\mu$. 
    \item It is conventional to index time with $\mu=0$. Some old texts use the antiquated notation $x^4$. For this reason in theories of extra dimensions it is conventional to label the extra dimension as $x^5$. 
    \item There is no such thing as a \emph{position vector}.\sidenote{I know a mathematician who was confused when the physics students in his calculus class kept talking about position vectors, as if the students were talking about unicorns. This may seem like nit picking, but it this insight is part of the underlying geometric picture built on fiber bundles. See \arXiv{hep-th/0611201} for a pedagogical introduction that should be accessible to students of this class with a bit of work.} This is because vector spaces have a special point, the origin $x^\mu = 0$. There is no such special point in spacetime. However, relative positions, $\Delta x^\mu = x_A^\mu - x_B^\mu$, are well defined vectors. 
\end{itemize}
In particle physics we do not often deal with (relative) position four vectors because our states are typically momentum eigenstates. Just as time and space are unified by $c=1$, so too are energy and momentum. These are combined into a four-momentum,
\begin{align}
    p^\mu \equiv (p^0, p^1, p^2, p^3) = (E, p_x, p_y, p_z) \ .
\end{align}
$p^\mu$ is the Fourier transform of $x^\mu$. It should not surprise you that we work with momentum eigenstates: these are the states that are eigenstates of the Hamiltonian by virtue of having a well defined energy. The on shell condition \eqref{eq:on:shell} then gives a well defined three-momentum magnitude.

\subsection{Lorentz Transformations}

A \textbf{Lorentz transformation} 

\section*{Acknowledgments}

\acro{PT}\ thanks 
all the people who taught him quantum field theory and particle physics over the years. In particular, courses from Scott Thomas, Pat Burchat, Savas Dimopoulos, Aaron Roodman, Michael Peskin, Shamit Kachru, David Tong, Maciej Dunajski, Ben Allanach, Hugh Osborn, Fernando Quevedo, Silvia Pascoli, Csaba Cs\'aki, Maxim Perelstein, and Yuval Grossman. I am further indebted to those who were (and are still) on this journey to figure this all out---those are too many to list explicitly, but I especially thank my postdoctoral mentors Tim Tait and Jonathan Feng, and everyone who has ever shared an office or done problem sets with me. My approach to writing and pedagogy is inspired by the writing of Sidney Coleman, Anthony Zee, David Tong, and Matthew Strassler---the physicists who you read if they have ever written anything vaguely related to whatever it is you are trying to learn.
%
% \acro{PT} thanks 
%     the Aspen Center for Physics (\acro{NSF} grant \acro{\#1066293})
%     % and the Kavli Institute for Theoretical Physics (\acro{NSF} grant \acro{PHY-1748958})`'
%     for 
%     its 
%     % their
%     hospitality during a period where part of this work was completed. 
% %
% \acro{PT} is supported by the \acro{DOE} grant \acro{DE-SC}/0008541.
\acro{PT} is supported by a \acro{NSF CAREER} award (\#2045333).

%% Appendices
\appendix
% \chapter{Proper appendix}
% index that follows this chapter.

% \section{Things to work on}

% It may be nice to incorporate something like \texttt{classicthesis}\footnote{\url{https://www.ctan.org/tex-archive/macros/latex/contrib/classicthesis/}}

\chapter{Notation and Conventions}

\section{Spacetime Conventions}
\label{app:spacetime:conventions}


\acro{4D} Minkowski indices are written with lower-case Greek letters from the middle of the alphabet, $\mu, \nu, \cdots$. \acro{5D} indices are written in capital Roman letters from the middle of the alphabet, $M, N, \cdots$. Tangent space indices are written in lower-case Roman letters from the beginning of the alphabet, $a,b, \cdots$. Flavor indices are written in lower-case Roman letters near the beginning of the alphabet, $i,j,\cdots$.

% We use the particle physics (`West Coast,' mostly-minus) metric for Minkowski space, $(+,-,-,-)$. We will also use the conformally flat AdS$_5$ metric,
% \begin{align}
%   ds^2= \left(\frac{R}{z}\right)^2 \left(\eta_{\mu\nu}dx^\mu dx^\nu - dz^2\right).
% \end{align} 
Dirac spinors $\Psi$ are related to left- and right-chiral Weyl spinors ($\chi, \bar\psi$ respectively) via
\begin{align}
    \Psi = \begin{pmatrix}
        \chi \\
        \bar\psi
    \end{pmatrix}.
\end{align}
Note that sometimes we will write $\Psi=(\psi,\bar\chi)^T$. The point is that un-barred Weyl spinors are---by convention---left-handed while barred spinors are right-handed. 
Our convention for $\sigma^0$ and the three Pauli matrices $\vec\sigma$ is
\begin{align}
    \sigma^0 = 
    \begin{pmatrix}
        1 & 0\\
        0 & 1
    \end{pmatrix}
    \quad
    \sigma^1 = 
    \begin{pmatrix}
        0 & 1\\
        1 & 0
    \end{pmatrix}
    \quad
    \sigma^2 = 
    \begin{pmatrix}
        0 & -i\\
        i & 0
    \end{pmatrix}
    \quad
    \sigma^3 = 
    \begin{pmatrix}
        1 & 0\\
        0 & -1
    \end{pmatrix}
\end{align}
with the flat-space $\gamma$ matrices given by
\begin{align}
    \gamma^\mu =
    \begin{pmatrix}
        0 & \sigma^\mu \\
        \bar\sigma^\mu & 0 
    \end{pmatrix}
    \quad\quad\quad\quad
    \gamma^5=
    \begin{pmatrix}
        i\mathbbm{1} & 0 \\
        0 & -i\mathbbm{1}
    \end{pmatrix},
\end{align}
where $\bar\sigma^\mu = (\sigma^0, -\vec\sigma)$.
This convention for $\gamma^5$ gives us the correct Clifford Algebra. (Note that this differs from the definition of $\gamma^5$ in Peskin \& Schroeder.)


\chapter{Representations of the Poincare Group}

This appendix is slightly more advanced than the rest of these notes.

\section{The Poincar\'e Algebra}
\label{sec:Poincare:Algebra}
% 
We briefly review the Poincar\'e group and its spinor representations. 
%
Readers with a strong background in field theory will be familiar with these topics and can skip this subsection. Other readers with a weaker background in the representations of the Poincar\'e group are encouraged to do peruse more thorough literature on this topic. Excellent references include section 2 of Weinberg, Vol. I \autocite{weinberg}, Section 1 of Buchbinder and Kuzenko\autocite{Buchbinder:1998qv}, Section 5 of Gutowski\autocite{gutowski}, Section 4 of Osborn\autocite{Osborn:Symmetries}, and Section 10 of Jones\autocite{JonesGroups}. 

\subsection{The Poincar\'e group and its properties}

The \textbf{Poincar\'e group}\index{Poincar\'e group@Poincar\'e group} describes the symmetries of Minkowski space and is composed of transformations of the form
\begin{align}
    x^\mu &\rightarrow x'^\mu = \Lambda^\mu_{\phantom{\mu}\nu} x^\nu + a^\mu,
\end{align}
where $a^\mu$ parameterizes translations and $\Lambda^\mu_{\phantom{\mu}\nu}$ parameterizes transformations of the Lorentz group \index{Lorentz group} containing rotations and boosts. 
%
We can write elements of the Poincar\'e group as $\{(\Lambda,a)\}$. A pure Lorentz transformation is thus $(\Lambda,0)$ while a pure translation is $(\mathbbm{1},a)$. 
%
Elements are multiplied according to the rule
\begin{align}
    (\Lambda_2,a_2)\cdot(\Lambda_1,a_1) &= (\Lambda_2\Lambda_1,\,\Lambda_2 a_1 + a_2.).\label{eq:SUSYalg:Poincar\'e:multiplication}
\end{align}
%
Note that these transformations \textit{do not commute},
\begin{align}
    (\Lambda,0)\cdot (\mathbbm{1},a) &= (\Lambda,\Lambda a)\\
    (\mathbbm{1},a)\cdot(\Lambda,0) &= (\Lambda,a).
\end{align}
Thus the Poincar\'e group is \textit{not} a direct product of the Lorentz group and the group of 4-translations. The technical term for the relation between these groups is that the Poincar\'e group is a \textbf{semi-direct product} of the Lorentz and 4-translation groups.

Locally the Poincar\'e group is represented by the algebra
\begin{align}
    [M^{\mu\nu},M^{\rho\sigma}] &= i(M^{\mu\sigma}\eta^{\nu\rho}+ M^{\nu\rho}\eta^{\mu\sigma} - M^{\mu\rho}\eta^{\nu\sigma} - M^{\nu\sigma}\eta^{\mu\rho})\label{eq:SUSYalg:Poincar\'e:alg:1}\\
    [P^\mu,P^\nu] &= 0\label{eq:SUSYalg:Poincar\'e:alg:2}\\
    [M^{\mu\nu}, P^\sigma] &= i(P^\mu\eta^{\nu\sigma}-P^\nu\eta^{\mu\sigma}).\label{eq:SUSYalg:Poincar\'e:alg:3}
\end{align}
The $\mathbf{M}$ are the antisymmetric generators of the Lorentz group,
\begin{align}
(M^{\mu\nu})_{\rho\sigma}&=i(\delta^\mu_\rho\delta^\nu_\sigma-\delta^\mu_\sigma\delta^\nu_\rho),\label{eq:SUSYalg:LorentzGenerators}
\end{align}
and the $\mathbf P$ are the generators of translations. We will derive the form of the Lorentz generators below. As a `sanity check,' one should be able to recognize in  (\ref{eq:SUSYalg:Poincar\'e:alg:1}) the usual $O(3)$ Euclidean symmetry  by taking $\mu,\nu,\rho,\sigma \in \{1,2,3\}$ and noting that at most only one term on the right-hand side survives. One may check that this coincides with the algebra for angular momenta, $\mathbf J$.  Equation (\ref{eq:SUSYalg:Poincar\'e:alg:2}) says that translations commute, while  (\ref{eq:SUSYalg:Poincar\'e:alg:3}) says that the generators of translations transform as vectors under the Lorentz group. This is, of course, expected since the generators of translations are precisely the four-momenta. The factors of $i$ should also be clear since we're taking the generators $\mathbf{P}$ and $\mathbf{M}$ to be Hermitian. 

One can represent this algebra in matrix form as
\begin{align}
    \left(
    \begin{array}{cc:c}
    \multicolumn{2}{c:}{\multirow{2}{*}{\Large{$M$}}} & \multicolumn{1}{c}{\multirow{2}{*}{\Large{$P$}}} \\
     &&  \\
    \hdashline
    0 & 0 & 1
    \end{array}
    \right).
\end{align}
One can check explicitly this reproduces the algebra in (\ref{eq:SUSYalg:Poincar\'e:alg:1}--\ref{eq:SUSYalg:Poincar\'e:alg:3}) and the multiplication law (\ref{eq:SUSYalg:Poincar\'e:multiplication}).
%
The `translation' part of the Poincar\'e algebra is boring and requires no further elucidation. It is the Lorentz algebra that yields the interesting features of our fields under Poincar\'e transformations.

\subsection{The Lorentz Group}

Let us now explore the \textbf{Lorentz group}\index{Lorentz group}, which is sometimes called the \textbf{homogeneous Lorentz group}\index{Lorentz group!homogeneous} to disambiguate it from the Poincar\'e group which is sometimes called the \textbf{inhomogeneous Lorentz group}\index{Lorentz group!inhomogeneous|see{Poincar\'e group}}.

The Lorentz group is composed of the transformations that preserve the inner product on Minkowski space, $\langle x^\mu,x^\nu\rangle = x^\mu \eta_{\mu\nu}x^\nu = x^\mu x_\mu$. In particular, for $x^\mu \rightarrow x'^\mu = \Lambda^{\mu}_{\phantom\mu\nu}x^\nu$, we have
\begin{align}
    \left(\Lambda^\mu_{\phantom\mu\rho}x^\rho\right) \eta_{\mu\nu} \left(\Lambda^{\nu}_{\phantom\nu\sigma}x^\sigma\right) &= x^\rho \eta_{\rho\sigma}x^\sigma.
\end{align}
From this we may deduce that the fundamental transformations of the Lorentz group satisfy the relation
\begin{align}
        \Lambda^\mu_{\phantom\mu\rho}\, \eta_{\mu\nu}\, \Lambda^{\nu}_{\phantom\nu\sigma} &= \eta_{\rho\sigma},\label{eq:SUSYalg:lorentzgroup:indices}
\end{align}
or in matrix notation,
\begin{align}
    \mathbf{\Lambda^T\eta\Lambda} &= \eta,\label{eq:SUSYalg:lorentzgroup}
\end{align}
where $\eta = \text{diag}(+,-,-,-)$ is the usual Minkowski metric used by particle physicists\sidenote{If you are a particle physicist born after 1980 and you write papers using a different metric, then I am mad at you.}.

\subsubsection{Generators of the Lorentz Group}

Let's spell out the procedure for determining the generators of the Lorentz group. We will later follow an analogous procedure to determine the generators of supersymmetry. We start by writing out any [finite] Lorentz transformation as the exponentiation
\begin{align}
    \mathbf{\Lambda} &= e^{i t \mathbf{W}},\label{eq:SUSYalg:lorentz:exp}
\end{align}
where $t$ is a transformation parameter and $\mathbf{W}$ is the generator we'd like to determine. We stick with the convention that generators of unitary representations  should be Hermitian. 
%
Clever readers will question whether it is true that \textit{all} Lorentz transformations can be written as the exponentiation of a generator at the identity. This is true for the cases of physical interest, where we only deal with the part of the subgroup which is connected to the identity. We will discuss the disconnected parts shortly.

Plugging (\ref{eq:SUSYalg:lorentz:exp}) into  (\ref{eq:SUSYalg:lorentzgroup}) and setting $t=0$, we obtain the relation
\begin{align}
    \mathbf{\eta} \mathbf{W} + \mathbf{W}^T \mathbf{\eta} &= 0,
\end{align}
or with explicit indices,
\begin{align}
    \eta_{\mu\rho}W^\rho_{\phantom\rho\nu} + W^\rho_{\phantom\rho\mu}\eta_{\rho\nu} &=0\\
    W_{\mu\nu} + W_{\nu\mu} &= 0.
\end{align}
Thus the generators $\mathbf{W}$ are $4\times 4$ antisymmetric matrices characterized by six real transformation parameters so that there are six generators. Let us thus write the exponent of the finite transformation (\ref{eq:SUSYalg:lorentz:exp}) as
\begin{align}
    it\,W^{\lambda\sigma} &= i t\omega^{\mu\nu}\left(M_{\mu\nu}\right)^{\lambda\sigma},
\end{align}
where $\omega^{\mu\nu}$ is an antisymmetric $4 \times 4$ matrix parameterizing the linear combination of the independent generators and $\left(M_{\mu\nu}\right)^{\lambda\sigma}$ are the Hermitian generators of the Lorentz group. The $\mu,\nu$ indices label the six generators, while the $\lambda,\sigma$ indices label the matrix structure of each generator.

We may thus verify that  (\ref{eq:SUSYalg:LorentzGenerators}) indeed furnishes a basis for the generators of the Lorentz group connected to the identity
\begin{align}
(M^{\mu\nu})_{\rho\sigma}&=i(\delta^\mu_\rho\delta^\nu_\sigma-\delta^\mu_\sigma\delta^\nu_\rho).
\end{align}
The qualification ``connected to the identity'' turns out to be rather important, as we shall see when we consider representations of the Lorentz algebra.

\subsubsection{Components of the Lorentz Group}

Recall that the Lorentz group has four disconnected parts. The defining  (\ref{eq:SUSYalg:lorentzgroup}) implies that 
\begin{align}
    \left(\det \mathbf\Lambda\right)^2 &= 1,\\
    (\Lambda^0_{\phantom{0}0})^2-\sum_i(\Lambda_0^{\phantom{0}i})^2 &=1,
\end{align}
where the first equation comes from taking a determinant and the second equation comes from taking $\rho=\sigma=0$ in  (\ref{eq:SUSYalg:lorentzgroup:indices}). From these equations we see that 
\begin{align}
    \det\mathbf\Lambda &= \pm 1\\
    \Lambda^0_{\phantom 00} &= \pm \sqrt{1+\sum_i(\Lambda_0^{\phantom{0}i})^2}.
\end{align}
The choice of the two signs on the right-hand sides of these equations labels the four components of the Lorentz group. One cannot form a smooth path in the space of Lorentz transformations starting in one component of and ending in another (i.e. they are disconnected).

The component of the Lorentz group with $\det \mathbf\Lambda = +1$ contains the identity element and is a subgroup that preserves parity. In order to preserve the direction of time, one ought to further choose $\Lambda^0_{\phantom{0}0}\geq 1$. We shall specialize to this subgroup, which is called the \textbf{orthochronous Lorentz group}\index{Lorentz group!orthochronous}, $SO(3,1)^\uparrow_+$ which further satisfies 
\begin{align}
    \det \mathbf{\Lambda}&= +1\\
    \Lambda^0_0 &\geq 1.
\end{align}
Other parts of the Lorentz group can be obtained from $SO(3,1)^\uparrow_+$ by applying the transformations
\begin{align}
    \Lambda_P &= \text{diag}(+,-,-,-)\\
    \Lambda_T &= \text{diag}(-,+,+,+).
\end{align}
Here $\Lambda_P$ and $\Lambda_T$ respectively refer to parity and time-reversal transformations. One may thus write the Lorentz group in terms of `components' (not necessarily `subgroups'),
\begin{align}
    SO(3,1) &= SO(3,1)^\uparrow_+ \oplus SO(3,1)^\uparrow_- \oplus SO(3,1)^\downarrow_+ \oplus SO(3,1)^\downarrow_-,
\end{align}
where the up/down arrow refers to $\Lambda^0_{\phantom 00}$ greater/less than $\pm 1$, while the $\pm$ refers to the sign of $\det \mathbf\Lambda$. Again, only $SO(3,1)^\uparrow_\pm$ form subgroups. In these notes we will almost exclusively work with the orthochronous Lorentz group so that we will drop the $\pm$ and write this as $SO(3,1)^\uparrow$. 

It is worth noting that the fact that the Lorentz group is not simply connected is related to the existence of a `physical' spinor representation, as we will mention below.


\subsubsection{\texorpdfstring{The Lorentz Group is related to $SU(2) \times SU(2)$}{The Lorentz Group is related to SU(2)xSU(2)}}

%\textbf{FT:} Excellent discussions can be found in \url{http://groups.google.com/group/sci.physics.research/browse_thread/thread/301d2700bacebc05/9d0b342e91b4eea9?hl=en&lnk=gst&q=reece#9d0b342e91b4eea9}

Locally the Lorentz group is related to the group $SU(2)\times SU(2)$, i.e. one might suggestively write
\begin{align}
    SO(3,1) &\approx SU(2)\times SU(2).
\end{align}
Let's flesh this out a bit. One can explicitly separate the Lorentz generators $M^{\mu\nu}$ into the generators of rotations, $J_i$, and boosts, $K_i$:
\begin{align}
    J_i &= \frac 12 \,\epsilon_{ijk}\,M_{jk}\label{eq:Poincar\'e:J}\\
    K_i &= M_{0i},\label{eq:Poincar\'e:K}
\end{align}
where $\epsilon_{ijk}$ is the usual antisymmetric Levi-Civita tensor. 
$\mathbf J$ and $\mathbf K$ satisfy the algebra
\begin{align}
    [J_i, J_j] &= \phantom+ i\epsilon_{ijk}J_k\label{eq:SUSYalg:JJ}\\
    [K_i, K_j] &= -i\epsilon_{ijk}J_k\label{eq:SUSYalg:KK}\\
    [J_i, K_j] &= \phantom+ i\epsilon_{ijk}K_k.\label{eq:SUSYalg:JK}
\end{align}
We can now define `nice' combinations of these two sets of generators,
\begin{align}
    A_i &= \frac 12 (J_i + iK_i)\label{eq:SUSYalg:Ai}\\
    B_i &= \frac 12 (J_i - iK_i)\label{eq:SUSYalg:Bi}.
\end{align}
This may seem like a very arbitrary thing to do, and indeed it's \textit{a priori} unmotivated. However, we now see that the algebra of these generators decouple into two $SU(2)$ algebras,
\begin{align}
    [A_i,A_j] &= i\,\epsilon_{ijk}\, A_k\\
    [B_i,B_j] &= i\,\epsilon_{ijk}\, B_k\\
    [A_i,B_j] &= 0.
\end{align}
Magic! %The $\textbf{A}$ and $\textbf{B}$ generators form \textit{decoupled} representations of the $SU(2)$ algebra. 
Note, however, that from  (\ref{eq:SUSYalg:Ai}) and (\ref{eq:SUSYalg:Bi}) that these generators are \emph{not} Hermitian (gasp!). 
Recall that a Lie group is generated by Hermitian operators.\sidenote{Mathematicians often use anti-Hermitian generators.} Thus we were careful above \emph{not} to say that $SU(3,1)$ \textit{equals} $SU(2)\times SU(2)$, where `equals' usually means either isomorphic or homomorphic. As a further sanity check, $SU(2)\times SU(2)$ is manifestly compact while the Lorentz group cannot be since the elements corresponding to boosts can be arbitrarily far from the origin.
%
This is all traced back to the sign difference in the time-like component of the metric, i.e.\ the difference between $SO(4)$ and $SO(3,1)$. While rotations are Hermitian and generate unitary matrices, boosts are anti-Hermitian and generate anti-unitary matrices. At this level, then, our representations are non-unitary.

Anyway, we needn't worry about the precise sense in which $SO(3,1)$ and $SU(2)\times SU(2)$ are related, the point is that we may label representations of $SO(3,1)$ by the quantum numbers of $SU(2)\times SU(2)$, $(A,B)$. For example, a Dirac spinor is in the $(\frac 12, \frac 12)=(\frac 12, 0)\oplus (0,\frac 12)$ representation, i.e. the direct sum of two Weyl reps. 
%(More on this in Section \ref{sec:susyalg:repsofsl2c}.) 
To connect back to reality\sidenote{Ope! There goes gravity. Apologies to Eminem, ``Lose Yourself.''}, the physical meaning of all this is that we may write the spin of a representation as $J=A+B$.


\subsubsection{An aside: complexified algebras}
So how are $SO(3,1)$ and $SU(2)\times SU(2)$ \textit{actually} related?

We've been deliberately vague about the exact relationship between the Lorentz group and $SU(2)\times SU(2)$. The precise relationship between the two groups are that the \textit{complex} linear combinations of the generators of the Lorentz algebra are isomorphic to the \textit{complex} linear combinations of the Lie \textit{algebra} of $SU(2)\times SU(2)$. 
    \begin{align}
        \mathcal L_{\mathbb{C}}(SO(3,1)) &\cong \mathcal L_{\mathbb{C}}(SU(2)\times SU(2))
    \end{align}
    Be careful not to say that the Lie algebras of the two groups are identical, it is important to emphasize that only the \textit{complexified} algebras are identifiable. 
    % See: http://groups.google.com/group/sci.physics.research/browse_thread/thread/301d2700bacebc05/9d0b342e91b4eea9?hl=en&lnk=gst&q=reece#9d0b342e91b4eea9
    % See also: http://groups.google.com/group/sci.physics.research/browse_thread/thread/73e95b0c8cca27fd/8f88fe7881dd56d0?hl=en&lnk=gst&q=pauli+matrix+indices#8f88fe7881dd56d0
    %
    % See further: Bilal's SUSY notes
    The complexification of $SU(2)\times SU(2)$ is the special linear group, $SL(2,\mathbb C)$. In the next subsection we will identify $SL(2,\mathbb C)$ as the \textbf{universal cover}\index{universal cover} of the Lorentz group. First, however, we shall show that the Lorentz group is isomorphic to $SL(2,\mathbb C)/\mathbb{Z}_2$. %We discuss this topic from an orthogonal direction in Section \ref{sec:SUSYalg:projective}.



\subsubsection{\texorpdfstring{The Lorentz group is isomorphic to $SL(2,\mathbb{C})/\mathbb{Z}_2$}{The Lorentz group is isomorphic to SL(2,C)/Z2}}\index{SL(2,C)@$SL(2,\mathbb C)$}

While the Lorentz group and $SU(2)\times SU(2)$ were neither related by isomorphism nor homomorphism, we \textit{can} concretely relate the Lorentz group to $SL(2,\mathbb{C})$. More precisely, the Lorentz group is isomorphic to the coset space $SL(2,\mathbb{C})/\mathbb{Z}_2$
\begin{align}
    SO(3,1) \cong SL(2,\mathbb{C})/\mathbb{Z}_2
\end{align}

% ***
% % 
Recall that we may represent four-vectors in Minkowski space as complex Hermitian $2\times 2$ matrices via $V^\mu \rightarrow V_\mu\sigma^\mu$, where the $\sigma^\mu$ are the usual Pauli matrices\index{Pauli matrix},
\begin{align}
    \sigma^0 = 
    \begin{pmatrix}
        1 & 0\\
        0 & 1
    \end{pmatrix}
    \quad
    \sigma^1 = 
    \begin{pmatrix}
        0 & 1\\
        1 & 0
    \end{pmatrix}
    \quad
    \sigma^2 = 
    \begin{pmatrix}
        0 & -i\\
        i & 0
    \end{pmatrix}
    \quad
    \sigma^3 = 
    \begin{pmatrix}
        1 & 0\\
        0 & -1
    \end{pmatrix}.\label{eq:SUSYalg:pauli:matrices}
\end{align}
$SL(2,\mathbb C)$ is the group of complex $2\times 2$ matrices with unit determinant. It is spanned precisely by these Pauli matrices. 
Purists will admonish us for not explicitly distinguishing between a Lie group ($SL(2,\mathbb{C})$) and its algebra ($sl(2,\mathbb{C})$ or $\mathcal{L}[SL(2,\mathbb{C})]$ or $\mathfrak{sl}(2,\mathbb{C})$). The distinction is not worth the extra notational baggage since the meaning is clear in context


To be explicit, we may associate a vector $\mathbf x$ with either a vector in Minkowski space $\mathbb M^4$ spanned by the unit vectors $e^\mu$,
\begin{align}
    \mathbf x &= x^\mu e_\mu = \left(x^0,x^1,x^2,x^3\right),\label{eq:susyalg:vectorrep}
\end{align}
    or with a matrix in $SL(2,\mathbb C)$,
\begin{align}
    \mathbf x &= x_\mu \sigma^\mu
              = \begin{pmatrix}
                \phantom+x_0 + \phantom{i} x_3 &\quad \phantom+ x_1-ix_2\\
                \phantom+x_1+ix_2 &\quad \phantom+ x_0-\phantom{i} x_3
              \end{pmatrix}.\label{eq:susyalg:sl2crep}
\end{align}
Note the lowered indices on the components of $x_\mu$, i.e. $(x^0,x^1,x^2,x^3) = (x_0,-x_1,-x_2,-x_3)$. The four-vector components are recovered from the $SL(2,\mathbb C)$ matrices via
\begin{align}
    x_0 &= \frac 12\text{Tr}(\mathbf{x}), & x_i &= \frac 12\text{Tr}(\mathbf{x}\sigma^i).\label{eq:SUSYalg:sl2ctom4}
\end{align}
The latter of these is easy to show by expanding $\mathbf{x} = x_0\mathbbm{1}^0 + x_i\sigma^i$ and then noting that $\mathbbm{1}\sigma^i \propto \sigma^i$, $\sigma^j\sigma^i|_{j\neq i}\propto \sigma^k_{k\neq i}$, and $\sigma^i\sigma^i|_{\text{no sum}}\propto \mathbbm{1}$. Thus only the $\sigma^i\sigma^i$ term of $\mathbf{x}\sigma^i$ has a trace, so that taking the trace projects out the other components.

For the Minkowski four-vectors, we already understand how a Lorentz transformation $\mathbf \Lambda$ acts on a [covariant] vector $x^\mu$ while preserving the vector norm,   
\begin{align}
    |\mathbf x |^2 &= x_0^2 - x_1^2 - x_2^2 - x_3^2.\label{eq:SUSYalg:mink:invt}
\end{align}
This is just the content of  (\ref{eq:SUSYalg:lorentzgroup}), which defines the Lorentz group.

For Hermitian matrices, there is an analogous transformation by the action of the group of invertible complex matrices of unitary determinant, $SL(2,\mathbb C)$. For $\mathbf N \in SL(2,\mathbb C)$, $\mathbf N^\dag \mathbf{x} \mathbf N$
is also in the space of Hermitian $2\times 2$ matrices. Such transformations preserve the determinant of $\mathbf x$,
\begin{align}
    \det \mathbf{x} &= x_0^2 - x_1^2 - x_2^2 - x_3^2.\label{eq:SUSYalg:herm:invt}
\end{align}
The equivalence of the right-hand sides of s (\ref{eq:SUSYalg:mink:invt}) and (\ref{eq:SUSYalg:herm:invt}) are very suggestive of an identification between the Lorentz group $SO(3,1)$ and $SL(2,\mathbb C)$. Indeed,  (\ref{eq:SUSYalg:herm:invt}) implies that for each $SL(2,\mathbb C)$ matrix $\mathbf N$, there exists a Lorentz transformation $\Lambda$ such that 
\begin{align}
    \mathbf{N^\dag} x^\mu \mathbf{\sigma}_\mu \mathbf{N} &= (\Lambda x)^\mu \mathbf{\sigma}_\mu.\label{eq:SUSYalg:SL2C:Lorentz}
\end{align}
A very 
important feature should already be apparent: the map from $SL(2,\mathbb C)\rightarrow SO(3,1)$ is two-to-one. This is clear since the matrices $\mathbf N$ and $-\mathbf N$ yield the \textit{same} Lorentz transformation, $\Lambda^\mu_{\phantom\mu\nu}$. Hence it is not $SO(3,1)$ and $SL(2,\mathbb C)$ that are isomorphic, but rather $SO(3,1)$ and $SL(2,\mathbb C)/\mathbb Z_2$.

The point is that one will miss something if one only looks at representations of $SO(3,1)$ and not the representations of $SL(2,\mathbb C)$. This `something' is the spinor representation\index{spinor}. How should we have known that $SL(2,\mathbb C)$ is the important group? One way of seeing this is noting that $SL(2,\mathbb C)$ is \textbf{simply connected} as a group manifold.

By the polar decomposition for matrices, any $g \in SL(2,\mathbb C)$ can be written as the product of a unitary matrix $U$ times the exponentiation of a traceless Hermitian matrix $h$,
\begin{align}
    g &= U e^{h}.
\end{align}
We may write these matrices explicitly in terms of real parameters $a,\cdots,g$;
\begin{align}
     h &= \begin{pmatrix}c \quad& a-ib\\ a+ib \quad& -c\end{pmatrix}\\
     U &= \begin{pmatrix}d+ie \quad& f+ig\\-f+ig \quad& d-ie\end{pmatrix}.
\end{align}
Here $a,b,c$ are unconstrained while $d,\cdots,g$ must satisfy
\begin{align}
    d^2+e^2+f^2+g^2 &= 1.
\end{align}
Thus the space of $2\times 2$ traceless Hermitian matrices $\{h\}$ is topologically identical to $\mathbb R^3$ while the space of unit determinant $2\times 2$ unitary matrices $\{U\}$ is topologically identical to the three-sphere, $S_3$. Thus we have
\begin{align}
    SL(2,\mathbb C) &= \mathbb R^3 \times S_3.
\end{align}
As both of the spaces on the right-hand side are simply connected, their product, $SL(2,\mathbb C)$, is also simply connected. This is a `nice' property because we can write down any element of the group by exponentiating its generators at the identity. But even further, since $SL(2,\mathbb C)$ is simply connected, its quotient space $SL(2,\mathbb C)/\mathbb Z_2 = SO(3,1)^\uparrow$ is \emph{not} simply connected.




\subsubsection{Universal cover of the Lorentz group}\label{sec:SUSYalg:universal:cover}
% This comes from Kuzenko p.4

The fact that $SO(3,1)^\uparrow$ is not simply connected should bother you. In the back of your mind, your physical intuition should be unsatisfied with non-simply connected groups. This is because simply-connected groups have the very handy property of having a one-to-one correspondence between representations of the group and representations of its algebra; i.e. we can write any element of the group as the exponentiation of an element of the algebra about the origin. 

What's so great about this property? In quantum field theory fields transform according to representations of a symmetry's algebra, not representations of the group. Since $SO(3,1)^\uparrow$ is not simply connected, the elements of the algebra at the identity that we used do \textit{not} tell the whole story. They were fine for constructing finite elements of the Lorentz group \textit{that were connected to the identity}, but they don't capture the \textit{entire} algebra of $SO(3,1)^\uparrow$.\sidenote{To spoil the surprise, the point is this: the elements of the algebra of $SO(3,1)^\uparrow$ at the identity capture the vector (i.e. fundamental) representation of the Lorentz group, but it misses the spinor representation.}

% \vspace{.5em}
% \begin{framed}
%     \noindent\textbf{To spoil the surprise,} the point is this: the elements of the algebra of $SO(3,1)^\uparrow$ at the identity capture the vector (i.e. fundamental) representation of the Lorentz group, but it misses the spinor representation.
% \end{framed}
% \vspace{.5em}

Now we're in a pickle. Given a group, we know how to construct representations of an algebra near the identity based on group elements connected to the identity. But this only characterizes the entire algebra if the group is simply connected. $SO(3,1)^\uparrow$ is \textit{not} simply connected. Fortunately, there's a trick. It turns out that for any connected Lie group, there exists a unique `minimal' simply connected group that is homeomorphic to it called the \textbf{universal covering group}\index{universal covering group}. 

% from Kuzenko
Stated slightly more formally, for any connected Lie group $G$, there exists a simply connected universal cover $\tilde{G}$ such that there exists a homomorphism $\pi:\tilde G \to G$ where $G \cong \tilde G/\ker \pi$ and $\ker \pi$ is a discrete subgroup of the center of $\tilde G$. Phew, that was a mouthful. For the Lorentz group this statement is $SO(3,1)^\uparrow \cong SL(2,\mathbb{C})/\mathbb{Z}_2$. Thus the key statement is:
\begin{center}
% \begin{quote}
The Lorentz group is covered by $SL(2,\mathbb{C})$.
% \end{quote} 
\end{center}
The point is that the homomorphism $\pi$ is locally one-to-one and thus $G$ and $\tilde G$ have the same Lie algebras. Thus we can determine the Lie algebra of $G$ away from the identity by considering the  Lie algebra for $\tilde G$ at the identity.

This universal covering group of $SO(3,1)^\uparrow$ is often referred to as $Spin(3,1)$\index{spin(3,1)@\textit{Spin(3,1)}}. The name is no coincidence, it has everything to do with the spinor representation.


\subsubsection{Projective representations}\label{sec:SUSYalg:projective}

For the uninitiated, it may not be clear why the above rigamarole is necessary or  interesting. Here we would like to approach the topic from a different direction to explain why the spinor representation is necessarily the `most basic' representation of four-dimensional spacetime symmetry.
    
% %     \noindent 
A typical ``representation theory for physicists'' course goes into detail about constructing the usual tensor representations of groups but only mentions the spinor representation of the Lorentz group in passing. Students `inoculated' with a quantum field theory course will not bat an eyelid at this, since they're already used to the technical manipulation of spinors. But where does the spinor representation come from if all of the `usual' representations we're used to are tensors?
    
% %     \noindent
 The answer lies in quantum mechanics. Recall that when we write representations $U$ of a group $G$, we have $U(g_1)U(g_2) = U(g_1g_2)$ for $g_1, g_2 \in G$. In quantum physics, however, physical states are invariant under phases, so we have the freedom to be more general with our multiplication rule for representations: $U(g_1)U(g_2) = U(g_1g_2)\exp({i\phi(g_1,g_2)})$. Such `representations' are called \textbf{projective representations}. In other words, quantum mechanics allows us to use projective representations rather than ordinary representations. 
    
% %     \noindent 
It turns out that not every group admits `inherently' projective representations. In cases where such reps are not allowed, a representation that one \textit{tries} to construct to be projective can have its generators redefined to reveal that it is actually an ordinary non-projective representation. The relevant mathematical result for our purposes is that groups which are \textit{not} simply connected---such as the Lorentz group---\textit{do} admit inherently projective representations. 
    
% %     \noindent 
The Lorentz group is \textit{doubly} connected, i.e. going over any loop \textit{twice} will allow it to be contracted to a point. This means that the phase in the projective representation must be $\pm 1$. One can consider taking a loop in the Lorentz group that corresponds to rotating by $2\pi$ along the $\hat z$-axis. Representations with a projective phase $+1$ will return to their original state after a single rotation, these are the particles with integer spin. Representations with a projective phase $-1$ will return to their original state only after \textit{two} rotations, and these correspond to fractional-spin particles, or spinors. 
    
% %     \noindent 
An excellent discussion of projective representations can be found in Weinberg, Volume I\autocite{Weinberg:1995mt}. 
% %     %We reproduce the main parts of Weinberg's argument in \Appendix \ref{chap:Poincar\'e}. 
    More on the representation theory of the Poincar\'e group and its SUSY extension can be found in Buchbinder and Kuzenko\autocite{Buchbinder:1998qv}. Further pedagogical discussion of spinors can be found in\autocite{spinorspanner}. Some discussion of the topology of the Lorentz group can be found in Frankel section 19.3a\autocite{Frankel:2004}.
% % % \end{framed}
% % % \vspace{.5em}
% % 
% % % Actually, message is a bit subtler: projective representations
% % 
% % % As a sanity check, we can consider the invariants of each case. In $\mathbb M^4$,
% % % \begin{align}
% % %   |\mathbf x |^2 &= x_0^2 - x_1^2 - x_2^2 - x_3^2,
% % % \end{align}
% % % is invariant, using $\mathbf{\Lambda^T\eta\Lambda = \eta}$. In $SL(2,\mathbb C)$,
% % % \begin{align}
% % %   \det \mathbf{x} &= x_0^2 - x_1^2 - x_2^2 - x_3^2,
% % % \end{align}
% % % is invariant under $\mathbf x \rightarrow \mathbf{NxN}^\dag$ with $N\in SL(2,\mathbb C)$. 
% % 
% % % So we can construct a map from $SO(3,1)$ to $SL(2,\mathbb C)$, but what about the map from $SL(2,\mathbb C)$ back to $SO(3,1)$? One will note that the action of $\mathbf N$ and $-\mathbf{N} \in SL(2,\mathbb C)$ produce the \textit{same} Lorentz transformation
% % % 
% % % 
% % % , and hence it is not an isomorphism\footnote{See \Appendix \ref{chap:Poincar\'e} for a proof of this.}. Thus one would miss... only look at representations of $SO(3,1)$, and not $SL(2,\mathbb C)$, you'll be missing something.
% % 
% % 
% % % So we can construct a map from $SO(3,1)$ to $SL(2,\mathbb C)$, but it turns out that the map from $SL(2,\mathbb C)$ back to $SO(3,1)$ is 2-to-1, and hence it is not an isomorphism\footnote{See \Appendix \ref{chap:Poincar\'e} for a proof of this.}. Thus one would miss... only look at representations of $SO(3,1)$, and not $SL(2,\mathbb C)$, you'll be missing something.
% % 

\subsubsection{Lorentz representations are non-unitary and non-compact}\label{sec:SUSYalg:nonunitary}
% % 
% % % See Ryder P.40
% % 
If you weren't vigilant you might have missed a potential deal-breaker. We mentioned briefly that the representations of the Lorentz group are not unitary. The generators of boosts are imaginary. This makes them \textit{anti-unitary} rather than unitary. From the point of view of quantum mechanics this is the kiss of death since we know that only \textit{unitary} representations preserve probability. Things aren't looking so rosy anymore, are they? 

Where does this non-unitarity come from?\sidenote{Maybe we can fix it?} It all comes from the factor of $i$ associated with boosts. Just look at (\ref{eq:SUSYalg:Ai}) and (\ref{eq:SUSYalg:Bi}). This factor of $i$ is crucial since is is related to the non-compactness of the Lorentz group. This is a very intuitive statement: rotations are compact since the rotation parameter lives on a circle ($\theta=0$ and $\theta=2\pi$ are identified) while boosts are non-compact since the rapidity can take on any value along the real line. The dreaded factor of $i$, then, is deeply connected to the structure of the group. In fact, it's precisely the difference between $SO(3,1)$ and $SO(4)$, i.e.\ the difference between space and time: a minus sign in the metric. To make the situation look even more grim, even if we were able to finagle a way out of the non-unitarity issue (and we can't), there is a theorem that unitary representations of non-compact groups are infinite-dimensional. There is nothing infinite-dimensional about the particles we hope to describe with the Lorentz group. This is looking like quite a pickle!

Great---what do we do now? Up until now we'd been thinking about representations of the Lorentz group as if they would properly describe particles. Have we been wasting our time looking at representations of the Lorentz group? No; fortunately not---but we'll have to wait until we examine the representations of this group before we properly resolve this apparent problem. The key, however, is that one must look at \textit{full} Poincar\'e group (incorporating translations as well as Lorentz transformations) to develop a consistent picture. Adding the translation generator $P$ to the algebra surprisingly turns out to cure the ills of non-unitarity (i.e. of non-compactness). The cost for these features, as mentioned above, is that the representations will become infinite dimensional, but this infinite dimensionality is well-understood physically: we can boost into any of a continuum of frames where the particle has arbitrarily boosted four-momentum. %In fact, we'll even find a sensible way to work with \textit{finite} dimensional reps rather than the \textit{infinite} dimensional reps that one would expect form the Lorentz group alone.

This is why most treatments of this subject don't make a big deal about the Lorentz group not being satisfactory for particle representations. They actually end up being rather useful for describing \textit{fields}, where the non-unitarity of the Lorentz representations isn't a problem because the actual states in the quantum Hilbert space are the \textit{particles} which are representations of the full Poincar\'e group. %We will go over this in more detail in Section \ref{eq:SUSYreps:unitarity}. 

For now our strategy will be to sweep any concerns about unitarity under the rug and continue to learn more about representations of the Lorentz group. We will then get back to the matter at hand and settle the present issues by working with representations of the Poincar\'e group. The take-home message, however, is that it is not sufficient to just have the Lorentz group; nature really needs the full Poincar\'e group to make sense of itself. This principle of extending symmetries is a motivation for studying supersymmetry and extra dimensions, and indeed has been a guiding principle for particle physics over the past three decades. 
% % 

% \subsubsection{Spinors: the fundamental representation of $SL(2,\mathbb{C})$}
\subsubsection{\texorpdfstring{Spinors: the fundamental representation of $SL(2,\mathbb{C})$}{Spinors: the fundamental representation of SL(2,C)}}
\label{sec:susyalg:repsofsl2c}

The representations of the universal cover of the Lorentz group, $SL(2,\mathbb C)$, are spinors. Most standard quantum field theory texts do calculations in terms of four-component Dirac spinors. This has the benefit of representing all the degrees of freedom of a typical Standard Model massive fermion into a single object.\sidenote{In supersymmetry, on the other hand, it will turn out to be natural to work with two-component spinors.  For example, a complex scalar field has two real degrees of freedom. In order to have a supersymmetry between complex scalars and fermions, we require that the number of degrees of freedom match for both types of object. A Dirac spinor, however, has four real degrees of freedom ($2 \times$ (4 complex degrees of freedom) $-$ 4 from the Dirac equation). Weyl spinors, of course, have just the right number of degrees of freedom.} Remember that the Standard Model is a \textit{chiral} theory which already is most naturally written in terms of Weyl spinors---that's why the Standard Model Feynman rules in Dirac notation always end up with ugly factors of $\frac{1}{2}(\mathbbm{1}\pm\gamma^5)$.  A comprehensive guide review of two-component spinors can be found in Dreiner et al.~\autocite{Dreiner:2008tw}.

Let us start by defining the \textbf{fundamental}\index{SL(2,C)@$SL(2,\mathbb C)$!fundamental representation} and \textbf{conjugate}\index{SL(2,C)@$SL(2,\mathbb C)$!conjugate representation} (or \textbf{antifundamental}) representations of $SL(2,\mathbb C)$. These are just the matrices $N_\alpha^{\phantom\alpha\beta}$ and $(N^*)_{\dot\alpha}^{\phantom\alpha\dot\beta}$. Don't be startled by the dots on the indices, they're just a book-keeping device to keep the fundamental and the conjugate indices from getting mixed up. One cannot contract a dotted with an undotted $SL(2,\mathbb C)$ index; this would be like trying to contract spinor indices ($\alpha$ or $\dot\alpha$) with vector indices ($\mu$): they index two totally different representations.\sidenote{This doesn't mean that we can't swap between different types of indices. In fact, this is exactly what we did in \eqref{eq:susyalg:vectorrep} and \eqref{eq:susyalg:sl2crep}. We will get to the role of the $\sigma$ matrices very shortly.}

We are particularly interested in the objects that these matrices act on. Let us thus define \textbf{left-handed Weyl spinors}, $\psi$, as those acted upon by the fundamental rep and \textbf{right-handed Weyl spinors}, $\overline\chi$, as those that are acted upon by the conjugate rep. Again, do not be startled with the extra jewelry that our spinors display. The bar on the right-handed spinor just serves to distinguish it from the left-handed spinor. To be clear, they're both spinors, but they're different types of spinors that have different types of indices and that transform under different representations of $SL(2,\mathbb C)$. Explicitly,
\begin{align}
    \psi'_\alpha &= N_\alpha^{\phantom\alpha\beta} \psi_\beta \\
    \overline\chi'_{\dot{\alpha}} &= \left(N^*\right)_{\dot{\alpha}}^{\phantom{\dot{\alpha}}\dot{\beta}}\overline\chi_{\dot{\beta}}.    
\end{align}



\subsection{Invariant Tensors} % See Aitchison

We know that $\eta_{\mu\nu}$ is invariant under $SO(3,1)$ and can be used (along with the inverse metric) to raise and lower $SO(3,1)$ indices. For $SL(2,\mathbb{C})$, we can build an analogous tensor, the unimodular antisymmetric tensor\index{antisymmetric tensor}
\begin{align}
    \epsilon^{\alpha\beta} %&= i(\sigma^{2})_{\alpha\beta}\\
    &= \begin{pmatrix}
        0 \quad& 1 \\
        -1 \quad& 0
    \end{pmatrix}.\label{eq:SUSYalg:epsilonupper}
\end{align}
Unimodularity (unit determinant) and antisymmetry uniquely define the above form
up to an overall sign. The choice of sign ($\epsilon^{12}=1$) is a convention. As a mnemonic, $\epsilon^{\alpha\beta}=i\left(\sigma^2\right)_{\alpha\beta}$, but note that this is not a formal equality since we will see below that the index structure on the $\sigma^2$ is incorrect. %\footnote{The convention is often summarized as $\epsilon^{12}=1$, with all other elements coming from antisymmetry. We prefer using a definition in terms of $i\sigma^2$ since honest physics students know the $\sigma$ matrices by heart. It is important to emphasize, however, that $\epsilon_{\alpha\beta}=i(\sigma^\mu)_{\alpha\beta}$ is a \textit{matrix} relation--the index structures on the left- and right-hand sides do not match.}.
 This tensor is invariant under $SL(2,\mathbb C)$ since
\begin{align}
    \epsilon'^{\alpha\beta} = \epsilon^{\rho\sigma}N_\rho^{\phantom{\rho}\alpha}N_\sigma^{\phantom\sigma\beta}
    =\epsilon^{\alpha\beta}\det N
    = \epsilon^{\alpha\beta}.
\end{align}
We can now use this tensor to raise undotted $SL(2\mathbb{C})$ indices:
\begin{align}
    \psi^\alpha &\equiv \epsilon^{\alpha\beta}\psi_\beta.
\end{align}
To lower indices we can use an analogous unimodular antisymmetric tensor with two lower indices.
For consistency, the overall sign of the lowered-indices tensor must be defined as
\begin{align}
    \epsilon_{\alpha\beta} &= -\epsilon^{\alpha\beta},
\end{align}
so that raising and then lowering returns us to our original spinor:
\begin{align}
    \epsilon_{\alpha\beta}\epsilon^{\beta\gamma} &= \delta^\gamma_\alpha.
\end{align}
This is to ensure that the upper- and lower-index tensors are inverses, i.e. so that the combined operation of raising then lowering an index does not introduce a sign.
%
Dotted indices indicate the complex conjugate representation, $\epsilon_{\alpha\beta}^{*} = \epsilon_{\dot\alpha\dot\beta}$. Since $\epsilon$ is real we thus use the same sign convention for dotted indices as undotted indices,
\begin{align}
    \epsilon^{\dot 1 \dot 2} = \epsilon^{12} = - \epsilon_{\dot 1 \dot 2} = - \epsilon_{12}.
\end{align}
%
We may raise dotted indices in exactly the same way:
\begin{align}
    \overline\chi^{\dot\alpha} &\equiv \epsilon^{\dot \alpha \dot \beta}\overline\chi_{\dot\beta}.
\end{align}
In order to avoid sign errors, it is a useful mnemonic to always put the $\epsilon$ tensor directly to the left of the spinor whose indices it is manipulating, this way the index closest to the spinor contracts with the spinor index. In other words, one needs to be careful since  $\epsilon^{\alpha\beta}\psi_\beta \neq \psi_\beta\epsilon^{\beta\alpha}$.
%

In summary:
\begin{align}
    \psi^\alpha &= \epsilon^{\alpha\beta}\psi_\beta & \psi_\alpha &= \epsilon_{\alpha\beta}\psi^\beta & \overline\chi^\alpha &= \epsilon^{\dot\alpha\dot\beta}\psi_{\dot\beta} & \overline\chi_{\dot\alpha} &= \epsilon_{\dot\alpha\dot\beta}\overline\chi^{\dot\beta}.
\end{align}


\subsection{Contravariant representations}
Now that we're familiar with the $\epsilon$ tensor, we should tie up a loose end from Section \ref{sec:susyalg:repsofsl2c}. There we introduced the fundamental and conjugate representations of $SL(2,\mathbb{C})$. What happened to the \textbf{contravariant} representations that transform under the inverse matrices $N^{-1}$ and $N^{*-1}$? For a general group, e.g. $GL(N,\mathbb{C})$, these are unique representations so that we have a total of four different reps for a given group.
%
% Let us make another parenthetical note that we may also form \textbf{contravariant} representations of $SL(2,\mathbb C)$ using the inverse matrices $N^{-1}$ and $N^{*-1}$,
% \begin{align}
%   \psi'^\alpha &= \psi^\beta(N^{-1})_\beta^{\phantom\beta\alpha}\\
%   \overline{\chi}'^{\dot{\alpha}} &= \overline{\chi}^{\dot{\beta}}(N^{*-1})_{\dot{\beta}}^{\phantom{\dot{\beta}}\dot{\alpha}}.
% \end{align}

It turns out that for $SL(2,\mathbb{C})$ these contravariant representations are equivalent (in the group theoretical sense) to the fundamental and conjugate representations presented above. Using the antisymmetric tensor $\epsilon_{\alpha\beta}$ ($\epsilon^{12}=1$) and the unimodularity of $N\in SL(2,\mathbb C)$,
\begin{align}
    \epsilon_{\alpha\beta}N^\alpha_{\phantom\alpha\gamma}N^\beta_{\phantom\beta\delta} &= \epsilon_{\gamma\delta}\det N\\
    \epsilon_{\alpha\beta}N^\alpha_{\phantom\alpha\gamma}N^\beta_{\phantom\beta\delta} &= \epsilon_{\gamma\delta}\\
    \left(N^T\right)_{\gamma}^{\phantom\gamma\alpha}\epsilon_{\alpha\beta}N^\beta_{\phantom\beta\delta} &= \epsilon_{\gamma\delta}\\
    \epsilon_{\alpha\beta}N^\beta_{\phantom\beta\delta} &= \left[\left(N^T\right)^{-1}\right]_{\alpha}^{\phantom\alpha\gamma}\epsilon_{\gamma\delta}
\end{align}
% See page 419 of Binetruy, eq (B.3)
%
And hence by Schur's Lemma $N$ and $(N^T)^{-1}$ are equivalent. Similarly, $N^*$ and $(N^\dag)^{-1}$ are equivalent. This is not surprising, of course, since we already knew that the antisymmetric tensor, $\epsilon$, is used to raise and lower indices in $SL(2,\mathbb C)$. Thus the equivalence of these representations is no more `surprising' than the fact that Lorentz vectors with upper indices are equivalent to Lorentz vectors with lower indices. Explicitly, then, the contravariant representations\index{SL(2,C)@$SL(2,\mathbb C)$!contravariant representations} transform as
\begin{align}
    \psi'^\alpha &= \psi^\beta(N^{-1})_\beta^{\phantom\beta\alpha}\\
    \overline{\chi}'^{\dot{\alpha}} &= \overline{\chi}^{\dot{\beta}}(N^{*-1})_{\dot{\beta}}^{\phantom{\dot{\beta}}\dot{\alpha}}.
\end{align}

% To summarize, our two-component spinor representations are
% \begin{align}
%   \psi'_\alpha &= N_\alpha^{\phantom\alpha\beta}\psi_\beta\label{eq:SUSYalg:reps:1}\\
%   \overline\chi'_{\dot\alpha} &= (N^*)_{\dot\alpha}^{\phantom\alpha\dot\beta}\overline\chi_{\dot\beta}\label{eq:SUSYalg:reps:2}\\
%   \psi'^\alpha &= \psi^\beta(N^{-1})_\beta^{\phantom\beta\alpha}\label{eq:SUSYalg:reps:3}\\
%   \overline\chi'^{\dot\alpha} &= \overline\chi^{\dot\beta}(N^{*-1})_{\dot\beta}^{\phantom\beta\dot\alpha}.\label{eq:SUSYalg:reps:4}
% \end{align}
% Occasionally one will see s (\ref{eq:SUSYalg:reps:2}) and (\ref{eq:SUSYalg:reps:4}) written in terms of Hermitian conjugates,
% \begin{align}
%   \overline\chi'_{\dot\alpha} &= \overline\chi_{\dot\beta}(N^\dag)_{\phantom\beta\dot\alpha}^{\dot\beta}\label{eq:SUSYalg:reps:2p}\\
%   \overline\chi'^{\dot\alpha} &= (N^{\dag-1})_{\phantom\alpha\dot\beta}^{\dot\alpha}\overline\chi^{\dot\beta}.\label{eq:SUSYalg:reps:4p}
% \end{align}
% %= \quad \overline\chi_{\dot\beta}(N^\dag)^{\dot\beta}_{\phantom\beta\dot\alpha}
% We will not advocate this notation, however, since Hermitian conjugates are a bit delicate notationally in quantum field theories.

Let us summarize the different representations for $SL(2,\mathbb{C})$,

\begin{center}
    \begin{tabular}{|lll|}
        \hline
        \textbf{Representation} & \textbf{Index Structure} & \textbf{Transformation}\\
        \hline
        Fundamental & Lower & $\psi'_\alpha = N_\alpha^{\phantom\alpha\beta}\psi_\beta$\\
        Conjugate & Lower dotted & $\overline\chi'_{\dot\alpha} = (N^*)_{\dot\alpha}^{\phantom\alpha\dot\beta}\overline\chi_{\dot\beta}$\\
        Contravariant & Upper & $   \psi'^\alpha = \psi^\beta(N^{-1})_\beta^{\phantom\beta\alpha}$\\
        Contra-conjugate & Upper dotted & $\overline\chi'^{\dot\alpha} = \overline\chi^{\dot\beta}(N^{*-1})_{\dot\beta}^{\phantom\beta\dot\alpha}$\\
        \hline
    \end{tabular}.  
\end{center}
Occasionally one will see the conjugate and contravariant-conjugate transformations written in terms of Hermitian conjugates,
\begin{align}
    \overline\chi'_{\dot\alpha} &= \overline\chi_{\dot\beta}(N^\dag)_{\phantom\beta\dot\alpha}^{\dot\beta}\label{eq:SUSYalg:reps:2p}\\
    \overline\chi'^{\dot\alpha} &= (N^{\dag-1})_{\phantom\alpha\dot\beta}^{\dot\alpha}\overline\chi^{\dot\beta}.\label{eq:SUSYalg:reps:4p}
\end{align}
%= \quad \overline\chi_{\dot\beta}(N^\dag)^{\dot\beta}_{\phantom\beta\dot\alpha}
We will not advocate this notation, however, since Hermitian conjugates are a bit delicate notationally in quantum field theories. For more details about the representations of $SL(2,\mathbbm{C})$, see the appendix of Wess and Bagger\autocite{Wess:1992cp}.
\begin{example}[Equivalent representations]
We stated before that the fundamental, conjugate, contravariant, and contravariant-conjugate representations of $GL(N,C)$ are generally not equivalent. We've seen that for $SL(2,\mathbb{C})$ this is not true, and there are only two unique representations. Another example is $U(N)$, for which $U^\dag = U^{-1}$ and $U^{\dag-1} = U$. Thus, unlike $SL(2,\mathbb{C})$ where the upper- and lower-index representations are equivalent, for $U(N)$ the dotted- and undotted-index representations are equivalent.
\end{example}
Note that there are different conventions for the index height, but the point is that the upper and lower index objects are equivalent due to the $\epsilon$ tensor. We can see this in a different way by looking at tensor structures. %For matrices $N$ in $SL(N,\mathbb{C})$ we have $\det N = 1$.


\subsection{Stars and Daggers}\label{sec:SUSYalg:starsanddaggers}


Let us take a pause from our main narrative to clarify some notation. When dealing with \textit{classical} fields, the complex conjugate representation is the usual complex conjugate of the field; i.e. $\psi \rightarrow \psi^*$. When dealing with \textit{quantum} fields, on the other hand, it is conventional to write a Hermitian conjugate; i.e. $\psi \rightarrow \psi^\dag$. This is because the quantum field contains creation and annihilation \textit{operators}. The Hermitian conjugate here is the quantum version of complex conjugation. (We'll explain this statement below.)

This is the same reason why Lagrangians are often written $\mathcal L =$ term $+\; \text{h.c.}$ 
%
In classical physics, the Lagrangian is a scalar quantity so one would expect that one could have just written `c.c.' (complex conjugate) rather than `h.c.' (Hermitian conjugate). In QFT, however, the fields in the Lagrangian are operators that must be Hermitian conjugated.
% % %
% % 
% % \noindent
 When taking a first general relativity course, some students develop a very bad habit: they think of lower-index objects as row vectors and upper-index objects as column vectors, so that
\begin{align}
    V_\mu W^\mu &= \begin{pmatrix}
        V_0 & V_1 & V_2 & V_3
    \end{pmatrix}\cdot
    \begin{pmatrix}
        W^0 \\ W^1 \\ W^2 \\ W^3
    \end{pmatrix}.
\end{align}
Thus they think of the covariant vector as somehow a `transpose' of contravariant vectors. This is is a bad, bad, \textit{bad} habit and those students must pay their penance when they work with spinors. In addition to confusion generated from the antisymmetry of the metric and the anticommutation relations of the spinors, such students become confused when reading an expression like $\psi_\alpha^\dag$ because they interpret this as 
\begin{align}
    \psi_\alpha^\dag \stackrel{?}{=} (\psi_\alpha^*)^T = (\overline\psi_{\dot\alpha})^T \stackrel{?}{=} \overline\psi^{\dot\alpha}
\end{align}
\textit{Wrong! Fail! Go directly to jail, do not pass go!}
The dagger ($^\dag$) on the $\psi$ acts \textit{only} on the quantum operators in the field $\psi$, it doesn't know and doesn't care about the Lorentz index. Said once again, with emphasis: \textit{There is no transpose in the quantum Hermitian conjugate!}

To be safe, one could always write the Hermitian conjugate since this is `technically' always correct. The meaning, however, is not always clear. Hermitian conjugation is always defined with respect to an inner product. Anyone who shows you a Hermitian conjugate without an accompanying inner product might as well be selling you a used car with no engine. 

In matrix quantum theory the inner product comes with the appropriate Hilbert space. This is what is usually assumed when you see a dagger in QFT. In quantum wave mechanics, on the other hand, the Hermitian conjugate is defined with respect to the $L^2$ inner product,
\begin{align}
    \langle f,g \rangle &= \int dx\, f^*(x)\,g(x),
\end{align}
so that its action on fields is just complex conjugation. The structure of the inner product still manifests itself, though. Due to integration by parts, the Hermitian conjugate of the derivative is non-trivial,
\begin{align}
    \left(\frac{\partial}{\partial x}\right)^\dag &= -\frac{\partial}{\partial x}.
\end{align}
As you know very well we're really just looking at different aspects of the same physics.
\begin{example}[Not-so-obvious inner products]
It may seem like we're beating a dead undergrad with a stick with all this talk of the canonical inner product. However, in spaces with boundaries---such as the Randall-Sundrum model of a warped extra dimension---the choice of an inner product can be non-trivial. In order for certain operators to be Hermitian (e.g. so that physical masses are non-negative),  functional inner products have to be modified. This changes the expansion of a function (e.g. a wavefunction) in terms of an `orthonormal basis.'
\end{example}

The relevant inner product depends on the particular representation one is dealing with. 
% In Section \ref{chap:SUSYreps} we'll discuss representations of supersymmetry on the space of one-particle states. 
In one-particle representations of symmetry, the inner product is the usual bracket for linear matrix\sidenote{We say `matrix' because the one-particle state space is finite-dimensional so we could actually write our operators explicitly as matrices. This doesn't actually provide much insight and we won't do this, but the terminology is helpful to distinguish between the superspace picture where the operators are differential operators.} operators on the finite dimensional space of states in a supersymmetirc multiplet and we can think of daggers as usual for quantum mechanics operators (e.g. turning raising and lowering operators into each other). That gives  some insight about the particle content in supersymmetry, but one doesn't really see the field theory come through until one works with `superspace' upon wich `superfields' propagate. In this case we'll use the appropriate generalization of the $L^2$ inner product for the infinite dimensional space of functions on superspace. The operators in the superspace picture will no longer be matrix operators but differential operators which one must be careful keeping track of minus signs from integration-by-parts upon Hermitian conjugation.

It is worth making one further note about notation. Sometimes authors will write
\begin{align}
    \overline\psi_{\dot\alpha} &= \psi^\dag_\alpha.
\end{align}
This is technically correct, but it can be a bit misleading since one shouldn't get into the habit of thinking of the bar as some kind of operator. The bar and its dotted index are notation to distinguish the right-handed representation from the left-handed representation. The content of the above equation is the statement that the conjugate of a left-handed spinor transforms as a right-handed spinor.

If none of that made any sense, then you should take a deep breath, pretend you didn't read any of this, and continue to the next subsection. It be clear when we start making use of these ideas in proper context.

\subsection{Tensor representations}

% \vspace{.5em}
% \begin{framed}
%   \noindent\textbf{A note on tensor representations}. 
Now that we've said a few things about raised/lowered and dotted/undotted indices, it's worth repeating the mantra of tensor representations of Lie groups: \textit{symmetrize, antisymmetrize, and trace} (see, for example, Section 4.3 of Cheng and Li \cite{chengandli}). Let's recall the familiar $SU(N)$ case. We can write down tensor representations by just writing out the appropriate indices, e.g. if $\psi^a \to U^a_{\phantom a b}\psi^b$ and $\psi_a \to U^{\dag\phantom a b}_{\phantom\dag a}\psi_b$, then we can write an $(n,m)$-tensor $\Psi$ and its transformation as
    \begin{align}
        \Psi^{i_1\cdots i_m}_{\phantom{i_1\cdots i_m}j_1\cdots j_m} \to U^{i_1}_{\phantom{i_1}i'_1}\cdots U^{i_n}_{\phantom{i_n}i'_n} U^{\dag\phantom{j_1} j'_1}_{\phantom\dag j_1}\cdots U^{\dag\phantom{j_m} j'_m}_{\phantom\dag j_m} \Psi^{i'_1\cdots i'_m}_{\phantom{i'_1\cdots i'_m}j'_1\cdots j'_m}.
    \end{align} 
This, however, is not generally an irreducible representation. In order to find the irreps, we can make use of the fact that tensors of symmetrized/antisymmetrized indices don't mix under the matrix symmetry group. For $U(N)$,
\begin{align}
    \Psi^{ij}\to \Psi'^{ij} &= U^i_{\phantom i k} U^j_{\phantom j \ell} \Psi^{k\ell}\\
    \Psi^{ji}\to \Psi'^{ji} &= U^j_{\phantom j \ell} U^i_{\phantom i k} \Psi^{\ell k}\\
    &= U^i_{\phantom i k} U^j_{\phantom j \ell} \Psi^{\ell k},
\end{align}
thus if $P(i,j)$ is the operator that swaps the indices $i \leftrightarrow j$, then $\Psi^{ij}$ and $\Psi^{ji} = P(i,j)\Psi^{ij}$ transform in the same way. In other words, $P(i,j)$ commutes with the matrices of $U(N)$, and hence we may construct simultaneous eigenstates of each. This means that the eigenstates of $P(i,j)$, i.e. symmetric and antisymmetric tensors, form invariant subspaces under $U(N)$. This argument is straightforwardly generalized to any matrix group and arbitrarily complicated index structures. Thus we may commit to memory an important lesson: we ought to symmetrize and antisymmetrize our tensor representations. 

%\noindent 
As with any good informercial, one can expect a ``but wait, there's more!'' deal to spice things up a little bit. Indeed, it turns our there are two more tricks we can invoke to further reduce our tensor reps. The first is taking the trace. For  $U(N)$ this is somewhat obvious once it's suggested: we know from basic linear algebra that the trace is invariant under unitary rotations; it is properly a scalar quantity. What this amounts to for a general tensor is taking the contraction of an upper index $i$ and lower index $j$ with the Kronecker delta, $\delta^j_i$. This is guaranteed to commute with the symmetry group because $\delta^j_i$ is invariant under $U(N)$. This is analogous to $\epsilon_{\alpha\beta}$ being an invariant tensor of $SL(2,\mathbb{C})$.

There's one more trick for $SU(N)$ (but not $U(N)$) which comes from another invariant tensor, $\epsilon_{i_1\cdots i_N}$. This is invariant under $SU(N)$ since
\begin{align}
    U_{i_1}^{i'_1}\cdots U_{i_N}^{i'_N} \epsilon_{i'_1\cdots i'_N} &= \det U \epsilon_{i_1\cdots i_N} = \epsilon_{i_1\cdots i_N}.
\end{align} 
Thus any time one has $N$ antisymmetric indices of an $U(N)$ tensor, one can go ahead and drop them. Just like that. 
Note that this is \textit{totally different} from the $\epsilon_{\alpha\beta}$ of $SL(2,\mathbb{C})$.

By now, the slightly more group theoretically savvy will have recognized the basic rules for $U(N)$ Young tableaux. This formalism further allows one to formulaically determine the dimension of a tensor representation and its decomposition into irreducible representations. Details for the $SU(N)$ Young tableaux are worked out in Cheng and Li \cite{chengandli}, with a more general discussion in any self-respecting representation theory text. 

% See Osborn

The points that one should take away from this, however, isn't the formalism of Young tableaux, but rather the `big picture' intuition of decomposing into irreducible tensors. In particular for $SL(2,\mathbb{C})$ the irreducible two-index $\epsilon$ tensor tells us that we can always reduce any tensorial representation into direct sums irreducible tensors which are symmetric in their dotted and (separately) undotted indices,
\begin{align}
    \Psi_{\alpha_1\cdots\alpha_{2n} \dot\alpha_1\cdots\dot\alpha_{2m}} = 
    \Psi_{(\alpha_1\cdots\alpha_{2n}) (\dot\alpha_1\cdots\dot\alpha_{2m})}.
\end{align}
%
We label such an irreducible tensor-of-spinor-indices with the $SO(3,1)$ notation ($n,m$). In this notation the fundamental left- ($\psi$) and right-handed ($\bar\chi$) spinors transform as ($\frac 12$,0) and (0,$\frac 12$) respectively. One might now want to consider how to reduce Poincar\'e tensor products following the analogous procedure that textbooks present for $SU(2)$. Recall that $SO(3)\cong SU(2)/\mathbbm{Z}_2$ so that such an analogy amounts to `promoting' $SO(3)$ to $SO(3,1)$. For further details see, e.g., Osborn's lecture notes\autocite{Osborn:Symmetries}.

\subsection{Lorentz-Invariant Spinor Products}

Armed with a metric to raise and lower indices, we can also define the inner product of spinors as the contraction of upper and lower indices. Note that in order for inner products to be Lorentz-invariant, one cannot contract dotted and undotted indices. 

There is a very nice short-hand that is commonly used in supersymmetry that allows us to drop contracted indices. Since it's important to distinguish between left- and right-handed Weyl spinors, we have to be careful that dropping indices doesn't introduce an ambiguity. This is why right-handed spinors are barred in addition to having dotted indices. Let us now define the contractions
\begin{align}
    \psi\chi &\equiv \psi^\alpha\chi_\alpha\label{eq:susyalg:undotted}\\
    \overline\psi\overline\chi &\equiv \overline\psi_{\dot\alpha}\overline\chi^{\dot\alpha}\label{eq:susyalg:dot}.
\end{align}
Note that the contractions are different for the left- and right-handed spinors. A useful mnemonic is to imagine swordsman who carries his/her sword along his waist. A right-handed swordsman would have his sword along his left leg so that he could easily unsheathe it by pulling up and to the right---just like the way the right-handed dotted Weyl spinor indices contract. Similarly, a left-handed swordsman would have his sword along his right leg so that he would unsheathe by pulling up and to the left.

This is a choice of convention such that
\begin{align}
    (\psi\chi)^\dag \equiv (\psi^\alpha\chi_\alpha)^\dag = \overline\chi_{\dot\alpha}\overline\psi^{\dot\alpha} \equiv \overline\chi\overline\psi = \overline\psi\overline\chi.
\end{align}
The second equality is worth explaining. Why is it that $(\psi^\alpha\chi_\alpha)^\dag = \overline\chi_{\dot\alpha}\overline\psi^{\dot\alpha}$? Recall from that the Hermitian conjugation acts on the creation and annihilation operators in the quantum fields $\psi$ and $\chi$. The Hermitian conjugate of the product of two Hermitian operators $AB$ is given by $B^\dag A^\dag$. The coefficients of these operators in the quantum fields are just $c$-numbers (`commuting' numbers), so the conjugate of $\psi^\alpha\chi_\alpha$ is $\left(\chi^\dag\right)_{\dot\alpha}\left(\psi^\dag\right)^{\dot\alpha}$.

% % %
Now let's get back to our contraction convention. Recall that quantum spinor fields are Grassmann, i.e. they anticommute. Thus we show that with our contraction convention, the order of the contracted fields don't matter:
\begin{align}
    \psi\chi = \psi^\alpha\chi_\alpha = -\psi_\alpha\chi^\alpha = \chi^\alpha\psi_\alpha = \chi\psi\label{eq:SUSYalg:contractions}\\
    \overline\psi\overline\chi = \overline\psi_{\dot\alpha}\overline\chi^{\dot\alpha}= -\overline\psi^{\dot\alpha}\overline\chi_{\dot\alpha} = \overline\chi_{\dot\alpha}\overline\psi^{\dot\alpha}=\overline\chi\overline\psi.\label{eq:SUSYalg:overlinecontractions}
\end{align} 

% SEE PAGE 39 of Aitchison ... this is rather cute, I might as well show things explicitly

% \emph{\textbf{FLIP:} Now we streamline notation a bit and say that an unindexed $\chi$ has a lower index and an unindexed $\psi$ has an upper index.}
% 
% We can now take inner products... now also we define unindexed spinors.
% 
% \begin{align}
%   \chi \psi &\equiv \chi^\alpha\psi_\alpha\\
%   &= \epsilon^{\alpha\beta}\epsilon_{\alpha\gamma}\chi_\beta\psi^\gamma\\
%   &= -\delta^\beta_{\phantom\beta\gamma}\chi_\beta\psi^\gamma\\
%   &= -\chi_\gamma\psi^\gamma\\
%   \overline\chi\overline\psi &\equiv \overline \chi_{\dot\alpha}\overline\psi^{\dot\alpha}\\
%   &= -\overline\chi^{\dot\alpha}\overline\psi_{\dot\alpha}
% \end{align}

It is actually rather important that quantum spinors anticommute. If the $\psi$ were \emph{commuting} objects, then
\begin{align}
    \psi^2 &= \psi\psi = \epsilon^{\alpha\beta}\psi_\beta\psi_\alpha = \psi_2\psi_1-\psi_1\psi_2 =0.
\end{align}
Thus we must have $\psi$ such that
\begin{align}
    \psi_1\psi_2 = -\psi_2\psi_1,
\end{align}
i.e. the components of the Weyl spinor must be Grassmann. 
So one way of understanding why spinors are anticommuting is that metric that raises and lowers the indices is antisymmetric. (We know, of course, that from another perspective this anticommutativity comes from the quantum creation and annihilation operators.)


\subsection{Vector-like Spinor Products}

Notice that the Pauli matrices give a natural way to go between $SO(3,1)$ and $SL(2,\mathbb C)$ indices. Using  (\ref{eq:SUSYalg:SL2C:Lorentz}),
\begin{align}
    (x_\mu\sigma^\mu)_{\alpha\dot\alpha} &\rightarrow N_\alpha^{\phantom\alpha\beta}(x_\nu\sigma^\nu)_{\beta\dot\gamma}N^{*\phantom{\dot\alpha}\dot\gamma}_{\phantom *\dot\alpha}\\
    &= (\Lambda_\mu^{\phantom\mu\nu}x_\nu)\sigma^\mu_{\phantom\mu\alpha\dot\alpha}.
\end{align}
Then we have
\begin{align}
    (\sigma^\mu)_{\alpha\dot\alpha} &= N_\alpha^{\phantom\alpha\beta}(\sigma^\nu)_{\beta\dot\gamma}(\Lambda^{-1})^\mu_{\phantom\mu\nu}N^{*\phantom{\dot\alpha}\dot\gamma}_{\phantom*\dot\alpha}.
\end{align}
One could, for example, swap between the vector and spinor indices by writing
\begin{align}
    V_\mu & \rightarrow V_{\alpha\dot\beta} \equiv V_\mu (\sigma^\mu)_{\alpha\dot\beta}.\label{eq:SUSYalg:vecspinor}
\end{align} 
We can define a `raised index' $\sigma$ matrix,
\begin{align}
    (\overline\sigma^\mu)^{\dot\alpha\alpha} &\equiv \epsilon^{\alpha\beta}\epsilon^{\dot\alpha\dot\beta}(\sigma^\mu)_{\beta\dot\beta}\label{eq:SUSYalg:sigmamu}\\
%   &= (\sigma^\mu)^\dag\\
    &= (\mathbbm 1, -{\mathbf{\sigma}}).\label{eq:SUSYalg:sigma-bar}
\end{align}
Note the bar and the reversed order of the dotted and undotted indices. The bar is just notation to indicate the index structure, similarly to the bars on the right-handed spinors. 

Now an important question: How do we understand the indices? Why do we know that the un-barred Pauli matrices have lower indices $\alpha\dot\alpha$ while the barred Pauli matrices have upper indices $\dot\alpha\alpha$? Clearly this allows us to maintain our convention about how indices contract, but some further checks might help clarify the matter. Let us go back to the matrix form of the Pauli matrices (\ref{eq:SUSYalg:pauli:matrices}) and the upper-indices epsilon tensor (\ref{eq:SUSYalg:epsilonupper}). One may use $\epsilon = i\sigma^2$ and to directly verify that 
\begin{align}
    \epsilon\overline\sigma_\mu &= \sigma_\mu^T\epsilon,
\end{align}
and hence
\begin{align}
    \overline\sigma_\mu &= \epsilon\sigma_\mu^T\epsilon^T.
\end{align}
Now let us write these in terms of dot-less indices---i.e. write all indices without dots, whether or not they ought to have dots---then we can restore the indices later to see how they turn out. To avoid confusion we'll write dot-less indices with lowercase Roman letters $\alpha,\beta,\gamma,\delta \rightarrow a,b,c,d$.
\begin{align}
    (\overline \sigma^\mu)^{ad} &= \epsilon^{ab}(\sigma^{\mu T})_{bc}(\epsilon^T)^{cd}\\
    &= \epsilon^{ab}(\sigma^\mu)_{cb} \epsilon^{dc}\\
    &= \epsilon^{ab}\epsilon^{dc}(\sigma^\mu)_{cb}.
\end{align}
We already know what the dot structure of the $\sigma^\mu$ is, so we may go ahead and convert to the dotted/undotted lowercase Greek indices. Thus $c,b \rightarrow \gamma,\dot\beta$. Further, we know that the $\epsilon$s carry only one type of index, so that $a,d \rightarrow \dot\alpha,\delta$. 
% Restoring indices on the right-hand side,
% \begin{align}
%    \epsilon\sigma_\mu^T\epsilon^T  &\rightarrow \epsilon^{\alpha\beta}(\sigma^{\mu T})_{\beta\dot\beta}(\epsilon^T)^{\dot\beta\dot\alpha}\\
%   &\rightarrow \epsilon^{\alpha\beta}\epsilon^{\dot\alpha\dot\beta}(\sigma^{\mu})_{\dot\beta\beta}.
% \end{align}
%We'll get to this in \subsection \ref{sec:SUSYalg:sec:chirality}.
Thus we see that the $\overline\sigma^\mu$ have a dotted-then-undotted index structure. A further consistency check comes from looking at the structure of the $\gamma$ matrices as applied to the Dirac spinors formed using Weyl spinors with our index convention. %We do this in Section \ref{sec:SUSYalg:sec:chirality}. 




\subsection{\texorpdfstring{Generators of $SL(2,\mathbb{C})$}{Generators of SL(2,C)}}


How do Lorentz transformations act on Weyl spinors? We should already have a hint from the generators of Lorentz transformations on Dirac spinors. (Go ahead and review this subsection of your favorite QFT textbook.) The objects that obey the Lorentz algebra,  (\ref{eq:SUSYalg:Poincar\'e:alg:1}), and generate the desired transformations are given by the matrices,
\begin{align}
    (\sigma^{\mu\nu})_\alpha^{\phantom\alpha\beta} &= \frac i4(\sigma^\mu\overline\sigma^\nu-\sigma^\nu\overline\sigma^\mu)_\alpha^{\phantom\alpha\beta}\label{eq:SUSYalg:sigmamunu}\\
    (\overline\sigma^{\mu\nu})^{\dot\alpha}_{\phantom{\dot\alpha}\dot\beta} &= \frac i4 (\overline \sigma^\mu\sigma^\nu - \overline\sigma^\nu\sigma^\mu)^{\dot\alpha}_{\phantom{\dot\alpha}\dot\beta}\label{eq:SUSYalg:sigmabarmunu}.
\end{align}
It is important to note that these matrices are Hermitian. (Some sources will define these to be anti-Hermitian, see below.) The assignment of dotted and undotted indices are deliberate; they tell us which generator corresponds to the fundamental versus the conjugate representation. The choice of \emph{which} one is fundamental versus conjugate, of course, is arbitrary. 
Thus the left and right-handed Weyl spinors transform as
\begin{align}
    \psi_\alpha &\rightarrow \left(e^{-\frac i2 \omega_{\mu\nu}\sigma^{\mu\nu}}\right)_\alpha^{\phantom\alpha\beta}\psi_\beta\label{eq:SUSYalg:alphatransform}\\
    \overline\chi^{\dot\alpha} &\rightarrow \left(e^{-\frac i2 \omega_{\mu\nu}\overline\sigma^{\mu\nu}}\right)^{\dot\alpha}_{\phantom\alpha\dot\beta}\overline\chi^{\dot\beta}.\label{eq:SUSYalg:alphadottransform}
\end{align}


\begin{example}[Factors of $i$] Oh boy.
\begin{quote}
``In the kingdom of the blind, the one-$i$'d man is king,'' D.\ Erasmus.
\end{quote}
% 
Some standard references (such as Bailin \& Love\footnotemark) define $\sigma^{\mu\nu}$ and $\overline\sigma^{\mu\nu}$ without the leading factor of $i$. Their spinor transformations thus also lack the $(-i)$ in the exponential so that the actual quantity being exponentiated is the same in either convention. As much as it pains me---and it will certainly pain \textit{you} even more---to differ from `standard notation', we will be adamant about our choice since only then do our Lorentz transformations take the usual format for exponentiating Lie algebras:
    \begin{align}
        e^{i\cdot(\mathbb R\,\text{Transformation Parameter})\cdot(\text{Hermitian Generator})}.
    \end{align} 
Thus propriety demands that we define \textit{Hermitian} $\sigma^{\mu\nu}$ as in  (\ref{eq:SUSYalg:sigmabarmunu}), even if this means having a slightly different algebra from Bailin \& Love. This will be very important when using the Fierz identities
\end{example}\footnotetext{\cite{Bailin:1994qt}}

We can invoke the $SU(2)\times SU(2)$ representation (and we use that word \emph{very} loosely) of the Lorentz group from (\ref{eq:Poincar\'e:J}) and (\ref{eq:Poincar\'e:K}) to write the left-handed $\sigma^{\mu\nu}$ generators as
\begin{align}
    J_i &= \frac 12 \epsilon_{ijk}\sigma_{jk} = \frac 12 \sigma_i\label{eq:SUSYalg:Jpauli}\\
    K_i &= \sigma_{0i} = -\frac i2 \sigma_i.\label{eq:SUSYalg:Kpauli}
\end{align}
One then finds
\begin{align}
    A_i &= \frac 12 (J_i+iK_i) = \frac 12 \sigma_i\\
    B_i &= \frac 12 (J_i - iK_i) = 0.
\end{align}
Thus the left-handed Weyl spinors $\psi_\alpha$ are $(\frac 12, 0)$ spinor representations Similarly, one finds that the right-handed Weyl spinors $\overline \chi^{\dot\alpha}$ are $(0,\frac 12)$ spinor representations.

Alternately, we could have \textit{guessed} the generators of the Lorentz group acting on Weyl spinors from the algebra of rotations and boosts in (\ref{eq:SUSYalg:JJ}) -- (\ref{eq:SUSYalg:JK}). With a modicum of cleverness one could have made the ansatz that the $\mathbf J$ and $\mathbf K$ are represented on Weyl spinors via (\ref{eq:SUSYalg:Jpauli}) and (\ref{eq:SUSYalg:Kpauli}). From this one could exponentiate to derive a finite Lorentz transformation,
\begin{align}
    \exp\left({\frac i2 \vec\sigma\cdot\vec\theta \pm \frac 12 \vec\sigma\cdot\vec\phi}\right) &= \exp\left({i\frac 12 \vec\sigma\cdot(\vec\theta \mp i\vec\phi)}\right),
\end{align}
where the upper sign refers to left-handed spinors while the lower sign refers to right-handed spinors. $\vec \theta$ and $\vec \phi$ are the parameters of rotations and boosts, respectively. One can then calculate the values of $\sigma^{0i}$ and $\sigma^{ij}$ to confirm that they indeed match the above expression.

Alternately, we could have \textit{guessed} the generators of the Lorentz group acting on Weyl spinors from the algebra of rotations and boosts in \eqref{eq:SUSYalg:JJ} -- \eqref{eq:SUSYalg:JK}. With a modicum of cleverness one could have made the ansatz that the $\mathbf J$ and $\mathbf K$ are represented on Weyl spinors via (\ref{eq:SUSYalg:Jpauli}) and (\ref{eq:SUSYalg:Kpauli}). From this one could exponentiate to derive a finite Lorentz transformation,
\begin{align}
    \exp\left({\frac i2 \vec\sigma\cdot\vec\theta \pm \frac 12 \vec\sigma\cdot\vec\phi}\right) &= \exp\left({i\frac 12 \vec\sigma\cdot(\vec\theta \mp i\vec\phi)}\right),
\end{align}
where the upper sign refers to left-handed spinors while the lower sign refers to right-handed spinors. $\vec \theta$ and $\vec \phi$ are the parameters of rotations and boosts, respectively. One can then calculate the values of $\sigma^{0i}$ and $\sigma^{ij}$ to confirm that they indeed match the above expression.

\begin{example}
    \noindent\textbf{Representations of the Lorentz group.} %
    % From Peskin, Weinberg
    It is worth making an aside about the representations of the Lorentz group since there is a nice point that is often glossed over during one's first QFT course; see, for example, subsection 3.2 of Peskin\autocite{Peskin:1995ev}. Dirac's trick for finding $n$-dimensional representations of the Lorentz generators was to postulate the existence of $n\times n$ matrices $\gamma^\mu$ that satisfy the Clifford algebra,
    \begin{align}
        \{\gamma^\mu,\gamma^\nu\} = 2\eta^{\mu\nu}\cdot\mathbbm 1_{n\times n}.
    \end{align}
One can then use this to explicitly show that such matrices satisfy the algebra of the Lorentz group,  (\ref{eq:SUSYalg:Poincar\'e:alg:1}). You already know that for $n=4$ in the Weyl representation, this construction is explicitly reducible into the left- and right-handed Weyl representations and we see that we get the appropriate generators are indeed what we defined to be $\sigma^{\mu\nu}$ and $\overline\sigma^{\mu\nu}$. We could have constructed the $n=2$ generators directly, but this would then lead to a factor of $i$ in the definition of $\vec\sigma$. 
\end{example}

\subsection{Chirality}\label{sec:SUSYalg:sec:chirality}

Now let's get back to a point of nomenclature. Why do we call them left- and right-handed spinors? The Dirac equation tells us\sidenote{To be clear, there's some arbitrariness here. How do we know which `Dirac equation' (i.e. with $\sigma$ or $\overline\sigma$) to apply to $\psi$ (the fundamental rep) versus $\overline\chi$ (the conjugate rep)? This is convention, `by the interchangeability of the fundamental and conjugate reps' and `the interchangeability of $\sigma$ and $\overline\sigma$' if you wish. Once we have chosen the convention of  (\ref{eq:susyalg:dirac2fund}), then  (\ref{eq:susyalg:dirac2anti}) follows from Hermitian conjugation. In other words, once we've chosen that the fundamental representation goes with the `$\sigma$' Dirac equation (\ref{eq:susyalg:dirac2fund}), we know that the conjugate representation goes with the `$\overline\sigma$' Dirac equation (\ref{eq:susyalg:dirac2anti}). If you ever get confused, check the index structure of $\sigma$ and $\overline\sigma$ and make sure they are contracting honestly.}
\begin{align}
    p_\mu\sigma^\mu \psi &= m \psi\label{eq:susyalg:dirac2fund}\\
    p_\mu\overline\sigma^\mu \overline\chi &= m \overline\chi\label{eq:susyalg:dirac2anti}.
\end{align}
% From Aitchison
Equation (\ref{eq:susyalg:dirac2anti}) follows from  (\ref{eq:susyalg:dirac2fund}) via Hermitian conjugation, as appropriate for the conjugate representation. 

In the massless limit, then, $p^0\rightarrow |\mathbf p|$ and hence 
\begin{align}
    \left(\frac{\mathbf\sigma\cdot\mathbf p}{|\mathbf{p}|}\psi\right) &= \phantom+ \psi\\
    \left(\frac{\mathbf\sigma\cdot\mathbf p}{|\mathbf{p}|}\overline\chi\right) &= -\overline\chi.
\end{align}
We recognize the quantity in parenthesis as the helicity operator, so that $\psi$ has helicity +1 (left-handed) and $\overline\chi$ has helicity $-$1 (right-handed). Non-zero masses complicate things, of course. In fact, they complicate things differently depending on whether the masses are Dirac or Majorana. We'll get to this in due course, but the point is that even though $\psi$ and $\overline\chi$ are no longer helicity eigenstates, they are \emph{chirality}\index{chirality} eigenstates:
\begin{align}
    \gamma_5\begin{pmatrix}\psi\\0\end{pmatrix} &= -\begin{pmatrix}\psi\\0\end{pmatrix}\\
    \gamma_5\begin{pmatrix}0\\\overline\chi\end{pmatrix} &=\phantom - \begin{pmatrix}0\\\overline\chi\\\end{pmatrix},
\end{align}
where we've put the Weyl spinors into four-component Dirac spinors in the usual way so that we may apply the chirality operator, $\gamma_5$. %(See Section \ref{subsec:SUSYalg:DiracSpinors}.)
\begin{example}
Keeping the broad program in mind, let us take a moment to note that chirality will play an important role in whatever new physics we might find at the Terascale. The Standard Model is a chiral theory (e.g. $q_L$ and $q_R$ are in different gauge representations), so whatever Terascale completion supersedes it must also be chiral. This is no problem in SUSY where we may place chiral fields into different supermultiplets (`superfields'). In extra dimensions, however, we run into the problem that there is no chirality operator in five dimensions. This leads to a lot of subtlety in model-building. (Not to mention issues with anomaly cancellation.) By the way, it prudence requires that a diligent student should thoroughly understand the difference between chirality and helicity.
\end{example}







\subsection{Fierz Rearrangement}\label{sec:SUSYalg:Fierz}

Fierz identities\index{Fierz identity} are useful for rewriting spinor operators by swapping the way indices are contracted. For example,
\begin{align}
    (\chi\psi)(\chi\psi) &= -\frac 12 (\psi\psi)(\chi\chi)\label{eq:SUSYalg:Fierz:alphaalphadot}.
\end{align}
%
One can understand these Fierz identities as an expression of the decomposition of tensor products in group theory. For example, we could consider the decomposition $(\frac 12,0)\otimes(0,\frac 12)=(\frac 12, \frac 12)$:
\begin{align}
    \psi_\alpha\overline\chi_{\dot\alpha} &= \frac 12 (\psi\sigma_\mu\overline\chi)\sigma^{\mu}_{\phantom\mu\alpha\dot\alpha},\label{eq:SUSYalg:fierz:sigma}
\end{align}
where, on the right-hand side, the object in the parenthesis is a vector in the same sense as  (\ref{eq:SUSYalg:vecspinor}). The factor of $\frac 12$ is, if you want, a Clebsch-Gordan coefficient.

Another example is the decomposition for $(\frac 12,0)\otimes(\frac 12,0)=(0,0)+(1,0)$:
\begin{align}
    \psi_\alpha\chi_\beta &= \frac 12 \epsilon_{\alpha\beta}(\psi\chi) + \frac 12 (\sigma^{\mu\nu}\epsilon^T)_{\alpha\beta}(\psi\sigma_{\mu\nu}\chi).
\end{align}
Note that the $(1,0)$ rep is the antisymmetric tensor representation. All higher dimensional representations can be obtained from products of spinors. Explicit calculations can be found in the lecture notes by M\"uller-Kirsten and Wiedemann \cite{MullerKirsten:1986cw}.

These identities are derived from completeness relations for the basis $\{\sigma^\mu\}$ of $2\times 2$ complex matrices. Using  (\ref{eq:SUSYalg:sl2ctom4}), we may write a generic $SL(2,\mathbb C)$ matrix $\mathbf x$ as 
% \begin{align}
%   \mathbf{x} &= x_\mu\sigma^\mu\\
%               &= \frac 12\Tr(\mathbf x) \sigma^0 + \frac 12\Tr(\mathbf x\sigma^i)\sigma^i\\
%   (\mathbf{x})_{\alpha\beta} &= \frac 12 (\mathbf x)_{\gamma\gamma}\delta_{\alpha\beta} + \frac 12 
% (\mathbf x)_{\gamma\delta}(\sigma^i)_{\delta\gamma}(\sigma^i)_{\alpha\beta},\label{eq:SUSYalg:completeness1}
% \end{align}
\begin{align}
    \mathbf{x} &= x_\mu\sigma^\mu\\
                &= \frac 12\text{Tr}(\mathbf x) \sigma^0 + \frac 12\text{Tr}(\mathbf x\sigma^i)\sigma^i\\
    (\mathbf{x})_{ac} &= \frac 12 (\mathbf x)_{zz}\delta_{ac} + \frac 12 
(\mathbf x)_{yz}(\sigma^i)_{zy}(\sigma^i)_{ac},\label{eq:SUSYalg:completeness1}
\end{align}
where we sum over repeated indices and we are using lower-case Roman indices to emphasize that this is a \textit{matrix} relation. The above statement knows nothing about metrics or raised/lowered indices or representations of $SL(2,\mathbb C)$; it's just a fact regarding the multiplication these particular $2\times 2$ matrices together. We already know the canonical index structure of $\sigma$ matrices so we can later make this statement `$SL(2,\mathbb C)$-covariant.' First, though, we take $\mathbf x$ to be one of the canonical basis elements of the space of $2\times 2$ matrices, $\mathbf x = \mathbf e_{bd}$ with index structure $(\mathbf e_{bd})_{ac} = \delta_{ab}\delta_{cd}$. Thus we may write  (\ref{eq:SUSYalg:completeness1}) as
\begin{align}
    \delta_{ab}\delta_{cd} &= \frac 12 \delta_{zb}\delta_{zd}\delta_{ac} - \frac 12 \delta_{yb}\delta_{zd}(\sigma^i)_{zy}(\sigma^i)_{ac}\\
        &= \frac 12 \delta_{ac}\delta_{db} + \frac 12 (\sigma^i)_{ac}(\sigma^i)_{db}.\label{eq:SUSYalg:sigma:completeness}
\end{align}
Now remembering the \textit{matrix} definition of $\overline\sigma$, i.e.  (\ref{eq:SUSYalg:sigma-bar}) rather than (\ref{eq:SUSYalg:sigmamu}), we may write
\begin{align}
    \delta_{ab}\delta_{cd} &= \frac 12 \delta_{ac}\delta_{db} - \frac 12 (\sigma^i)_{ac}(\overline\sigma^i)_{db}\\
    &= \frac 12 \delta_{ac}\delta_{db} + \frac 12 (\sigma^i)_{ac}(\overline\sigma_i)_{db}\\
    &= \frac 12 (\sigma^\mu)_{ac}(\overline\sigma_\mu)_{db},
\end{align}
where we have now used the Minkowski space metric to lower the contracted index and combine both terms. Let's now promote this from a matrix equation to an  $SL(2,\mathbb C)$ covariant equation by raising and dotting indices according to the conventions for $\sigma^\mu$ and $\overline\sigma^\mu$. We shall also now use our conventional $SL(2,\mathbb C)$ lower-case Greek indices. We find
\begin{align}
    \delta_\alpha^{\phantom\alpha\beta}\delta_{\dot\gamma}^{\phantom\gamma\dot\delta} &= \frac 12 (\sigma^\mu)_{\alpha\dot\gamma}(\overline\sigma_\mu)^{\delta\dot\beta}.\label{eq:SUSYalg:sigma:fierz}
\end{align}
Upon contracting indices with the appropriate spinors, this is precisely  (\ref{eq:SUSYalg:fierz:sigma}). This relation can now be used to generate further Fierz identities, as the eager student may check independently. It is useful to remember the general structure of this `mother' Fierz identity. On the left-hand side we have two Kronecker $\delta$s, one with undotted indices and the other with dotted indices. As usual both $\delta$s have one upper and one lower index. On the right-hand side we have two Pauli `four-matrices,' one barred and the other unbarred with their vector index contracted. The indices on the right-hand side is fixed by the index structure on the left-hand side, so this is actually rather trivial to write down. Just don't forget the factor of one-half. (As with many of the metric identities, one can easily obtain the overall normalization by tracing both sides.)

\begin{example}[How to properly write this Fierz Identity]
Let's make a rather pedantic point about notation. The form of the `mother' Fierz identity in  (\ref{eq:SUSYalg:sigma:fierz}) is what one should use to derive further Fierz identities since all indices are explicit. However, if one wanted to write down a list of useful identities---for example as Bailin \& Love\autocite{Bailin:1994qt} do in their appendix---one would instead write out the explicit spinors, i.e.
  \begin{align}
      \psi_\alpha\overline\chi^{\dot\gamma} &= \frac 12 (\sigma^\mu\overline\chi)_\alpha(\overline\sigma_\mu\psi)^{\dot\gamma}.
  \end{align}
This is more useful than  (\ref{eq:SUSYalg:sigma:fierz}) since that equation still had a lot of freedom to re-order indices. For example, one could have written the left-hand side of  (\ref{eq:SUSYalg:sigma:completeness}) as any of
\begin{align}
  \delta_{\alpha\delta}\delta_{\beta\gamma} = \delta_{\delta\alpha}\delta_{\beta\gamma} = \delta_{\alpha\delta}\delta_{\gamma\beta} = \delta_{\delta\alpha}\delta_{\gamma\beta} = \delta_{\beta\gamma}\delta_{\alpha\delta} = \cdots
\end{align}
\end{example}

% \vspace{.5em}
% \begin{framed}
% \noindent\textbf{How to properly write this Fierz Identity}. Let's make a rather pedantic point about notation. The form of the `mother' Fierz identity in  (\ref{eq:SUSYalg:sigma:fierz}) is what one should use to derive further Fierz identities since all indices are explicit. However, if one wanted to write down a list of useful identities---as we do in \Appendix \ref{chap:identities:fierz} and as Bailin \& Love \cite{Bailin:1994qt} do in their appendix---one would instead write out the explicit spinors, i.e.
%   \begin{align}
%       \psi_\alpha\overline\chi^{\dot\gamma} &= \frac 12 (\sigma^\mu\overline\chi)_\alpha(\overline\sigma_\mu\psi)^{\dot\gamma}.
%   \end{align}
% This is more useful than  (\ref{eq:SUSYalg:sigma:fierz}) since that equation still had a lot of freedom to re-order indices. For example, one could have written the left-hand side of  (\ref{eq:SUSYalg:sigma:completeness}) as any of
% \begin{align}
%   \delta_{\alpha\delta}\delta_{\beta\gamma} = \delta_{\delta\alpha}\delta_{\beta\gamma} = \delta_{\alpha\delta}\delta_{\gamma\beta} = \delta_{\delta\alpha}\delta_{\gamma\beta} = \delta_{\beta\gamma}\delta_{\alpha\delta} = \cdots
% \end{align}
% \end{framed}
% \vspace{.5em}

% Before you rush off and compare this to the completeness relation listed in the\SUSY literature (i.e. before you accuse me of lying to you), it's worth noting that by the symmetry of the Kronecker $\delta$ we can of course swap $\alpha$ with $\delta$ and/or $\dot\beta$ with $\dot\gamma$ on the left-hand side while leaving them in the same order on the right-hand side. Further, we could have assigned either $\sigma^i$ to have gotten a lower-index and a bar. Thus we in fact we could have written our completeness relation with different index structures, such as ***: Rewrite the following!! ***
% \begin{align}
%   \delta_\alpha^{\phantom\alpha\beta}\delta_{\dot\gamma}^{\phantom\gamma\dot\delta} &= \frac 12 (\sigma^\mu)_{\gamma\dot\alpha}(\overline\sigma_\mu)^{\dot\beta\dot\delta}\label{eq:SUSYalg:sigma:fierz1}\\
%   \delta_\alpha^{\phantom\alpha\beta}\delta_{\dot\gamma}^{\phantom\gamma\dot\delta} &= \frac 12 (\sigma^\mu)_{\gamma\dot\alpha}(\overline\sigma_\mu)^{\dot\beta\dot\delta}\label{eq:SUSYalg:sigma:fierz2}\\
%   \delta_\alpha^{\phantom\alpha\beta}\delta_{\dot\gamma}^{\phantom\gamma\dot\delta} &= \frac 12 (\sigma^\mu)_{\gamma\dot\alpha}(\overline\sigma_\mu)^{\dot\beta\dot\delta}\label{eq:SUSYalg:sigma:fierz3}
% \end{align}
% 
% A second set of Fierz identities is formed by using the basis $\{\mathbbm 1, \sigma^{\mu\nu}\}$. *** FLIP: Does anyone know how to do this??? 
% 
% %... this procedure, btw, generalizes to SU(N) quite nicely
% 
% The main `generating' relations for Fierz identities may be written using Weyl spinors as
% \begin{align}
%   (\theta\phi)(\chi\eta) &= -\frac12 \left[(\theta\eta)(\chi\phi) - (\theta\sigma^{\mu\nu}\eta)(\chi\sigma_{\mu\nu}\phi)\right]\\
%   (\theta\phi)(\overline\chi\overline\eta) &= -\frac 12(\theta\sigma^\mu\eta)(\overline\chi\overline\sigma_\mu\phi).
% \end{align}
% *** ... How do I prove the first one?! 

A comprehensive list of Fierz identities can be found in Appendix A of Bailin \& Love\autocite{Bailin:1994qt}, note the different convention for $\sigma^{\mu\nu}$. A very pedagogical exposition on deriving Fierz identities for Dirac spinors is presented in Nishi\autocite{nishi:1160}. 


\subsection{Connection to Dirac Spinors}\label{subsec:SUSYalg:DiracSpinors}

We would now like to explicitly connect the machinery of two-component Weyl spinors to the four-component Dirac spinors that we (unfortunately) teach our children.

Let us define
\begin{align}
    \gamma^\mu & \equiv \begin{pmatrix}0\quad&\sigma^\mu\\\overline\sigma^\mu\quad&0\end{pmatrix}.\label{eq:SUSYalg:gamma:weylrep}
\end{align}
This, one can check, gives us the Clifford algebra
\begin{align}
    \left\{\gamma^\mu,\gamma^\nu\right\} &= 2\eta^{\mu\nu}\cdot\mathbbm{1}.
\end{align}
We can further define the fifth $\gamma$-matrix, the four-dimensional chirality operator,
\begin{align}
    \gamma^5 &= i\gamma^0\gamma^1\gamma^2\gamma^3 = \begin{pmatrix}-\mathbbm{1}\quad&0\\0\quad&\mathbbm{1}\end{pmatrix}.
\end{align}
% \emph{\textbf{FLIP:} I should say something about the role of $\gamma^5$ as the chirality operator.}
% 
% \textbf{FLIP:} I should also explain why dirac spinors in Wess and Bagger are defined with lower undotted and upper dotted index. See page 8 of Bailin and Love. Also gives a way of showing why sigma indice are assigned as they are. Also, why is the dirac spinor composed of an upper index and lower dotted index (or whatever)? Because this is how we defined our contractions.


A \textbf{Dirac spinor}\index{spinor!Dirac} is defined, as mentioned above, as the direct sum of left- and right-handed Weyl spinors, $\Psi_D = \psi\oplus\overline\chi$, or
\begin{align}
    \Psi_D &= \begin{pmatrix}
        \psi_\alpha\\\overline\chi^{\dot\alpha}
    \end{pmatrix}.
\end{align} 
The choice of having a lower undotted index and an upper dotted index is convention and comes from how we defined our spinor contractions. The generator of Lorentz transformations takes the form
\begin{align}
    \Sigma^{\mu\nu} &=  \begin{pmatrix}
                            \sigma^{\mu\nu} &\quad 0\\
                            0               &\quad \overline\sigma^{\mu\nu}
                        \end{pmatrix},
\end{align}
with spinors transforming as
\begin{align}
    \Psi_D &\rightarrow e^{-\frac i2 \omega_{\mu\nu}\Sigma^{\mu\nu}}\Psi_D.
\end{align}

In our representation the action of the chirality operator is given by $\gamma_5$,
\begin{align}
    \gamma^5\Psi_D = \begin{pmatrix}
        -\psi_\alpha\\\phantom{+}\overline\chi^{\dot\alpha}
    \end{pmatrix}.
\end{align} 
We can then define left- and right-handed projection operators,
\begin{align}
    P_{L,R} = \frac 12\left(\mathbbm{1}\mp\gamma^5\right).
\end{align}
Using the standard notation, we shall define a barred \textit{Dirac} spinor as $\overline\Psi_D \equiv \Psi^\dag\gamma^0$. Note that this bar has nothing to do with the bar on a Weyl spinor. We can then define a charge conjugation matrix $C$ via $C^{-1}\gamma^\mu C = -(\gamma^\mu)^T$ and the Dirac conjugate spinor $\Psi_D^{\phantom{D}c} = C\overline\Psi_D^{\phantom{D}T}$, or explicitly in our representation,
\begin{align}
    \Psi_D^{\phantom{D}c} = \begin{pmatrix}
        \chi_\alpha \\ \overline\psi^{\dot\alpha}
    \end{pmatrix}.
\end{align}
A \textbf{Majorana spinor}\index{spinor!Majorana} is defined to be a Dirac spinor that is its own conjugate, $\Psi_M = \Psi_M^c$. We can thus write a Majorana spinor in terms of a Weyl spinor,
\begin{align}
    \Psi_M &= \begin{pmatrix}
        \psi_\alpha \\ \overline\psi^{\dot\alpha}
    \end{pmatrix}.
\end{align}
Here our notation is that $\overline\psi = \psi^\dag$, i.e.\ we treat the bar as an operation acting on the Weyl spinor (a terrible idea, but we'll do it just for now).
One can choose a basis of the $\gamma$ matrices such that the Majorana spinors are manifestly real. Thus this is sometimes called the `real representation' of a Weyl spinor.% Some references use Majorana generators for the SUSY algebra. Those references are stupid and annoying. (*** Flip: change this.)
%
Note that a Majorana spinor contains exactly the same amount of information as a Weyl spinor. Some textbooks thus package the Weyl SUSY generators into Majorana Dirac spinors, eschewing the dotted and undotted indices.


It is worth noting that in four dimensions there are no Majorana-Weyl spinors. This, however, is a dimension-dependent statement A good treatment of this can be found in the appendix of Polchinksi volume II\autocite{Polchinski:1998rr}.


\subsubsection{Dots and Bars}

It's worth emphasizing once more that the dots and bars are just book-keeping tools. Essentially they are a result of not having enough alphabets available to write different kinds of objects. The bars on Weyl spinors can be especially confusing for beginning supersymmetry students since one is tempted to associate them with the barred Dirac spinors, $\overline\Psi = \Psi^\dagger \gamma_0$. \emph{Do not make this mistake}. Weyl and Dirac spinors are different objects. The bar on a Weyl spinor has \emph{nothing} to do with the bar on a Dirac spinor. We see this explicitly when we construct Dirac spinors out of Weyl spinors (namely $\Psi = \psi\oplus\overline\chi$), but it's worth remembering because the notation can be misleading. %

In principle $\psi$ and $\overline\psi$ are totally different spinors in the same way that $\alpha$ and $\dot\alpha$ are totally different indices. Sometimes---as we have done above---we may also use the bar as an operation that converts an unbarred Weyl spinor into a barred Weyl spinor. That is to say that for a left-handed spinor $\psi$, we may define $\overline\psi=\psi^\dag$. To avoid ambiguity it is customary---as we have also done---to write $\psi$ for left-handed Weyl spinors, $\overline\chi$ for right-handed Weyl spinors, and $\overline\psi$ to for the right-handed Weyl spinor formed by taking the Hermitian conjugate of the left-handed spinor $\psi$.

To make things even trickier, much of the literature on extra dimensions use the convention that $\psi$ and $\chi$ (unbarred) refer to left- and right-`chiral' \textit{Dirac} spinors. Here `chiral' means that they permit chiral zero modes, a non-trivial subtlety of extra dimensional models that we will get to in due course. For now we'll use the supersymmetric convention that $\psi$ and $\overline\chi$ are left- and right-handed Weyl spinors.



\section{The SUSY Algebra}
\label{chap:SUSYalg}
% % 
% % \sectionquote{Supersymmetry is nearly thirty years old. It seems that now we are approaching the fourth supersymmetry revolution which will demonstrate its relevance to nature.}%
% % {G.L. Kane and M. Shifman \cite{shifman}}%: Blackwood's Magazine May 1830
% % 
% % 
This is now well beyond the scope of this course, but if you have made it this far, we might as well see what all this buys us.

\subsection{The Supersymmetry Algebra}

Around the same time that the Beatles released \emph{Sgt. Pepper's Lonely Hearts Club Band}, Coleman and Mandula published their famous `no-go' theorem which stated that the most general symmetry Lie group of an $S$-matrix in four dimensions is the direct product of the Poincar\'e group with an internal symmetry group. See Weinberg Vol III for a proof of the Coleman-Mandula theorem. In other words, there can be no mixing of spins within a symmetry multiplet. 

Ignorance is bliss, however, and physicists continued to look for extensions of the Poincar\'e symmetry for some years without knowing about Coleman and Mandula's result. In particular, Golfand and Licktmann extended the Poincar\'e group using Grassmann operators, `discovering' supersymmetry in physics. Independently, Ramond, Neveu, Schwarz, Gervais, and Sakita where applying similar ideas in two dimensions to insert fermions into a budding theory of strings, hence developing (wait for it...) superstring theory.

SUSY, then, is able to evade the Coleman-Mandula theorem by generalizing the symmetry from a Lie algebra to a \textbf{graded Lie algebra}\index{Lie algebra!graded}. This has the property that if $\mathcal O_a$ are operators, then
\begin{align}
    \mathcal O_a\mathcal O_b - (-1)^{\eta_a\eta_b}\mathcal O_b\mathcal O_a &= i C^{e}_{\phantom{e}ab}\mathcal O_e,\label{eq:SUSYalg:gradedalg}
\end{align}
where,
\begin{align}
    \eta_a &= \left\{ 
    \begin{array}{l l}
      0 & \quad \mbox{if $\mathcal O_a$ is bosonic}\\
      1 & \quad \mbox{if $\mathcal O_a$ is fermionic}\\
    \end{array} \right.
\end{align} 
%For example, $\mathbf{P}$ and $\mathbf{J}$ are bosonic. We will become acquainted with some fermionic generators very soon.

The Poincar\'e generators $P^\mu, M^{\mu\nu}$ are both bosonic generators with $(A,B)=(\frac 12, \frac 12), (1,0)\oplus(0,1)$ respectively. In supersymmetry, on the other hand, we add \textit{fermionic generators}, $Q^A_\alpha, \overline Q^B_{\dot\alpha}$. Here $A,B = 1, \cdots, \mathcal N$ label the number of \textbf{supercharges}\index{supercharge} (these are, of course, different from the $(A,B)$ that label representations of the Lorentz algebra) and $\alpha, \dot\alpha = 1, 2$ are Weyl spinor indices. We will primarily focus on \textbf{simple supersymmetry} where $\mathcal N = 1$. We call $\mathcal N >1$ \textbf{extended supersymmetry}\index{extended supersymmetry}.

Haag, Lopuszanski, and Sohnius\autocite{Haag:1974qh} showed in 1974 that $(\frac 12,0)$ and $(0,\frac 12)$ are the only generators for supersymmetry. For example, it would be inconsistent to include generators $\tilde Q$ in the representation $(A,B = (\frac 12, 1))$. The general argument can be found in section 25.2 in Weinberg III\sidenote{As a rule-of-thumb you can find anything in Weinberg. You can probably find unicorns in Weinberg... but they'd be very well hidden in excessively curly script.}. 

Without further ado, let's write down the supersymmetry algebra. 
\begin{align}
    [M^{\mu\nu},M^{\rho\sigma}] &= i(M^{\mu\nu}\eta^{\nu\rho}+M^{\nu\rho}\eta^{\mu\sigma}-M^{\mu\rho}\eta^{\nu\sigma}-M^{\nu\sigma}\eta^{\mu\rho})\label{eq:SUSYalg:MM}\\
    [P^\mu,P^\nu] &= 0\label{eq:SUSYalg:PP}\\
    [M^{\mu\nu},P^\sigma]&=i(P^\mu\eta^{\nu\sigma}-P^\nu\eta^{\mu\sigma}\label{eq:SUSYalg:MP})\\
    [Q_\alpha,M^{\mu\nu}] &= (\sigma^{\mu\nu})_\alpha^{\phantom\alpha\beta}Q_\beta\label{eq:SUSYalg:QM}\\
    [Q_\alpha,P^\mu]&=0\label{eq:SUSYalg:QP}\\
    \{Q_\alpha,Q^\beta\} &= 0\label{eq:SUSYalg:QQ}\\
    \{Q_\alpha,\overline Q_{\dot\beta}\} &= 2(\sigma^\mu)_{\alpha\dot\beta}P_\mu\label{eq:SUSYalg:QQbar}
\end{align}
We're already familiar with (\ref{eq:SUSYalg:MM}) -- (\ref{eq:SUSYalg:MP}) from the usual Poincar\'e algebra. It remains to discuss the remaining equations involving the new fermionic generators. Note that some conventions define  (\ref{eq:SUSYalg:QM}) with an $i$, we will discuss this below.

Before we do that, however, two important notes are in order. First, one should check that the assignment of commutators in the above equations matches our definition for a graded Lie algebra,  (\ref{eq:SUSYalg:gradedalg}). Second, one should note that up to overall constants, we should \textit{almost} have been able to \textit{guess} the form of the new equations by matching the index structure on the left- and right-hand sides of each equation, using only the SUSY algebra and the generators of $SL(2,\mathbb{C})$, (\ref{eq:SUSYalg:sigmamunu}) and (\ref{eq:SUSYalg:sigmabarmunu}).

%\texorpdfstring{}{}
 % \subsection{
 % \texorpdfstring{$[Q_\alpha,M^{\mu\nu}] = (\sigma^{\mu\nu})_\alpha^{\hspace{.5em}\beta}Q_\beta$}{Q,M Commutator}}\label{sec:SUSYalg:QM}
 % \subsection{
 % $[Q_\alpha,M^{\mu\nu}] = (\sigma^{\mu\nu})_\alpha^{\hspace{.5em}\beta}Q_\beta$}
 \subsection{\texorpdfstring{
 $[Q_\alpha,M^{\mu\nu}] = (\sigma^{\mu\nu})_\alpha^{\hspace{.5em}\beta}Q_\beta$}{[Q,M]}}
 \label{sec:SUSYalg:QM}
% For some reason PDFLaTeX doesn't like it if I replace \hspace{.5em} with \phantom{\alpha}. Why? I get a funny space in the Table of Contents for this subsection.
 
Now consider  (\ref{eq:SUSYalg:QM}).
% \begin{align*}
%   [Q_\alpha,M^{\mu\nu}] &= (\sigma^{\mu\nu})_\alpha^{\phantom\alpha\beta}Q_\beta.
% \end{align*}
How do we understand this? First of all, because $Q_\alpha$ is a spinor, we may write down its transformation under an infinitesimal Lorentz transformation,
\begin{align}
    Q'_\alpha &= (e^{-\frac i2\omega_{\mu\nu}\sigma^{\mu\nu}})_\alpha^{\phantom\alpha\beta}Q_\beta \label{eq:SUSYalg:QM:prespinor}\\
    &\approx (\mathbbm{1}-\frac i2\omega_{\mu\nu}\sigma^{\mu\nu})_\alpha^{\phantom\alpha\beta}Q_\beta.\label{eq:SUSYalg:QM:spinor}
\end{align}
Equation (\ref{eq:SUSYalg:QM:prespinor}) defines our convention for the transformation of spinors under Lorentz transformations, as in (\ref{eq:SUSYalg:alphatransform}) and (\ref{eq:SUSYalg:alphadottransform}). 
%
Next we note that $Q_\alpha$ also leads a second life as an operator. Thus we know it \textit{also} transforms as
\begin{align}
    Q'_\alpha &= U^\dag Q_\alpha U\\
    U &= e^{-\frac i2 \omega_{\mu\nu}M^{\mu\nu}},
\end{align}
and hence,
\begin{align}
    Q'_\alpha &\approx (\mathbbm{1}+\frac i2\omega_{\mu\nu}M^{\mu\nu})\,Q_\alpha\, (\mathbbm{1}-\frac i2\omega_{\mu\nu}M^{\mu\nu}).\label{eq:SUSYalg:QM:operator}
\end{align}
Setting (\ref{eq:SUSYalg:QM:spinor}) and (\ref{eq:SUSYalg:QM:operator}) equal to one another, 
\begin{align}
    Q_\alpha - \frac i2 \omega_{\mu\nu}(\sigma^{\mu\nu})_\alpha^{\phantom\alpha\beta}Q_\beta &= Q_\alpha - \frac i2 \omega_{\mu\nu}(Q_\alpha M^{\mu\nu}-M^{\mu\nu}Q_\alpha)+\mathcal O(\omega^2),
\end{align}
from which we finally deduce  (\ref{eq:SUSYalg:QM})
\begin{align}
    [Q_\alpha,M^{\mu\nu}] &= (\sigma^{\mu\nu})_\alpha^{\phantom\alpha\beta}Q_\beta.
\end{align}
 
The commutator for the right-handed representation corresponds to placing bars on this relation,
\begin{align}
    [\overline Q_{\dot\alpha},M^{\mu\nu}] &= \epsilon_{\dot\alpha\dot\delta}(\overline\sigma^{\mu\nu})^{\dot\delta}_{\phantom\delta\dot\beta}\overline Q^{\dot\beta},\label{eq:SUSYalg:QbarM}
\end{align}
or written with `naturally' raised indices for the right-handed spinor,
\begin{align}
    [\overline Q^{\dot\alpha},M^{\mu\nu}] &= (\overline\sigma^{\mu\nu})^{\dot\alpha}_{\phantom\alpha\dot\beta}\overline Q^{\dot\beta}.\label{eq:SUSYalg:QbarMraised}
\end{align}
These follow from the transformation law in  (\ref{eq:SUSYalg:sigmabarmunu}).
%
\begin{example}[Bailin \& Love convention]
As we noted previously, some textbooks carry a different normalization for $\sigma^{\mu\nu}$ that differs from ours by a factor of $-i$. In that case the infinitesimal transformation in  (\ref{eq:SUSYalg:QM:spinor}) is replaced with
\begin{align}
    Q'_\alpha & \approx (\mathbbm{1}+\frac 12\omega_{\mu\nu}\sigma^{\mu\nu})_\alpha^{\phantom\alpha\beta}Q_\beta,
\end{align}
in which case the commutators become
\begin{align}
[Q_\alpha,M^{\mu\nu}] &= i(\sigma^{\mu\nu})_\alpha^{\phantom\alpha\beta}Q_\beta\\
    [\overline Q_{\dot\alpha},M^{\mu\nu}] &= i\epsilon_{\dot\alpha\dot\delta}(\overline\sigma^{\mu\nu})^{\dot\delta}_{\phantom\delta\dot\beta}\overline Q^{\dot\beta}.
    \end{align}
\end{example}



\subsection{\texorpdfstring{$[Q_\alpha,P^\mu]=0$}{[Q,P]}}

Equation (\ref{eq:SUSYalg:QP}) tells us that translations don't affect the fermionic transformations. This is a bit surprising since our mnemonic of looking at the index structure suggests that the right-hand side of this equation could be proportional to $(\sigma^\mu)_{\alpha\dot\alpha}\overline Q^{\dot\alpha}$. Indeed, let us assume this to find that the proportionality constant, $c$ must be zero. Thus,
\begin{align}
    [Q_\alpha,P^\mu] = c(\sigma^\mu)_{\alpha\dot\alpha}\overline Q^{\dot\alpha}.\label{eq:SUSYalg:QPcomm}
\end{align}
This is actually two equations since we can get a corresponding equation for $\overline Q$.
%
Recall that taking the Hermitian conjugate of a left-handed spinor operator produces a right-handed spinor (and vice versa), so that $Q_\alpha^{\phantom\alpha\dag} = \overline Q_{\dot\alpha}$. What about the $\sigma$ matrix?
%
From  (\ref{eq:SUSYalg:sigmamu}) we have $(\sigma^\mu)_{\alpha\dot\alpha} = \epsilon_{\alpha\beta}\epsilon_{\dot\alpha\dot\beta}(\overline\sigma^\mu)^{\dot\beta\beta}$. Putting this together and taking the Hermitian conjugate of  (\ref{eq:SUSYalg:QPcomm}),
\begin{align}
    [Q_{\alpha}^{\phantom\alpha\dag},P^\mu] &= c^* (\sigma^\mu)_{\alpha\dot\alpha}\overline Q^{\dot\alpha\dag}\\
    [\overline Q_{\dot\alpha},P^\mu] &= c^* \epsilon_{\alpha\beta}\epsilon_{\dot\alpha\dot\beta}(\overline\sigma^\mu)^{\dot\beta\beta} Q^{\alpha}\\
    [\overline Q^{\dot\alpha},P^\mu] &= c^*(\overline\sigma^\mu)^{\dot\alpha\alpha} Q_{\alpha}.\label{eq:SUSYalg:QbarPcomm}
\end{align}
%$$(\sigma^\mu)_{\alpha\dot\alpha} = \epsilon_{\alpha\beta}\epsilon_{\dot\alpha\dot\beta}(\overline\sigma^\mu)^{\beta\dot\beta}$$
Note once again that the Hermitian conjugate acts only on the \textit{operator} $\overline Q$, i.e. it has nothing to do with a `complex conjugate transpose.' Equations (\ref{eq:SUSYalg:QPcomm}) and (\ref{eq:SUSYalg:QbarPcomm}) are, by index structure (that is, by Lorentz covariance), the most general form of the commutators of $Q$ and $\overline Q$ with $P$. To find $c$ we invoke the Jacobi identity for $P^\mu$, $P^\nu$, and $Q_\alpha$:
\begin{align}
    0 &= \left[P^\mu,\left[P^\nu,Q_\alpha\right]\right] + \left[P^\nu,\left[Q_\alpha,P^\mu\right]\right] + \left[Q_\alpha,\left[P^\mu,P^\nu\right]\right]\\
    &= -c\sigma^{\nu}_{\phantom\nu\alpha\dot\alpha} \left[P^\mu,\overline Q^{\dot\alpha}\right] + c\sigma^\mu_{\phantom\mu\alpha\dot\alpha}\left[P^\nu,\overline Q^{\dot\alpha}\right]\\
    &= \left|c\right|^2 \sigma^\nu_{\phantom\nu\alpha\dot\alpha} \overline\sigma^{\mu\dot\alpha\beta}Q_\beta - \left|c\right|^2 \sigma^\mu_{\phantom\mu\alpha\dot\alpha} \overline\sigma^{\nu\dot\alpha\beta}Q_\beta\\
    &= \left|c\right|^2 (\sigma^{\nu\mu})_\alpha^{\phantom\alpha\beta}Q_\beta.
\end{align}
From this we conclude that $c=0$, hence proving our assertion.


\subsection{\texorpdfstring{$\{ Q_\alpha,Q^\beta\}=0$}{[Q,Q]}}

Equation (\ref{eq:SUSYalg:QQ}) comes from a similar argument. Again we may write the most general form of the anticommutator,
\begin{align}
    \left\{Q_\alpha,Q^\beta\right\} &= k\left(\sigma^{\mu\nu}\right)_\alpha^{\phantom\alpha\beta}M_{\mu\nu}.
\end{align}
There can be no $\sigma^{\mu\nu}P_\mu P_\nu$ term by the antisymmetry of the $\sigma^{\mu\nu}$ in $\mu$ and $\nu$. Since $[Q,P]=0$, the left-hand side of the above equation manifestly commutes with $P$. The right-hand side, however, manifestly does not commute with $P$ from  (\ref{eq:SUSYalg:MP}). In order for the above equation to be consistent, then, $k=0$. Taking the Hermitian conjugate of the above equation of course also gives us
\begin{align}
    \left\{\overline Q^{\dot\alpha},\overline Q_{\dot\beta}\right\} = 0.
\end{align}

\subsection{\texorpdfstring{$\{Q_\alpha,\overline Q_{\dot{\beta}} \} = 2(\sigma^\mu)_{\alpha\dot{\beta}}P_\mu$}{[Q,Q-bar]}}

Thus far none of the previous results have been particularly interesting. We saw that the spinor SUSY generator has a nontrivial commutator with Lorentz transformations, but this is actually obvious because it is a nontrivial representation of the Lorentz group. The other (anti)commutators have been zero. By this point one might have become rather bored. Luckily, this anticommutator is the payoff for our patience. 

Using the same index argument as we've been using, we may write the anticommutator as
\begin{align}
    \left\{Q_\alpha,\overline Q_{\dot\beta}\right\} &= t(\sigma^\mu)_{\alpha\dot\beta} P_\mu.
\end{align}
This time, however, we cannot find an argument to set $t=0$. By convention we set $t=2$, though in principle we could have chosen any positive number. Since the right-hand side is the four-momentum operator, we require positivity to have positive energies.

Now let's step back for a moment. It is common to `dress' this equation in words. A particularly nice description is to say that the supersymmetry generators are a kind of square root of the four-momentum. Another description is to say that combining two supersymmetry transformations (one of each helicity) gives a spacetime translation.

If $|F \rangle$ represents a fermionic state and $|B\rangle$ a bosonic state, then the SUSY algebra tells us that
\begin{align}
    Q|F\rangle &= |B\rangle & \overline Q|F\rangle &= |B\rangle\\
    Q|B\rangle &= |F\rangle & \overline Q|B\rangle &= |F\rangle,
\end{align}
that is the SUSY generators turn bosons into fermions and vice-versa. However, the product of two generators preserves the spin of the particle but the particle is translated in spacetime,
\begin{align}
    Q\overline Q|B\rangle &\sim P|B\rangle.
\end{align}
We're being very loose with notation here, the $\sim$ is meant to allude to the anticommutator $\{Q,\overline Q\}$. Thus the SUSY generators `know' all about spacetime. This is starting to become interesting.

\begin{example}[On the uniqueness of $\mathcal N=1$ SUSY.] The $\mathcal N=1$ SUSY algebra derived above is the \textit{unique} extension of the Poincar\'e group by a graded Lie algebra. We've tried to maintain a flavor of this by `deriving' the above (anti-)commutation relations in terms of the tensors available to the Poincar\'e group. Our general argument was to write down the most general form of the (anti-)commutators based on covariance and then to constrain these using self-consistency. One can check that it is not possible to add higher-spin fermionic generators with non-trivial (anti-)commutators. For more on this, see Weinberg III
\end{example}




\subsection{Commutators with Internal Symmetries}

By the Coleman-Mandula theorem, we know that internal symmetry generators commute with the Poincar\'e generators. For example, the Standard Model gauge group commutes with the momentum, rotation, and boost operators. This carries over to the SUSY algebra. For an internal symmetry generator $T_a$,
\begin{align}
    [T_a,Q_\alpha] &= 0.
\end{align}
This is true with one exception. The SUSY generators come equipped with their own internal symmetry, called \textbf{R-symmetry}\index{R-symmetry}. There exists an automorphism of the supersymmetry algebra,
\begin{align}
    Q_\alpha &\rightarrow e^{it}Q_\alpha \label{eq:SUSYalg:RQ}\\
    \overline Q_{\dot\alpha} &\rightarrow e^{-it}\overline Q_{\dot\alpha},\label{eq:SUSYalg:RQbar}
\end{align}
for some transformation parameter $t$.
This is a $U(1)$ internal symmetry. Applying this symmetry preserves the SUSY algebra. If $R$ is the generator of this $U(1)$, then its action on the SUSY operators is given by\sidenote{``\emph{R! What is it good for? Absolutely nothing!}'' Contrary to Edwin Starr's hit 1969 Motown song, $R$-symmetry is more than just a curiosity and is actually a powerful tool when determining the existence of non-supersymmetric vacua. }
\begin{align}
    Q_\alpha &\rightarrow e^{-iRt}Q_\alpha e^{iRt}.\label{eq:SUSYalg:RQop}
\end{align}
By comparing the transformation of $Q$ under (\ref{eq:SUSYalg:RQop}) and (\ref{eq:SUSYalg:RQop}), we find the corresponding algebra,
\begin{align}
    [Q_\alpha,R] &= Q_\alpha\\
    [\overline Q_{\dot\alpha},R] &= -\overline Q_{\dot\alpha}.
\end{align}
This is the exact analog of the manipulations in Section \ref{sec:SUSYalg:QM} to derive the algebra from the comparison of $Q$ as an element of the representation of a group and as an operator.



\subsection{Extended Supersymmetry}

The most general supersymmetry algebra contains an arbitrary number $\mathcal N$ of SUSY generators, which we may label with capital roman letters: $Q^A_{\alpha},\overline Q^B_{\dot\alpha}$ where $A,B = 1,\cdots,\mathcal N$. The SUSY anticommutators take the general form
\begin{align}
    \{ Q^A_\alpha, \overline Q_{\dot\beta B}\} &= 2(\sigma^{\mu})_{\alpha\dot\beta} \delta^{A}_{\phantom AB}P_\mu\\
    \{ Q^A_\alpha, Q^B_\beta\} &= \epsilon_{\alpha\beta}Z^{AB}.
\end{align}
There's nothing special about the upper or lower capital letters, they're just labels. The first equation is a little boring, the different generators don't mix to form the momentum generator. The second equation, however, starts to get more interesting. The $Z$s are called \textbf{central charges}\index{central charge}. The antisymmetric tensor is the only object that has the right index structure. In order to be consistent with the symmetry of the left-hand-side, the central charge must be antisymmetric, $Z^{AB} = -Z^{BA}$.

$Z$ is like an abelian generator of an internal symmetry group. The commutator of the central charges with the other elements of the algebra are all null:
\begin{align}
    [Z^{AB},P^\mu] = [Z^{AB},M^{\mu\nu}] = [Z^{AB}, Q^C_\alpha] = [Z^{AB},Z^{CD}] = [Z^{AB},T_a] = 0.
\end{align}
The central charges affect the $R$-symmetry described in the previous subsection. If the central charges all vanish $Z^{AB} = 0$, then the $R$-symmetry group is $U(\mathcal N)$. If the charges do not all vanish, then the $R$-symmetry group is a subset of $U(\mathcal N)$.

Central charges play an important role in the nonperturbative nature of supersymmetry. Additionally, they appear generically in the analysis of projective representations of a symmetry group.

\begin{example}[Central Charges and Projective Representations.] Recall that for a projective representation $U$ of a symmetry group with elements $T,T'$,
    \begin{align}
        U(T)U(T') = e^{i\phi(T,T')}U(TT'),
    \end{align}
    where $\phi(T,T')$ is a phase that depends on the particular group elements being multiplied. Consistency requires that $\phi(T,1)=\phi(1,T)=0$ since the phase must vanish when multiplying by the identity. Parameterizing the group elements by $\alpha$, we can Taylor expand
    \begin{align}
        \phi(T(\alpha),T(\alpha')) = w_{ab}\alpha^a\alpha'^b+\cdots,
    \end{align}
    where the $w$ are real constants. The effect of this phase on the algebra (with elements $t,t'$) of the Lie group is that the commutator is modified to include a central charge, $z_{ab} = -w_{ab}+w_{ba}$:
    \begin{align}
        [t_b,t_c] = iC^a_{\phantom abc}t_a + iz_{bc}\mathbbm 1.
    \end{align}
    Generally one can redefine the generators of the algebra to remove the central charges from the commutator. If this can be done, then it turns out that the group does not admit projective representations. Recall that we used an alternate topological argument to show that the Lorentz group admits projective representations.
\end{example}



\section{Representations of Supersymmetry}
\label{chap:SUSYreps}

% \chapterquote{I had to figure out whether less complex superalgebras existed and then to determine whether they had any relation to field theory or high energy physics. The first part didn't take much time --- I wrote out fairly quickly all extensions of the algebra of generators of the Poincar\'e group by bispinor generators. It took significantly longer to put together the free field representations: one had to get used to the fact that in one multiplet were unified fields with both integer and half-integer spins.}%
% {Evgeny Likhtman \cite{shifman}}%: 

% \chapterquote{The multiplet that includes a spin-1 field also has a spin-1/2 field by supersymmetry. These are vector multiplets. This is a distinct use of the word `vector' from [the fundamental gauge representation] `vector.' The notation is designed, I think, to maximally confuse you so that if you understand it, you're not relying on the notation at all. So in that sense I always tell my students that [if you're confused the notation] that's good, because it forces them to actually understand the physics.}{Scott Thomas} % At the Hebrew University Summer School, Dec 08 - Jan 09

We discussed the representations of the Lorentz (or Poincar\'e) algebra (really of $Spin(3,1)$). Now we'd like to go a bit deeper to understand the properties of these fields that come from the Poincar\'e algebra itself. We will `rediscover' basic facts that we already know about Poincar\'e multiplets. Then we will extend this analysis to the SUSY algebra and use the analogous construction to learn about the components of SUSY multiplets.

Useful references for this chapter, in order of increasing formalism, are the appropriate chapters of Jones\autocite{JonesGroups}, Ryder\autocite{Ryder:1996}, Weinberg\autocite{weinberg}, Gutowski\autocite{gutowski}, Sternberg\autocite{Sternberg:1994tw}, and Kuzenko and Buchbinder\autocite{Buchbinder:1998qv}. The details for unitary representations of the Poincar\'e group, should one wish to pursue the literature further, were worked out originally by Wigner in his `classic' 1939 paper\autocite{Wigner:1939cj}. A treatment for general spacetime dimension can be found in Bakaert and Boulanger\autocite{Bekaert:fk}.

% \textbf{More general:} Unitary reps of Poincar\'e group in arbitrary dimension: \url{http://arxiv.org/abs/hep-th/0611263}


\section{Warm-up: Reps of the Rotation Group}

% \textbf{*** FLIP: Update this with the discussion from Bilal or Argyres... they say some good things about the non-SUSY poincare Casimir operators. Also include Csaba's discussion from page 136 of his notes. A good reference is Jones chapter 10... surprisingly good from that book.}


As a quick refresher, let's briefly review the rotation group. The algebra is given by
\begin{align}
    [J_i,J_j]&=i\epsilon_{ijk}J_k.
\end{align}
$SO(3)$ has one \textbf{Casimir operator}\index{Casimir operator}, i.e. an operator built out of the generators that commute with all of the generators. For $SO(3)$ this is 
\begin{align}
    \mathbf{J}^2 = \sum J_i^2.
\end{align}
Each irreducible representation (irrep) takes a single value of the Casimir operator. For example, the eigenvalues of $\mathbf{J}^2$ are $j(j+1)$ where $j=\frac 12,1, \cdots$. Thus each irrep is labelled by $j$. To label each element of the irrep, we pick eigenvalues of $J_3$ from the set $j_3 = -j,\cdots,j$. Thus each state is labelled as $|j;j_3\rangle$, identifying individual states with respect to their transformation properties under the symmetry. As Fernando Quevedo might say, ``I'm sure you've known this since you were in primary school.''


\section{Representations of the Poincar\'e Group}

\subsection{Casimir Operators}

Let's do the analogous analysis for the Poincar\'e group. This requires a bit more machinery. We shall be a bit heuristic here, leaving the uglier details to the references listed at the beginning of this chapter. Following the procedure for $SO(3)$, one might like to start by declaring the Casimir operators for the Poincar\'e group. A bit of physical intuition would lead you to suspect that there should be a Casimir each for the Lorentz part of the Poincar\'e group and the translation part. The former should be some covariant generalization of the $\mathbf{J}^2$ of $SO(3)$ that incorporates boosts, while the latter should have something to do with translations in space-time. Thinking about conserved quantities, one would expect these to roughly correspond to spin (angular momentum) and mass (energy).

I can now write out the Casimir operators for you, but unfortunately I cannot offer adequate \textit{a priori} motivation for their construction. It's a slightly fishy business to systematically deduce the Casimirs of an arbitrary group. We can only invoke our `intuitive' physical argument above and then leave it to the reader to check that the operators that we right down do, in fact, commute with all other operators. 


Without any proper motivation, let us define the \textbf{Pauli-Lubanski} vector\index{Pauli-Lubanski},
\begin{align}
    W_\mu &= \frac 12 \epsilon_{\mu\nu\rho\sigma} P^\nu M^{\rho\sigma}.\label{eq:SUSYreps:paulilubanski}
\end{align}
This unusual-looking vector is meant to be a Lorentz-covariant generalization of angular momentum. If you stare at it long enough---perhaps squinting a little---you might even begin to believe me. Even if you don't, however, we'll get a more intuition for this when we construct explicit representations. How might we have thought to write down something like this to represent `angular momentum' in $SO(3,1)$? Well, we really only have three [co/in-variant] tensors to play with: $M^{\mu\nu}$, $P^\mu$, and $\epsilon_{\mu\nu\rho\sigma}$. Taking some motivation from $\mathbf{J}=\mathbf{r}\times\mathbf{p}$ from kindergarten physics, we might guess to take some kind of `cross product' of $P^\mu$ and $M^{\mu\nu}$ (i.e. generator of translations $\sim \mathbf{R}$ with the generator of boosts $\sim \mathbf{p}$). The natural thing to write down up to normalization is given by  (\ref{eq:SUSYreps:paulilubanski}).


We can now define two Poincar\'e Casimir operators (i.e. both Lorentz- and translation-invariant),
\begin{align}
  C_1 &\equiv  P^\mu P_\mu\\
  C_2 &\equiv W^\mu W_\mu.
\end{align}
That these are really Casimirs can be checked explicitly with a bit of unenlightening effort.  The eigenvalue of $C_1$ is, of course, the particle mass as usual. We will get to the business of interpreting $C_2$ shortly, but one can already guess based on the discussion of the previous paragraph that $C_2$ has something to do with the particle's spin. From these two we will be able to label Poincar\'e irreps $|m,\omega\rangle$ by their mass, $m$, and the eigenvalue of $C_2$ (`spin'), which we call $\omega$. 

A the connection between $C_2$ and spin will come about when we look at particular representations, so our strategy will be to first show some features of how $C_1$ decomposes the space of Poincar\'e representations and then to see what happens when we look at $C_2$ on these subspaces. If you are unsatisfied with the present path to the definition of $C_2$ (and honest physicists should be), then don't worry. The entire analysis that follows can be done without explicit knowledge of $C_2$, and in fact one can `reverse-engineer' the expression for $C_2$ after we do some heavy-lifting. If you prefer, this is the `proper' way to motivate $W_\mu$ and derive $C_2$.

\flip{More to add... see comments}

% \subsection{\texorpdfstring{States in a Poincar\'e Irreducible Representation}{States in a Poincare Irreducible Representation}}
% 
% To label the particular particle states within an irreducible representation of the Poincar\'e group, we need to pick eigenvalues of a set of commuting generators. A good place to start is the the momentum operator\footnote{Why do we start with the momentum? We know from quantum mechanics that propagating states are eigenstates of the momentum operator. Further, we know from the Poincar\'e algebra that the different components of momentum commute.} $\hat P^\mu$,
% \begin{align}
%   \hat P^\mu|m,\omega;p^\mu\rangle &= p^\mu|m,\omega;p^\mu\rangle.
% \end{align}
% We shall adopt the non-standard notation of writing a hat to mean the appropriate representation (operator) of a Poincar\'e group element\footnote{A more typical notation is to write the representation of the abstract group element $P$ by $d(P)$ or even $d_R(P)$ if different representations $R$ are floating around. This gets ridiculously cumbersome and obfuscates the meaning of equations. Thus we shall write a hat to denote a representation. The particular representation shall be left implicit unless there is an ambiguity.}.
% 
% Are there more generators that commute with $P_\mu$, i.e. further labels for elements within a Poincar\'e irrep? Yes, and as one might guess they have something to do with the Pauli-Lubanski vector. One can quickly check, however, that $[W^\mu,P^\nu]\neq 0$ in general, so that this will require some work. What we'll end up doing is considering the cases of massive and massless representations separately. This is not so surprising since we know that massless and massive particles are fundamentally different from the point of view of the Lorentz group: you cannot boost into the rest frame of a massless particle.
% 
% To properly quantify this difference we'll need to do a few formal manipulations. Let us label a unitary representation of the Poincar\'e group by its momentum $p_\mu$ and any other quantum numbers $\alpha$. For example, $\alpha$ would include spin and any gauge quantum numbers. We shall write a state under this representation as $|p,\alpha\rangle$ with the property that
% \begin{align}
%   \hat{P}_\mu |p,\alpha\rangle = p_\mu |p,\alpha\rangle.
% \end{align}
% To be complete, we really should have written $|m,\omega;p,\alpha\rangle$ to label the irrep with the values of the Casimir operators. In the current analysis, however, we'll only work \textit{within} an irrep so we shall suppress these labels. Describe the space of all states of a given momentum $p$ by
% \begin{align}
%   \mathscr{H}_k = \{|k,\alpha\rangle\},
% \end{align}
% this set is labelled by the quantum numbers $\alpha$. For example, the space $\mathscr{H}_k$ for an on-shell massless $SU(N)$ gauge boson is the set of states for which the gauge boson has momentum $k_\mu$. In that case $\alpha$ is short hand for the $(N-1)$ gauge quantum states and the 2 spin polarizations.
% 
% What happens when we perform a finite\footnote{Another word of notation: we shall write finite group transformations with their transformation parameter as an argument. Thus a general Poincar\'e transformation $(\Lambda,a)$ will be written as $\hat U(\Lambda, a)$.} translation on the state $|p,\alpha\rangle$ by acting with $\hat U(\mathbbm{1},a)$? We can write such a translation as the exponentiation of the translation generator, the momentum operator,
% \begin{align}
%   \hat U(\mathbbm{1},a) |p,\alpha\rangle &= e^{ia\cdot\hat{P}}|p,\alpha\rangle\\
%   &= e^{ia\cdot p}|p,\alpha\rangle.\label{eq:SUSYreps:translation:momentum}
% \end{align}
% Easy-peasy Now we'd like to understand how Lorentz-transformed states behave under translations (we'll see why in just a moment). To this end let us consider the state 
% \begin{align}
%   |p,\alpha\rangle_\Lambda &\equiv \hat U(\Lambda,0)|p,\alpha\rangle\label{eq:SUSYreps:p:alpha:lambda}.
% \end{align}
% Of course the operator $\hat U(\Lambda,0)$ generically has some non-trivial $\alpha$ index structure acting on the spin quantum numbers, so one would rather expect a definition more like
% \begin{align}
%   |p,\alpha\rangle_\Lambda &= \hat U(\Lambda,0)_{\alpha\beta}|p,\beta\rangle.
% \end{align} 
% We know, however, that we are free to choose a basis of spin states where $\hat U(\Lambda,0)_{\alpha\beta}$ is diagonal, hence the definition (\ref{eq:SUSYreps:p:alpha:lambda}) is sensible. Let us act on the state $p,\alpha\rangle_\Lambda$ with $\hat U(\mathbbm{1},a)$.
% %
% According to the %Poincar\'e 
% multiplication law of \Equation (\ref{eq:SUSYalg:poincare:multiplication}),
% \begin{align}
%   \hat U(\mathbbm{1},a)\ |p,\alpha\rangle_\Lambda &= \hat U(\mathbbm{1},a)\,\hat U(\Lambda,0)\,|p,\alpha\rangle\\
%   &= \hat U(\Lambda,0)\, \hat U(\mathbbm{1},\Lambda^{-1}a) \,|p,\alpha\rangle\\
%   &= e^{i\Lambda^{-1}a\cdot p}\,U(\Lambda,0)\,|\p,\alpha\rangle\\
%   &= e^{ia\cdot\Lambda p}|p,\alpha\rangle_\Lambda.\label{eq:SUSYreps:translation:lorentz}
% \end{align}
% In the penultimate line we have just used the fact that $e^{i\Lambda^{-1}a\cdot p}$ is a scalar with no group structure and in the final line we've used $(\Lambda_\nu^{\phantom \nu \mu} a^\nu) p_\mu = a^\nu (\Lambda_\nu^{\phantom\nu\mu}p_\mu)$. Well, that was a cute calculation. But what was the point? The point is this: because of \Equation (\ref{eq:SUSYreps:translation:momentum}), we know that \Equation (\ref{eq:SUSYreps:translation:lorentz}) implies that the state $|p,\alpha\rangle_\Lambda = \hat U(\Lambda,0)\,|p,\alpha\rangle$ is part of the space $\mathscr{H}_{\Lambda p}$, i.e. $|p,\alpha\rangle_\Lambda \in \mathscr{H}_{\Lambda p}$. In other words, if we act on a state of momentum $p$ with a Lorentz transformation $\Lambda$, then the resulting state has momentum $\Lambda p$. In fact, since we work in a basis where $\hat U(\Lambda,0)$ is diagonal in spin indices, we may identify
% \begin{align}
%   |p,\alpha\rangle_\Lambda &= |\Lambda p,\alpha\rangle.
% \end{align} 
% Good job, Captan Obvious. Isn't all this true tautologically? Yes, if you're a physicist; but sometimes the mathematically-inclined need some convincing\footnote{If you think about it too much then it becomes non-trivial. The goal of theoretical physicists should be to think about things \textit{just} hard enough to generate new and deep insights without thinking so hard that you no longer believe them.}.
% %
% As you might have expected, we can continue this line of thought to uncover further mathematically-rigorous ways of saying physically obvious statements. Don't worry, I promise that this is going somewhere.
% 
% %% THE BOX BELOW IS ACTUALLY WRONG
% % \framemargin
% % \begin{framed}
% %     \noindent\textbf{Why did we name it $|p,\alpha\rangle_\Lambda$?} We've actually skimmed past a subtle point. We introduced the state $|p,\alpha\rangle_\Lambda$, defined in \Equation (\ref{eq:SUSYreps:p:alpha:lambda}). We then showed that this state is part of $\mathscr{H}_{\Lambda p}$ and is therefore a state with momentum $\Lambda p$, $|\Lambda p, \cdots\rangle$. Once we showed this, why didn't we just write
% %     \begin{align}
% %         |p,\alpha\rangle_\Lambda\equiv\hat U(\Lambda,0)\,|p,\alpha\rangle&\stackrel{?}{=}|\Lambda p,\alpha\rangle
% %     \end{align} 
% % instead of having to keep writing $|p,\alpha\rangle_\Lambda$? The reason is that, in general, \textit{$\hat U(\Lambda,0)$ also affects the $\alpha$s}! If the $\alpha$s labelled only internal quantum numbers (such as gauge indices) then this is no problem, but we also expect the $\alpha$s to contain information about spin angular momentum which \textit{is} part of the Poincar\'e group and \textit{should} change under Lorentz transformations. More theoretically, we want our analysis to be as general as possible. This will come up again rather shortly.
% % \end{framed}
% % \framemargin 
% 
% \subsection{Tracks and the little group}
% 
% In addition to $\mathscr H_k$, let us define larger subspaces $\mathscr H_{\{\Lambda k\}}$ that include all states with a momentum $q$ that can be related to the momentum $k$ by a Lorentz transformation,
% \begin{align}
%   \mathscr H_{\{\Lambda k\}} &= \left\{|q,\alpha\rangle \;|\; \exists \,\Lambda \text{ such that } q = \Lambda \right\}.
% \end{align}
% Heuristically one could write $\mathscr{H}_{\{\Lambda k\}} = \sum_i\mathscr{H}_{\Lambda_ik}$. Since we now know with excessive formality that Lorentz transformations $\hat U(\Lambda,0)$ take states $|p,\alpha\rangle$ to $|p,\alpha\rangle_\Lambda = |\Lambda p,\alpha\rangle$ and that translations do not induce any non-trivial transformation of states' quantum numbers\footnote{One relaxes this assumption when introducing `twists' to field representations on compactified extra dimensions. We'll get to this in \Chapter ***.} the space $\mathscr H_{\{\Lambda k\}}$ is invariant under the Poincar\'e group. Each of these spaces can be represented by a \textbf{track}\index{track} or \textbf{mass-shell surface}\index{mass-shell surface|see{track}}, a hyperboloid in 4-momentum space, as shown in \Figure \ref{fig:SUSYreps:hyperboloid}. These tracks are, by definition, invariant under the action of the Poincar\'e group and will be the `elements' of the space of Poincar\'e irreps. 
% 
% \begin{figure}[l!ht]
%   \begin{center}
%       %
%       \begin{tikzpicture}[domain=-4:4, range=-4:4, scale=.75]
%       %   \draw[color=red]    plot    (\x,\x) node[right] {$f(x)=x$};
%           \draw[color=red,rotate=45,domain=.2:1, range=0:1]   plot    (\x,{1/\x}) node[right] {};
%           \draw[color=red, rotate=45,domain=.2:1, range=0:1]  plot    (-\x,{1/\x})    node[right] {};
%           \draw[color=red,rotate=-45,domain=.2:1, range=0:1]  plot    (\x,{1/\x}) node[right] {};
%           \draw[color=red, rotate=-45,domain=.2:1, range=0:1] plot    (-\x,{1/\x})    node[right] {};
%           \draw[color=red,rotate=135,domain=.2:1, range=0:1]  plot    (\x,{1/\x}) node[right] {};
%           \draw[color=red, rotate=135,domain=.2:1, range=0:1] plot    (-\x,{1/\x})    node[right] {};
%           \draw[color=red,rotate=-135,domain=.2:1, range=0:1] plot    (\x,{1/\x}) node[right] {};
%           \draw[color=red, rotate=-135,domain=.2:1, range=0:1]    plot    (-\x,{1/\x})    node[right] {}; 
%           \draw[color=blue]   plot    (-\x,\x)    node[right] {};
%           \draw[color=blue]   plot    (\x,\x) node[right] {};
%           \draw[->] (0,0) -- (0,4) node[right] {$p^0$};
%           \draw[->] (0,0) -- (0,-4) node[right] {};
%           \draw[->] (0,0) -- (4,0) node[right] {$|\mathbf{p}|$};
%           \draw[->] (0,0) -- (-4,0) node[right] {};
%           \draw[color=blue] (4.1,4) node[right] {$p^2=0$};
%           \draw[color=blue] (4.1,3.5) node[right] {$p^0>0$};
%           \draw[color=red] (0.1,3.2) node[right] {$p^2=m^2$};
%           \draw[color=red] (0.1,2.6) node[right] {$p^0>0$};
%           \draw[color=red] (1.5,0.5) node[right] {$p^2=-m^2$};
%           \draw[color=red] (0.1,-2.9) node[right] {$p^2=m^2$};
%           \draw[color=red] (0.1,-3.5) node[right] {$p^0<0$};
%           \draw[color=blue] (4.1,-3) node[right] {$p^2=0$};
%           \draw[color=blue] (4.1,-3.5) node[right] {$p^0<0$};
%           \draw[->,color=purple, line width=0.75 mm] (0,0) -- (0,1.5) {};
%           \draw[color=purple] (-.7,1) node[right] {$\hat p$};
%       \end{tikzpicture}
%       %
%       \caption{Hyperboloids representing tracks of different characteristic momenta (e.g. $\hat p$), i.e. different irreducible representations of the Poincar\'e group. The full hyperboloids are given by rotating these cross sections about the $p^0$ axis.}
%       \label{fig:SUSYreps:hyperboloid}
%   \end{center}
% \end{figure}
% %
% It is clear that each track can be completely described by one (arbitrarily chosen) \textbf{characteristic momentum}\index{characteristic momentum}, $\hat p$. Canonical choices for characteristic momenta are:
% %
% % \begin{table}
%   \begin{center}
%       \begin{tabular}{|lcl|}
%           \hline
%           \textbf{Track} &\quad& \textbf{Characteristic} $\hat p$\\ \hline
%           $p^2=m^2>0$,\quad $p^0>0$       &\quad& $(m,\mathbf{0})$\\
%           $p^2=m^2>0$,\quad $p^0<0$       &\quad& $(-m,\mathbf{0})$\\
%           \hline
%           $p^2 = 0$,\quad $p^0>0$         &\quad& $(1,0,0,1)$\\
%           $p^2 = 0$,\quad $p^0<0$         &\quad& $(-1,0,0,1)$\\
%           \hline
%           $p^\mu=0$                   &\quad& $(0,\mathbf 0)$\\
%           \hline
%           $p^2=-m^2 <0$               &\quad& $(0,0,0,m)$\\
%           \hline
%       \end{tabular}.      
%   \end{center}
%   % \caption{Characteristic momenta .}
%   % \label{table:SUSYreps:characteristic:momenta}
% % \end{table}
% %
% %
% We separate out the positive and negative energy tracks $\pm p^0 >0$ since we know that physical states have non-negative energy. A fancy way of saying this is that the sign of $p^0$ is a sort of Casimir operator.
% For any (not-characteristic) momentum $p$ on a given track with characteristic momentum $\hat p$, define $\hat L(p)$ to be a Lorentz transformation that takes $\hat p$ to $p$,
% \begin{align}
%    L(p)\hat p &= p.
% \end{align}
% The power of defining such characteristic momenta is that we may now use \Equation (\ref{eq:SUSYreps:p:alpha:lambda}) to write down any state $|p,\alpha\rangle$ in terms of a state with the characteristic momentum of the track associated with $p$,
% \begin{align}
%   |p,\alpha\rangle &\equiv \hat U\big(L(p)\big) |\hat p, \alpha\rangle = |\hat p,\alpha\rangle_{L(p)}.\label{eq:SUSYreps:state:characteristic:momentum}
% \end{align}
% For simplicity we've dropped the second argument of $\hat U$ when it is zero: $\hat U(\Lambda,0)\equiv\hat U(\Lambda)$.
% %
% %Physically we shall identify a particle's momentum with its track. This is an identification of a \textit{continuum} of momentum states.\footnote{Already one can see how we can resolve the issue that non-compact groups have infinite dimensional representations that we identified in \Section \ref{sec:SUSYalg:nonunitary}.} This is essentially the statement that a particle is still the same particle if we look at it from a different frame.
% 
% % * Physically identify a particle's momentum with its track. Continuum of states identified. A particle is still the same particle if we're in a different frame.
% % * Still a further continuum of mass-squared that characterize each track. But this isn't a problem since we know that particles can come in any mass. The important thing is that within an irrep the particles are in finite-dimensional reps up to the idenfitication of momenta within a track.
% 
% %% BOX BELOW IS ALSO WRONG
% % \framemargin
% % \begin{framed}
% %     \noindent\textbf{Defining states relative to $|\hat p,\alpha\rangle$}. There is something rather subtle going on here that is worth mentioning. Upon closer examination, the indices in \Equation (\ref{eq:SUSYreps:state:characteristic:momentum}) seem rather fishy. If we explicitly write out the indices of the $\hat U(\Lambda)$,
% % what one would have \textit{expected} is something like
% %         \begin{align}
% %             |p,\alpha\rangle &\stackrel{?}{=} \hat U\big(L(p)\big)_{\alpha\alpha'}|\hat p,\alpha'\rangle,
% %         \end{align}
% %         where we've written out the $\alpha$ and $\alpha'$ indices explicitly and there is a sum over the $\alpha'$. Contrary to this, however, \Equation (\ref{eq:SUSYreps:state:characteristic:momentum}) has the \textit{same} index $\alpha$ on the left- and right-hand sides. Shouldn't there have been an analogous implicit sum over intermediate states? No.
% % %
% % The point is that all states are defined relative to to some reference `characteristic state' with momentum $\hat p$ and some quantum numbers $\alpha$. Internal quantum numbers completely decouple, but one should be a little careful about spin quantum numbers since we expect the Poincar\'e group to act non-trivially on them. 
% % 
% % \noindent The way to interpret \Equation (\ref{eq:SUSYreps:state:characteristic:momentum}), then, is to say that a state $|p,\alpha\rangle$ is defined by boosting the characteristic state with the same quantum numbers $\alpha$ (particularly spin) by the appropriate Lorentz transformation $L(p)$. (This transformation should be defined \textit{a priori} if multiple $L(p)$s exist.)
% % 
% % \noindent If one were being \textit{especially} careful, one would question why the state $| p,\alpha\rangle$ should necessarily be obtainable by a characteristic state $|\hat p,\alpha\rangle$ with the \textit{same} [spin] quantum number $\alpha$. In this case we can appeal to physical intuition. If the particle is massive, then we can boost into its rest frame and different spin states are connected by a Lorentz transformation so we're free to pick a characteristic state with the same $\alpha$ as $|p,\alpha\rangle$ since all such states are on the same track. On the other hand, if the particle is massless, then the spin is defined relative to the momentum and there is no way to boost to a frame where the particle has a different helicity. Thus we can always pick a characteristic state with the same momentum.
% % 
% % \noindent If you're not satisfied with an argument based on $a posteriori$ knowledge, we can make some more formal (perhaps unnecessarily so) appeals and treat \Equation (\ref{eq:SUSYreps:state:characteristic:momentum}) purely as a \textit{definition}. Sure, the indices are wonky, but it will turn out that we won't actually care about the index structure of $|p,\alpha\rangle_\Lambda$, only that it belongs to part of the track $\mathscr H_{\{\Lambda p\}}$. 
% % \end{framed}
% % \framemargin
% 
% Let us define the \textbf{little group}\index{little group} of $p$, $H_{ p}$ to be the subgroup of Lorentz transformations that leave the four-vector $p$ unchanged,
% \begin{align}
%   H_{p} &= \{\Lambda \;|\; \Lambda p =  p\}.
% \end{align}
% Sometimes this is called the \textbf{stability group}\index{stability group|see{little group}} or \textbf{invariance group} of $p$.
% For example, in $SO(3)$ the little group of a vector $\mathbf{v}$ is the $SO(2)$ subgroup of rotations about $\mathbf{v}$.
% %
% Don't confuse this with $\mathscr H_k$ or $\mathscr H_{\{\Lambda k\}}$, which are spaces of states rather than transformations.
% 
% We will be particularly interested in transformations that leave the characteristic momentum $\hat p$ unchanged, i.e. the little group $H_{\hat p}$. The reason why these particular transformations are useful is that we will write out all of our Poincar\'e states $|p,\alpha\rangle$ as a Lorentz transform $L(p)$ of a representative state $|\hat p,\alpha\rangle$ with the track's characteristic momentum $\hat p$. Distinct elements of an irreducible representation will correspond to different states in the representation of the characteristic momentum's little group. One obtains nontrivial elements of the little group if there exist more than one Lorentz transformation, e.g. $ L_1(p),  L_2(p)$, that takes $\hat p$ to $p$:
% \begin{align}
%    L_1^{-1}(p)  L_2(p) \,\hat p &= \hat p,
% \end{align}
% and so $ L_1^{-1}(p)  L_2(p) \in H_{\hat p}$.
% 
% \framemargin
% \begin{framed} % From Buchbinder and Kuzenko Sec 1.5.4
%   \noindent\textbf{The little group and the Pauli-Lubanski vector}. The action of a finite Lorentz transformation can be written as the exponential of a linear combination of the generators of the Lorentz algebra,
%   \begin{align}
%       \hat U(\Lambda) &= e^{\frac{i}{2}\omega_{\mu\nu}M^{\mu\nu}}.
%   \end{align}
%   For a Lorentz transformation $\Lambda$, may write the action of $\hat U( \Lambda)$ on a state $|p,\alpha\rangle$ as
%   \begin{align}
%       \hat U(\Lambda) |p,\alpha\rangle &= e^{\frac i2\omega_{\mu\nu}M^{\mu\nu}}|p,\alpha\rangle\\
%       &= \hat C_{\alpha\beta}|(e^{\omega})^\mu_{\phantom\mu\nu} p^\nu,\beta\rangle,
%   \end{align}
%   where $\hat C_{\alpha\beta}$ is some matrix acting on the spin quantum numbers only; it's particular form is of no interest to us at the moment. If we restrict to the case where $\Lambda\in H_{p}$, then the transformed momentum must equal the original momentum,
%   \begin{align}
%       (e^{\omega})^\mu_{\phantom\mu\nu} p^\nu &= p^\mu,
%   \end{align}
%   and hence
%   \begin{align}
%       \omega^\mu_{\phantom\mu\nu} p^\nu &= 0.
%   \end{align}
%   This has a general solution given by
%   \begin{align}
%       \omega_{\mu\nu} &= \epsilon_{\mu\nu\rho\sigma}p^\rho q^\sigma,
%   \end{align}
%   where $q$ is any arbitrary four-vector. Is this starting to look familiar? If we restrict the action to elements of the space $\mathscr H_{p}$, we may write down general elements of the little group $\Lambda_p(b,n)$ as
%   \begin{align}
%       \Lambda_p(b,q) &= \exp\left(-ib_\mu P^\mu+ \frac i2 \epsilon_{\mu\nu\rho\sigma}p^\mu q^\nu M_{\rho\sigma}\right)\\
%       &= \exp\left(-ib_\mu P^\mu+ i q_\mu W^\mu\right).
%   \end{align}
%   We welcome back our friend, the Pauli-Lubanski vector $W_\mu$, which appears to describe the Lorentz action of an element of the little group $H_p$ on a state in $\mathscr H_p$. To be absolutely clear, this is the statement: $W_\mu$ describes the action of the little group the momentum four-vector $p$ acting on states with precisely that momentum $p$.
%   
%   \noindent Let's try to interpret this in a way that foreshadows some upcoming results. By definition elements of $\mathscr H_p$ have the same momentum. The only  quantum number affected by the Poincar\'e group is spin, and so we expect (as mentioned earlier) that the Pauli-Lubanski vector indeed transforms states' spin polarizations. 
% \end{framed}
% \framemargin
% 
% \subsection{Wigner Decomposition}
% 
% %We'd like to write out our states $|p,\alpha\rangle$ in terms of the appropriate state $|\hat p,\alpha\rangle$ on the same track but with the track's characteristic momentum $\hat p$. 
% The next thing that we'll need is a rather obvious result: acting on characteristic momentum state $|\hat p,\alpha\rangle$ with an element from the little group $\Lambda_{\hat p} \in H_{\hat p}$ only acts on the $\alpha$ quantum numbers and leaves the state's momentum unchanged. If that doesn't sound mind-numbingly obvious, read it again. Written out formally, this statement is
% \begin{align}
%   \hat U(\Lambda_p,0)\,|\hat p,\alpha\rangle &= \hat D_{\alpha\alpha'}(\Lambda_p) \, |\hat p,\alpha'\rangle,\label{eq:SUSYreps:Poincare:littlegroup:action}
% \end{align}
% where $\hat D_{\alpha\alpha'}(\Lambda_{\hat p})$ is the representation of the element of the little group $\tilde\Lambda$. There is an implied sum over $\alpha'$ which is shorthand for `matrix' multiplication on the non-momentum quantum numbers. The point is that $\hat D_{\alpha\alpha'}$ is a scalar with respect to the Lorentz group. This is all obvious\footnote{I don't say this to be condescending, but rather to explain that if you're confused it's probably because you're over-thinking it.}.
% 
% Ok, back to task. For a \textit{general} Lorentz transformation $\Lambda$ acting on a \textit{general} state $|p,\alpha\rangle$, we can do a bit of sleight of hand. 
% \begin{align}
%   \hat U(\Lambda,0)\,|p,\alpha\rangle &= \hat U(\Lambda)\, \hat U\big(L(p)\big) |\hat p,\alpha\rangle\\
%   &= \hat U\big(L(\Lambda p)\big)\,\hat U\big(L^{-1}(\Lambda p)\big)\, \hat U(\Lambda)\, \hat U\big(L(p)\big) |\hat p,\alpha\rangle\\
%   &= \hat U\big(L(\Lambda p)\big)\,\hat U\big{(}\underbrace{L^{-1}(\Lambda p)\cdot\Lambda\cdot L(p)}_{\equiv\, \tilde\Lambda_p\;\in\, H_{\hat p}}\big{)} |\hat p,\alpha\rangle\label{eq:SUSYreps:Poincare:transform:state:1}\\
%   &= \hat U\big(L(\Lambda p)\big)\,\hat D_{\alpha\alpha'}(\tilde\Lambda_p)|\hat p,\alpha'\rangle\\
%   &= \hat D_{\alpha\alpha'}(\tilde\Lambda_p)\,\hat U\big(L(\Lambda p)\big)|\hat p,\alpha'\rangle\label{eq:SUSYreps:Poincare:transform:state:2}\\
%   &= \hat D_{\alpha\alpha'}(\tilde\Lambda_p)|\hat p,\alpha'\rangle_\Lambda\label{eq:SUSYreps:Poincare:transform:state:3}
% \end{align}
% %
% We used the `trick' of inserting $\mathbbm{1}=\hat U\big(L(\Lambda p)\big)\,\hat U\big(L^{-1}(\Lambda p)\big)$ so that we could identify one of the products of operators as a representation of an element of the little group, $L^{-1}(\Lambda p)\cdot\Lambda\cdot L(p)$ in \Equation (\ref{eq:SUSYreps:Poincare:transform:state:1}). We then use the definition of the action of the little group from \Equation (\ref{eq:SUSYreps:Poincare:littlegroup:action}) and use the fact that each $\hat D_{\alpha\alpha'}$ is just a scalar (with an implied sum over $\alpha'$) push $\hat U\big(L(\Lambda p)\big)$ past it and act on the state.  Finally, in the last line we invoke our (slightly unusual) definition for $|p,\alpha\rangle_\Lambda$ in \Equation (\ref{eq:SUSYreps:p:alpha:lambda}), with the reminder that $\hat U$ is diagonal in $\alpha$ indices.
% 
% % ***** Confusion: $|p,\alpha\rangle_\Lambda = |\Lambda p,\alpha\rangle$ or more generally $|\Lambda p,\alpha'\rangle$.?? This is very subtle! This is a \textit{definition}. $|p,\alpha\rangle \equiv U(L(p))|\hat p,\alpha\rangle$. We are NOT saying that $U(L(p))$ has no $\alpha$ structure -- we're simply defining the left hand side w/rt right hand side. (This involves and arbitrary choice of $L(p)$s.) In particular
% % \begin{align}
% %     |p,\alpha\rangle \equiv U(L(p))_{\alpha'\alpha}|\hat p,\alpha\rangle,
% % \end{align}
% % so there (in general, probably not really, but we haven't proven it) IS an actual matrix multiplication going on in a sense. 
% 
% % %% Yep. This box is all wrong too.
% % \framemargin
% % \begin{framed}
% %     \noindent\textbf{Wait, we can commute those?} \textit{[This box is rather excessively pedantic and should be skipped if you're comfortable with the above manipulations.]}
% % %   The formal manipulations have been a little bit tedious here, especially since it's not yet clear what the punchline is (we'll get to that right after this note). First, however, let's clear up a subtle algebraic point that may be confusing. 
% % In \Equation (\ref{eq:SUSYreps:Poincare:transform:state:2}) we commuted $\hat U\big(L(\Lambda p)\big)$ with $\hat D_{\alpha\alpha'}(\tilde\Lambda_p)$ citing that $\hat D_{\alpha\alpha'}$ is just a scalar quantity. One might object, however, that no---it is not `really' a scalar since it's formally a matrix acting on a vector. ``\textit{Just look,}'' one might say, ``\textit{there's a sum over the $\alpha'$ index. It's a matrix.}'' Further, one might go on to say, ``\textit{And look at $\hat U$! This is also a matrix, since it should act at least on the spin index that we know is hiding somewhere in the $\alpha$s. These two matrices needn't commute.}''
% %     
% %     \noindent This is why we made so many rather formal statements in previous boxes about the meaning of \Equations (\ref{eq:SUSYreps:p:alpha:lambda}) and (\ref{eq:SUSYreps:state:characteristic:momentum}). Let's continue and say a few more words. Let's keep in mind that both $\hat U\big(L(\Lambda p)\big)$ and $\hat D(\tilde \Lambda_p)$ are representations of Lorentz transformations. The only difference is that $\hat U\big(L(\Lambda p)\big)$ performs a non-trivial transformation of $p$ while $\hat D(\tilde \Lambda_p)$ preserves $p$ (e.g. is a rotation along the axis of $p$). Perhaps sitting and staring at the equations with this reminder might help clarify the picture.
% %     
% %     \noindent In light of our `physically intuitive' comments from the previous box, one can work backwards from \Equation (\ref{eq:SUSYreps:Poincare:transform:state:2}) to the line before it, arguing that there exists a Lorentz transformation that is diagonal in the $\alpha$ indices. If you refuse to accept this \textit{a posteriori} argument, however, one can literally do the expansion
% %     \begin{align}
% %         \hat U\big(L(\Lambda p)\big) \hat D_{\alpha \alpha'_1}(\tilde\Lambda_p)|\hat p,\alpha'_1\rangle + \hat U\big(L(\Lambda p)\big) \hat D_{\alpha \alpha'_2}(\tilde\Lambda_p)|\hat p,\alpha'_2\rangle + \cdots
% %     \end{align}
% %     and then commute the $U\big(L(\Lambda p)\big)$ past the \textit{manifestly scalar} $D_{\alpha \alpha'_i}$s,
% %     \begin{align}
% %         \hat D_{\alpha \alpha'_1}(\tilde\Lambda_p)\hat U\big(L(\Lambda p)\big)|\hat p,\alpha'_1\rangle + \hat D_{\alpha \alpha'_2}(\tilde\Lambda_p)\hat U\big(L(\Lambda p)\big)|\hat p,\alpha'_2\rangle + \cdots.
% %     \end{align}
% %     The states $\hat U\big(L(\Lambda p)\big)|\hat p,\alpha'_i\rangle$ are now well defined to be
% %     \begin{align}
% %         \hat U\big(L(\Lambda p)\big) |\hat p,\alpha'_i\rangle &= |\hat p,\alpha'_i\rangle_{L(\Lambda p)}.
% %     \end{align}
% %     If you took our \textit{a priori} physical arguments seriously earlier, then this state is exactly $|\hat p,\alpha'_i\rangle_{L(\Lambda p)} = |\hat p,\alpha'_i\rangle$. (This isn't strictly necessary for our purposes and one can check it explicitly once we look at particular cases later on.)    
% % %   \noindent To make the point abundantly clear, one might then try to write out the explicit sum over $\alpha$ indices between the two matrices. Naively, one would expect something trivial like normal matrix multiplication from kindergarden-level linear algebra:
% % %   \begin{align}
% % %       \mathbf{AB}\vec{v} &= A^i_{\phantom ij}B^{j}_{\phantom jk} v^k,\label{eq:SUSYreps:kindergarden:matrix}
% % %   \end{align}
% % %   but alas, it looks like we've pulled a fast one since \Equation (\ref{eq:SUSYreps:p:alpha:lambda}) looks wonky:
% % %   \begin{align}
% % %       |p,\alpha\rangle_\Lambda &\equiv \hat U(\Lambda,0)|p,\alpha\rangle.\tag{\ref{eq:SUSYreps:p:alpha:lambda}}
% % %   \end{align}
% % %   What the heck? What one would have \textit{expected} is something like
% % %   \begin{align}
% % %       |p,\alpha\rangle_\Lambda &\stackrel{?}{=} \hat U(\Lambda,0)_{\alpha\alpha'}|p,\alpha'\rangle,
% % %   \end{align}
% % %   where we've written out the $\alpha$ and $\alpha'$ indices explicitly. That would have indeed matched the naive kindergarden matrix multiplication of \Equation (\ref{eq:SUSYreps:kindergarden:matrix}). Did we make a mistake? No. I bet you thought I made a typo earlier, didn't you? I didn't, thank you very much.
% % %   
% % % \noindent The point is that \Equation (\ref{eq:SUSYreps:p:alpha:lambda}) is a \textit{definition}. We chose this definition with the benefit of hindsight knowing that we won't actually care about the index structure of $|p,\alpha\rangle_\Lambda$, only that it belongs to part of the track $\mathscr H_{\{\Lambda p\}}$. This will have some 
% % % 
% % % 
% % % ...\noindent Alternately, one can take the approach of Ryder \cite{Ryder:1996} and \textit{define} the state $|p,\alpha\rangle \equiv$
% % %
% % % \noindent For the sake of overkill, let's make the indices explicit to see what our funny definition really means. The $\alpha$'s index a vector space. Let us write a basis for this vector space as $\mathbf{e}^{(i)}_{\phantom{(i)}j}$ where the $(\alpha)$ indexes the basis element while $\beta$ indexes the component of that basis vector.
% % % % (If you're confused, the usual Cartesian basis vectors for Euclidean space are $\mathbf{e}^{(i)}_{\phantom{(i)}j}=\delta^i_j$.) 
% % % We can thus be \textit{really} pedantic and write out a state as
% % % \begin{align}
% % %   |p,\alpha_i\rangle &=|p,\alpha_j \mathbf{e}^{(j)}_{\phantom{(j)}i}\rangle.
% % % \end{align}
% % % With this notation the $\hat D_{\alpha\alpha'}$ can be written as $\hat D_{ij}$ so that the action of an element of the little group is given by
% % % \begin{align}
% % %   D_{ij} |p,\alpha_i\rangle &= D_{ij}|p,\alpha_k \mathbf{e}^{(k)}_{\phantom{(k)}i}\rangle.
% % % \end{align}
% % % 
% % % What we meant, then, in \Equation (\ref{eq:SUSYreps:p:alpha:lambda}) is that a 
% % % \begin{align}
% % %   |p,\alpha\rangle_\Lambda &= \hat U(\Lambda,0)_{ij} |p,\alpha_k \mathbf{e}^{(k)}_{\phantom{(k)}i}\rangle.
% % % \end{align}
% % \end{framed}
% % \framemargin
% 
% Here's the point: the action of the little group on any state on a track $\mathscr H_{\{\Lambda \hat p\}}$ has the same structure as its action on the state with the track's characteristic momentum $\hat p$. Thus, in order to determine the action of a general Lorentz transformation on a representation of the Poincar\'e group, one only needs to understand action of the little group on a state with the track's [arbitrarily chosen] characteristic momentum. This is an example of an \textbf{induced representation}\index{induced representation} whereby the representation of a group is given by a subgroup (in this case, the little group). This was first elucidated in Wigner's classic 1939 paper \cite{Wigner:1939cj}; thus we now call $\hat D$ a \textbf{Wigner rotation}\index{Wigner rotation} and the expression (\ref{eq:SUSYreps:Poincare:transform:state:3}) a \textbf{Wigner decomposition}\index{Wigner decomposition}. The curious reader is encouraged to peruse this topic further with the accounts in \Chapter 3 of Sternberg \cite{Sternberg:1994tw} or Straumann's review talk \cite{Straumann:2008kq}. As with most mathematical literature, it should be much easier to read once you already know what they're trying to tell you.
% 
% Now we get to the punchline: an irreducible representation of the Poincar\'e group corresponds to a characteristic momentum (i.e. a track) and a representation of the little group for that momentum. Let's update our list of tracks, then, with the little group for each characteristic momentum; this is done in Table \ref{table:SUSYreps:tracks}.
% %
% \begin{table}
% \begin{center}
%   \begin{tabular}{|llclcc|}
%       \hline
%       \textbf{Track} &&\quad& \textbf{Characteristic} $\hat p$ & $H_{\hat p}$&\textbf{Physical?}\\ \hline
%       $p^2=m^2>0$,& $p^0>0$       &\quad& $(m,\mathbf{0})$& $SO(3)$&Yes\\
%       $p^2=m^2>0$,& $p^0<0$       &\quad& $(-m,\mathbf{0})$& $SO(3)$&No\\
%       \hline
%       $p^2 = 0$,& $p^0>0$         &\quad& $(1,0,0,1)$& $E_2$&Yes\\
%       $p^2 = 0$,& $p^0<0$         &\quad& $(-1,0,0,1)$& $E_2$&No\\
%       \hline
%       $p^\mu=0$ &                 &\quad& $(0,\mathbf 0)$& $SL(2,\mathbb{C})$&Yes\\
%       \hline
%       $p^2=-m^2 <0$ &             &\quad& $(0,0,0,m)$& $SU(1,1)$&No\\
%       \hline
%   \end{tabular}.      
% \end{center}
% \caption{Irreducible representations of the Poincar\'e group. $E_2$ refers to the Euclidean group of the 2-plane. $SL(2,\mathbb{C})$, as previously established, is the universal cover of the Lorentz group. $SU(1,1)$ is the group that leaves $|z_1|^2-|z_2|^2$ invariant.}\label{table:SUSYreps:tracks}
% \end{table}
% %
% 
% Physical states correspond to those with non-negative energy and mass-squared, so we can restrict ourselves to such states when constructing representations of the Poincar\'e group. 
% 
% 
% \subsection{The vacuum state}
% 
% Let's start with the simplest track, $\hat p = (0,\mathbf{0})$. This corresponds to the track of the vacuum. The little group corresponds to the orthochronous Lorentz group, which we already know is universally covered by $SL(2,\mathbb{C})$.  The unitary irreps of this group are infinite dimensional, as we mentioned warily in \Section \ref{sec:SUSYalg:nonunitary}. This isn't a problem for the vacuum, however, since it lives in the trivial representation of the Lorentz group, 
% \begin{align}
%   \Lambda &\rightarrow \mathbbm{1}.
% \end{align}
% Thus we have a single vacuum $|0\rangle$ with the property that
% \begin{align}
%   \hat U(a,\Lambda) |0\rangle &= |0\rangle.
% \end{align}
% 
% Very Zen.
% 
% \subsection{Massive Representations}
% 
% For the case of massive particles one can always boost into a frame where
% \begin{align}
%   p^\mu &= (m,0,0,0).
% \end{align}
% We search for generators that leave $p^\mu = (m,0,0,0)$ invariant. This is given by the generators of the rotation group, $SO(3)$. We say that $SO(3)$ is the \textbf{stability group}\index{stability group} or the \textbf{little group}\index{little group}. This implies that we may use labels $j$ and $j^3$ as we did before. 
% 
% This sheds a little light on the nature of $W_\mu$. We notice that $W_0=0$ and $W_i=mJ_i$. In the massive representation the Pauli-Lubanski vector does not contain any new information; $\omega$ is the same as, for example, $j_3$. 
% 
% We may label elements within an irrep as $|m,j;p^\mu,j_3\rangle$. To be clear, this is \textit{precisely} what we mean by a \textbf{one-particle state}\index{one-particle state}, i.e. the definition of an elementary particle.
% 
% \subsection{Massless Representations}
% 
% For massless particles we are unable to boost into a rest frame. The best we can do is boost into a frame where
% \begin{align}
%   p^\mu &= (E,0,0,-E).
% \end{align}
% Looking at this, we expect once again that the stability group is $SO(2)$. This is indeed correct, though a proper analysis is a lot trickier. Writing out each element of the Pauli-Lubanski vector, one finds
% \begin{align}
%   W_0 &= EJ_3\\
%   W_1 &= E(-J_1+K_2)\\
%   W_2 &= E(J_2 - K_1)\\
%   W_3 &= EJ_3,
% \end{align}
% from which one can write down the commutation relations
% \begin{align}
%   [W_1, W_2] &= 0\\
%   [W_3, W_1] &= -iE\,W_2\\
%   [W_3, W_2] &= \phantom+iE\,W_1.
% \end{align}
% This is the algebra for the two dimensional Euclidean group. Evidently the little group is more than just the $SO(2)$ group we originally expected. There is a problem with this, however. This group has infinite-dimensional representations and hence we get a continuum label for each of our massless states. This, in turn, is patently ridiculous since we don't see massless particles with a continuum of states. We thus restrict to finite dimensional representations by imposing
% \begin{align}
%   W_1 = W_2 = 0.
% \end{align}
% If you want you can consider this an `experimental input\footnote{This argument is certainly unsatisfactory, but it appears to be the best that we can do for the moment.}.' The $W_3$ generates $O(2)$, as we wanted. Then
% \begin{align}
%   W^\mu = \lambda P^\mu,
% \end{align}
% with $\lambda$ defining the helicity of the particle. Recalling that the algebra \textbf{(FLIP: Work this out ***)} requires $e^{4\pi i \lambda} |\lambda\rangle = |\lambda\rangle$, we know that $\lambda \in \pm \frac 12, 1\cdots$; i.e. it takes on the value of a half integer. In fact, for a field theory with massless fields in the representation $(A,B)$, the helicity is given by $\lambda=B-A$. (See p. 253 of Weinberg.) Massless particle states can thus be labelled as
% \begin{align}
%   |0,j;p^\mu,\lambda\rangle.
% \end{align}
% 
% \subsection{Particles and Fields: How unitarity was rescued}\label{eq:SUSYreps:unitarity}
% ... not just unitarity, finite-dimensionlity
% ... we worried about nonunitarity in \Section \ref{sec:SUSYalg:nonunitary}. Until now we've left our concerns swept under a rug. Now that we're armed with the full Poincar\'e group, we can peek back under the rug and finally take care of the dirt.
% 
% PUNCHLINE s
% also: make explicit note about nonunitarity of lorentz rep
% ref: wigner *****
% 
% the subgroup of the Poincar\'e group that leaves $p$ invariant (i.e. $H_{p}$... check definition before... make it general, not just hat) has the same structure for all momenta in the same track. THUS, we can `mod out' in a very loose sense the action of the lorentz group that shifts p and we only have to learn about the action of the little group. This little group is 
% 
% this is what poincare (translations) buys us, the p. More symmetry is more constraints. that's a deep principle.
% 
% ... role of the poincare group in all this... determine momenta that splits reps in to physical and nonphysical states. Or to tracks. and mention finite vs infinite dimenional representations. infinite dimesinoality is now put into infinite number of tracks, but irreps are a single track. 
% 
% Tracks are identified as one particle (really?)
% Space of states is infinite dimensional, equal to a direct sum of the $\mathscr H_{\{\Lambda \hat p\}}$s.
% \begin{align}
%   \mathscr{H} = \bigoplus_{\hat p} \mathscr H_{\{\Lambda \hat p\}}.
% \end{align}
% However, what we shall find is that 
% 
% \url{http://golem.ph.utexas.edu/category/2009/03/unitary_representations_of_the.html}
% 
% \url{http://arxiv.org/abs/0809.4942}
% 
% % * Physically identify a particle's momentum with its track. Continuum of states identified. A particle is still the same particle if we're in a different frame.
% % * Still a further continuum of mass-squared that characterize each track. But this isn't a problem since we know that particles can come in any mass. The important thing is that within an irrep the particles are in finite-dimensional reps up to the idenfitication of momenta within a track.
% 
% 
% \section{$\mathcal N=1$ SUSY}
% 
% What happens when we now supersymmetrize our theory? $C_1=P^2$ is still a Casimir operator. This means that all the particles in a SUSY multiplet have the same mass. Now, however, $C_2=W^2$ is no longer a Casimir. This is rather intuitive since we saw that the Pauli-Lubanski vector had to do with spin and supersymmetry mixes particles of different spins into a single irreducible representation. This is, of course, how it evades the Coleman-Mandula theorem. 
% 
% In place of $C_2$, we can define another Casimir operator, $\tilde C_2$, in a somewhat oblique way:
% \begin{align}
%   \tilde C_2 &\equiv C_{\mu\nu}C^{\mu\nu}\\
%   C_{\mu\nu} &\equiv B_\mu P_\nu - B_\nu P_\mu\\
%   B_\mu &\equiv W_\mu - \frac 14 \overline Q_{\dot\alpha}(\overline{\sigma}_\mu)^{\dot\alpha\alpha}Q_\alpha.
% \end{align}
% Good students will explicitly check, with great pain, that $\tilde C_2$ is indeed a Casimir operator. Thus our irreducible representations still have two labels, but the second one isn't really related to spin any longer.
% 
% \framemargin
% \begin{framed}
% \noindent\textbf{Finding Casimir operators.} It is clear that the whole business of finding a complete set of Casimir operators for a spacetime symmetry is rather important. Here we've just written down the results for the Poincar\'e group and for SUSY. For compact, simple groups it is a bit more straightforward to formulaically determine the Casimirs. For more general groups, on the other hand, there is no clear systematic method. For our purposes we can leave the task of finding a complete set of Casimirs to mathematicians.
% \end{framed}
% \framemargin
% 
% \subsection{Massless Multiplets}
% 
% As before we can boost into a frame where $p_\mu = (E,0,0,E)$. Explicit calculation shows that both Casimir operators vanish,
% \begin{align}
%   C_1 = \tilde C_2 = 0.
% \end{align}
% Now consider the now-familiar anticommutator of $Q$ and $\overline Q$ and write it out explicitly as
% \begin{align}
%   \{Q_\alpha,\overline Q_{\dot \beta}\} = 2(\sigma^\mu)_{\alpha\dot\beta}P_\mu = 2E(\sigma^0+\sigma^3)_{\alpha\dot\beta} = 4E\begin{pmatrix}
%                                                   1 \quad& 0 \\
%                                                   0 \quad& 0
%                                           \end{pmatrix}.
% \end{align}
% In components,
% \begin{align}
%   \{Q_1,\overline Q_{\dot 1}\} &= 4E\label{eq:SUSYreps:massless:Q1}\\
%   \{Q_2,\overline Q_{\dot 2}\} &= 0\label{eq:SUSYreps:massless:Q2}.
% \end{align}
% Recall that the $\overline Q$ is really short-hand for the complex conjugate of $Q$. Thus the product $\overline Q_{\dot\alpha}Q_{\alpha}$ for $\dot\alpha = \alpha$ is something like $|Q_\alpha|^2$ and is non-negative. Thus the second equation tells us that for any massless state $|p_\mu,\lambda\rangle$,
% \begin{align}
%   Q_{2}|p_\mu,\lambda\rangle &= 0\label{eq:SUSYreps:Q2vanish}.
% \end{align}
% To be explicit, one can write
% \begin{align}
%   0 &=\langle p_\mu,\lambda|\{Q_2,\overline Q_{\dot 2}\}|p^\mu,\lambda\rangle\\
%   &= \langle p_\mu,\lambda|Q_2\overline Q_{\dot 2}+\overline Q_{\dot 2}Q_2|p^\mu,\lambda\rangle\\
%   &= \langle p_\mu,\lambda|Q_2\overline Q_{\dot 2}|p^\mu,\lambda\rangle+\langle p^\mu,\lambda|\overline Q_{\dot 2}Q_2|p^\mu,\lambda\rangle\\
%   &= \left|\overline Q_{\dot 2}|p_\mu,\lambda\rangle\right|^2 + \left|Q_2|p_\mu,\lambda\rangle\right|^2,
% \end{align}
% from which each term on the right hand side must vanish and we get \Equation (\ref{eq:SUSYreps:Q2vanish}).
% 
% Using \Equation (\ref{eq:SUSYreps:massless:Q1}) we can define raising and lowering operators,
% \begin{align}
%   a &\equiv \frac{Q_1}{2\sqrt E}\\
%   a^\dag &\equiv \frac{\overline Q_{\dot 1}}{2\sqrt E}.
% \end{align}
% These satisfy the anticommutation relation $\{a,a^\dag\} = 1$. We can now consider the spin of a massless state after acting with these operators.
% \begin{align}
%   J^3 a |p_\mu,\lambda\rangle &= \left(aJ^3 - [a,J^3]\right)\, |p^\mu,\lambda\rangle\\
%   &= \left(aJ^3 - \frac 12 a\right)\,|p_\mu,\lambda\rangle\\ 
%   &= \left(\lambda - \frac 12\right)\, a|p_\mu,\lambda\rangle.
% \end{align}
% In the second line we have used the fact that $[J^3,Q_{1,2}]=\mp\frac 12 Q_{1,2}$. This is just a statement of the helicity of the SUSY generators. Thus if we start with a state $|p_\mu,\lambda\rangle$ of helicity $\lambda$, acting with $a\sim Q_1$ produces a state of helicity $(\lambda-\frac 12)$. Similarly, because $[J^3,\overline Q_{\dot 1,\dot 2}]=\pm\frac 12 \overline Q_{\dot 1,\dot 2}$, acting with $a^\dag \sim \overline Q_{\dot 1}$ produces a state of helicity $(\lambda+\frac 12)$.
% 
% Since this is rather important, let's work through this explicitly: 
% \begin{align}
%   [J_3, Q_\alpha] &= \phantom - [M_{12},Q_\alpha]\\
%   &= - (\sigma^{12})_\alpha^{\phantom\alpha\beta}Q_\beta\\
%   &= -\frac i4 (\sigma^1\overline\sigma^2-\sigma^2\overline\sigma^1)_\alpha^{\phantom\alpha\beta}Q_\beta\\
%   &= \phantom + \frac i4 (\sigma^1\sigma^2-\sigma^2\sigma^1)_\alpha^{\phantom\alpha\beta}Q_\beta\label{eq:SUSYreps:J3Q1}\\
%   &= \phantom + \frac i4 \cdot 2i (\sigma^3)_\alpha^{\phantom\alpha\beta}Q_\beta\label{eq:SUSYreps:J3Q2}\\
%   &= - \frac 12 (\sigma^3)_\alpha^{\phantom\alpha\beta}Q_\beta.\label{eq:SUSYreps:J3Q3}
% \end{align}
% Purists will note that we've been a bit cavalier with index notation, though we hope that this is unlikely to cause confusion\footnote{Equations (\ref{eq:SUSYreps:J3Q1}) - (\ref{eq:SUSYreps:J3Q3}) are meant to be \textit{matrix} relations, i.e. we're ignoring the dotted/undotted and raised/lowered index structure. A mathematician would object that there is no way to use the $\epsilon$ tensor to turn $(\sigma^3)_{\alpha\dot\beta}$ into $(\sigma^3)_{\alpha}^{\phantom\alpha\beta}$, or that it is wrong to drop the bars in \Equation (\ref{eq:SUSYreps:J3Q1}). These are technically not $SL(2,\mathbb C)$ covariant. We don't really care because we ultimately want expressions for the individual components $Q_1$ and $Q_2$. The above equations are meant to mirror the calculation if one actually wrote everything out explicitly as $2\times 2$ matrices. If one wanted to be \textit{precise} with the indices, one would have write, for example,
% \begin{align}
%   [J_3, Q_\alpha] &= -\frac 12 (\sigma^3)_{\alpha\dot\beta} (\overline\sigma^0)^{\dot\beta\gamma}Q_\gamma,
% \end{align}
% where the $\overline\sigma^0$ is just an identity matrix used to convert he index structure of the $\sigma^3$ into a lower-undotted-then-upper-undotted structure. This give us the same result, \Equation (\ref{eq:SUSYreps:JQ}), though it's long-winded and unclear. One can see why we opted for the `heuristic' or `matrix' expressions above.}. If you don't have any problem with these equations, then don't worry about it; you're just thinking like a physicist rather than an anal-retentive mathematician. Anyway, we finally arrive at the conclusion 
% \begin{align}
%   [J^3,Q_{1,2}]&=\mp\frac 12 Q_{1,2}.\label{eq:SUSYreps:JQ}
% \end{align}
% %and thus $a|p_\mu,\lambda\rangle$ has helicity $(\lambda-\frac 12)$. 
% Similarly we may write the commutator for $\overline Q^{\dot\alpha}$,
% \begin{align}
%   [J_3, \overline Q_{\dot\alpha}] &= \phantom - [M_{12},\overline Q_{\dot\alpha}]\\
%   &= - (\overline\sigma^{12})^{\dot\alpha}_{\phantom\alpha\dot\beta}\overline Q^{\dot\beta}\\
%   &= - \frac 12 (-\sigma^3)^{\dot\alpha}_{\phantom\alpha\dot\beta}\overline Q^{\dot\beta}.
% \end{align}
% Note that the $\sigma^3$ now has an additional sign relative to the left-handed case. This is because $\overline\sigma^{12} = - \sigma{12}$, thus we have
% \begin{align}
%   [J^3,\overline Q^{\dot 1,\dot 2}]&=\pm\frac 12 \overline Q^{\dot 1,\dot 2},
% \end{align}
% or lowering the indices on both sides,
% \begin{align}
%   [J^3,\overline Q_{\dot 1,\dot 2}]&=\pm\frac 12 \overline Q_{\dot 1,\dot 2}\label{eq:SUSYreps:JQbar}.
% \end{align}
% 
% Thus we can finally write down the helicities of our states,
% \begin{align}
%   |p_\mu,\lambda\rangle \quad & \quad \text{helicity}\; \left.\lambda\right.\\
%   a|p_\mu,\lambda\rangle \quad & \quad \text{helicity}\; \left(\lambda-\frac 12\right)\\
%   a^\dag|p_\mu,\lambda\rangle \quad & \quad \text{helicity}\; \left(\lambda+\frac 12\right).
% \end{align}
% %
% %
% Now we're cookin'. Let's build a (super)multiplet. We start with a state that is annihilated by the lowering operator, i.e. a state of minimum helicity $|\Omega\rangle = |p_\mu,\lambda\rangle$ such that $a|\Omega\rangle = 0$. The next state we can construct comes from acting on $|\Omega\rangle$ with a creation operator,
% \begin{align}
%   a^\dag|\Omega\rangle = |p_\mu,(\lambda+\frac 12)\rangle.
% \end{align} 
% What next? We could try acting with another creation operator, $a^\dag a^\dag|\Omega\rangle$, but $a^\dag a^\dag \equiv 0$ from the Grassmann nature of the SUSY generator. To exhaust our possibilities, $aa^\dag |\Omega\rangle = (1-a^\dag a)|\Omega\rangle = |\Omega\rangle$. Thus our massless $\mathcal N=1$ supersymmetry multiplet has only two states, $|p_\mu,\lambda\rangle$ and $|p_\mu,(\lambda+\frac 12)\rangle$. We have paired a bosonic and a fermionic state, so we're happy that this is supersymmetric in an intuitive way. We haven't said anything about what the lowest helicity $\lambda$ is, and in fact we are free to choose this.
% 
% Let us note here that nature respects the discrete $CPT$ symmetry. Thus if we construct a model of a massless supermultiplet that is not $CPT$ self-conjugate, then we are obliged to also add a partner $CPT$-conjugate multiplet as well. For example, if $\lambda = \frac 12$, then our construction yields a multiplet with a fermion of helicity $\lambda=\frac 12$ and a vector partner with helicity $\lambda = 1$. $CPT$ invariance mandates that we must also have a fermion with helicity $\lambda=-\frac 12$ and a vector partner with helicity $\lambda = -1$. More generally, $CPT$ compels us to fill in our massless multiplets with states $|p_\mu,\pm\lambda\rangle$ and $|p_\mu,\pm(\lambda+\frac 12)\rangle$.
% 
% Let us go over some examples of massless supermultiplets. 
% \begin{itemize}
%   \item \textbf{Chiral multiplet}\index{chiral multiplet}. If we take $\lambda =0$ we have the multiplets for the Standard Model fermions. These are composed of the states $2|p_\mu,0\rangle$ (i.e. two such states by $CPT$) and $|p_\mu,\pm\frac 12\rangle$. These could represent pairs of squarks and quarks, sleptons and leptons, or Higgses and Higgsinos\footnote{The SUSY nomenclature should be clear. Scalar partners to Standard Model fermions have an `s-' prefix while fermionic partners to Standard Model bosons have an `-ino' suffix.}. One could pause and ask why these particles are massless supermultiplets when we know quarks, leptons, and the Higgs have mass (and their superparners ought to be even heavier to avoid detection) -- but just as in the Standard Model, these massless multiplets obtain mass from electroweak symmetry breaking.
%   \item \textbf{Gauge multiplet}\index{gauge multiplet}. If we take $\lambda =\frac 12$ we have multiplets for the Standard Model gauge bosons. These are composed of the states $|p_\mu,\pm \frac 12\rangle$ and $|p_\mu,\pm 1\rangle$. These would then represent gauginos and their Standard Model gauge boson counterparts. Since this multiplet contains spin-$\frac 12$ and spin-$1$ particles, would it have been more economical to try to fit the entire Standard Model into gauge multiplets? While that would be tidy indeed, this is not possible since the gauge particles are in the adjoint representation of the gauge group while the chiral fermions are in the fundamental and antifundamental representations. Further, the fact that the gauge multiplet is in the adjoint gauge representation allows the fermions in this multiplet to be Majorana. Why not pick $\lambda = 1$? We avoid this choice since there is no consistent way to couple spin-$\frac 32$ particles with spin-$1$.
%   \item \textbf{Gravity multiplet}\index{gravity multiplet}. We can also consider a supermultiplet containing a spin-$2$ particle, i.e. a graviton. For this we choose $\lambda = \frac 32$. We end up with a pair of gravitinos\footnote{This appears to be the correct pluralization of `gravitino,' though `gravitinii' is also acceptable.} $|p_\mu,\pm \frac 32\rangle$ and gravitons $|p_\mu,\pm 2\rangle.$.
% \end{itemize}
% 
% \subsection{Massive Multiplets}
% 
% Having fleshed out the massless supermultiplet, let's play the same game for the massive multiplets. In this case we can boost to a particle's rest frame,
% \begin{align}
%   p_\mu = (m,0,0,0).
% \end{align}
% The Casimir operators are given by 
% \begin{align}
%   C_1 &= m^2\\
%   \tilde C_2 &= 2m^4 Y^iY_i,
% \end{align}
% where $Y = J_i - \frac 1{4m}\left(Q\sigma_i \overline Q\right)$ is the \textbf{superspin}\index{superspin}. The nice feature of the superspin is that
% \begin{align}
%   [Y_i,Y_j] &= i\epsilon_{ijk}Y_k,
% \end{align}
% that is they satisfy the same algebra as the angular momentum operators, $J_i$. Thus we can label a multiplet by its mass $m$ and superspin $y$, the root of the eigenvalue of $Y^2$. As before, we can work out the anticommutator of the SUSY generators acting on a state with $p_\mu=(m,0,0,0)$:
% \begin{align}
%   \{Q_\alpha,\overline Q_{\dot \beta}\} &= 2m \begin{pmatrix}
%                                               1   &\quad 0\\ 0&\quad 1
%                                               \end{pmatrix}.
% \end{align}
% We now have \textit{two} sets of raising and lowering operators,
% \begin{align}
%   a_{1,2} &= \frac{1}{\sqrt{2m}}Q_{1,2}\\
%   a^\dag_{1,2} &= \frac{1}{\sqrt{2m}}\overline Q_{\dot 1, \dot 2}.
% \end{align}
% These satisfy the anticommutation relations
% \begin{align}
%   \{a_p,a_q^\dag\} &= \delta_{pq}\\
%   \{a_p,a_q\} &= 0\\
%   \{a_p^\dag,a_q^\dag\} &= 0.
% \end{align}
% As before we define a ground state $|\Omega\rangle$ that is annihilated by both $a_1$ and $a_2$, $a_{1,2}|\Omega\rangle = 0$. It is important to note that for the ground state,
% \begin{align}
%   \textbf Y|\Omega\rangle &= \textbf J|\Omega\rangle,
% \end{align}
% and so we can label the ground state by
% \begin{align}
%   |\Omega\rangle &= |m,y=j;p_\mu,j_3\rangle.
% \end{align}
% The spin in the $z$-direction, $j_3$, takes values from $-y$ to $y$ and so there are $(2y+1)$ ground states.
% 
% We can now act on $|\Omega\rangle$ with creation operators. Recalling \Equations (\ref{eq:SUSYreps:JQ}) and (\ref{eq:SUSYreps:JQbar}), we see that the resulting states are
% \begin{align}
%   a_1^\dag|\Omega\rangle &= |m,j=y+\frac 12; p_\mu, j_3\rangle\\
%   a_2^\dag|\Omega\rangle &= |m,j=y-\frac 12; p_\mu, j_3\rangle.
% \end{align}
% We see that $a_1^\dag|\Omega\rangle$ has $2(y+\frac 12)+1 = 2y+2$ states while $a_2^\dag|\Omega\rangle$ has $2(y-\frac 12)+1 = 2y$ states. This can be understood group theoretically, since
% \begin{align}
%   \frac 12 \otimes j = (j-\frac 12)\oplus (j+\frac 12)
% \end{align} 
% We're going to want to keep track of these to make sure that our bosonic and fermionic degrees of freedom match.
% 
% Unlike the massless case, we can now form a state with two creation operators,
% \begin{align}
%   a_1^\dag a_2^\dag |\Omega\rangle = -a_2^\dag a_1^\dag |\Omega \rangle = |m,j=y;p_\mu,j_3\rangle = |\Omega'\rangle.
% \end{align}
% This state looks very similar to the base state $\Omega$, but the two are not equivalent: $\Omega'\rangle$ is annihilated by the $a^\dag$s rather than the $a$s:
% \begin{align}
%   a^\dag_{1,2}|\Omega'\rangle = 0\\
%   a_{1,2}|\Omega\rangle = 0.
% \end{align}
% The $a_p^\dag$ and $a_p$ are related by a parity transformation:
% \begin{align}
%   \underbrace{a_{1,2}^\dag}_{(0,\frac 12)} &\leftrightarrow \underbrace{a_{1,2}}_{(\frac 12,0)},
% \end{align}
% and so the above equation suggests that $|\Omega\rangle$ and $|\Omega'\rangle$ are also related by parity. Then we can define parity eigenstates
% \begin{align}
%   |\pm\rangle &= |\Omega\rangle \pm |\Omega'\rangle.
% \end{align}
% For $y=0$ the $|+\rangle$ is a scalar while $|-\rangle$ is a pseudoscalar. 
% 
% Now we'd like to `check the accounting' and make sure our fermionic and bosonic states have the same number of degrees of freedom. $|\Omega\rangle$ and $|\Omega'\rangle$ each have $2y+1$ states, while $a_{1,2}^\dag|\Omega\rangle$ give $(2y+1) \pm 1$ states. Hence there sums are each $4y+2$, and hence the number of fermionic and bosonic states are equal.
% 
% In summary, for $y>0$, we have the states
% \begin{align}
%   |\Omega\rangle &= |m,j=y;p_\mu,j_3\rangle\\
%   |\Omega'\rangle &= |m,j=y;p_\mu,j_3\rangle\\
%   a_1^\dag|\Omega\rangle &= |m,j=y+\frac 12;p_\mu,j_3\rangle\\
%   a_2^\dag |\Omega\rangle &= |m,j=y-\frac 12;p_\mu,j_3\rangle.
% \end{align}
% For $y=0$, we have the states
% \begin{align}
%   |\Omega\rangle &= |m,j=0;p_\mu,j_3\rangle\\
%   |\Omega'\rangle &= |m,j=0;p_\mu,j_3\rangle\\
%   a_1^\dag|\Omega\rangle &= |m,j=\frac 12;p_\mu,j_3=\pm \frac 12\rangle.
% \end{align}
% 
% That's it for the representations of $\mathcal N=1$ supersymmetry!
% 
% 
% 
% \subsection{Equality of Fermionic and Bosonic States}
% 
% Let us now prove a rather intuitive statement: In any SUSY multiplet, the number $n_B$ of bosons equals the number $n_F$ of fermions.
% 
% We shall make use of the operator $(-)^F$, which assigns a `parity' to a state depending on whether it is a boson $(|B\rangle)$ or fermion $(|F\rangle)$:
% \begin{align}
%   (-)^F|B\rangle &= |B\rangle\\
%   (-)^F|F\rangle &= -|F\rangle.
% \end{align}
% This operator is sometimes written using less-elegant notation like $(-1)^{n_F}$.
% 
% We note that this operator anticommutes with SUSY generators since
% \begin{align}
%   (-)^F Q_\alpha |F\rangle    &= (-)^F|B\rangle= |B\rangle = Q_\alpha |F\rangle = -Q_\alpha (-)^F |F\rangle.
% \end{align}
% 
% Let us now calculate the following curious-looking trace:
% \begin{align}
%   \Tr\left\{(-)^F \{Q_\alpha,\overline Q_{\dot\beta}\} \right\} &= \Tr\left\{(-)^F Q_\alpha\overline Q_{\dot\beta} + (-)^F \overline Q_{\dot\beta}Q_\alpha \right\}\\
%   &= \Tr\left\{\underbrace{-Q_\alpha(-)^F\overline Q_{\dot\beta}}_{\text{Using anticommutator}} + \underbrace{Q_\alpha (-)^F \overline Q_{\dot\beta}}_{\text{Using cyclicity of trace}}\right\}\\
%   &= 0.
% \end{align}
% But since $\{Q_\alpha,\overline Q_{\dot\beta}\}=2(\sigma^{\mu})_{\alpha\dot\beta}P_\mu$, the above trace is
% \begin{align}
%   \Tr\left\{(-)^F 2(\sigma^{\mu})_{\alpha\dot\beta}P_\mu \right\} &= 2(\sigma^{\mu})_{\alpha\dot\beta}P_\mu \Tr\left((-)^F\right),
% \end{align}
% and hence $\Tr\left((-)^F\right)=0$. This trace is called the \textbf{Witten index}\index{Witten index} and will play a central role we study SUSY breaking in \Chapter \ref{chap:susybreaking}. The Witten index can be written more explicitly as a sum over bosonic and fermionic states,
% \begin{align}
%   \Tr\left((-)^F\right) &= \sum_B\langle B | (-)^F |B \rangle + \sum_F \langle F | (-)^F | F \rangle \\
%   &= \sum_B \langle B|B\rangle - \sum_F \langle F | F \rangle\\
%   &= n_B - n_F.
% \end{align}
% Thus the vanishing of the Witten index implies that $n_B = n_F$, or that there are an equal number of bosonic and fermionic states.
% 
% 
% 
% 
% 
% 
% \subsection{Massless $\mathcal N>1$ Representations}
% 
% Let's move on to $\mathcal N>1$ representations. This is a bit outside the scope of a typical introductory SUSY course, but a lot of recent developments in field theory have come from looking at $\mathcal N>1$ SUSY so we'll take some time to introduce it. The motivation, to be clear, is formal rather than phenomenological. 
% 
% For massless representations, once again we can boost to a frame $p_\mu = (E,0,0,E)$ and the anticommutator acting on this state is the same as before with the addition of a $\delta$ function,
% \begin{align}
%   \{Q^A_\alpha,\overline Q^B_{\dot\beta} \} &= 4E \begin{pmatrix}
%                                                   1 &\quad 0 \\ 0 &\quad 0
%                                                \end{pmatrix}\delta^A_B.
% \end{align}
% 
% Thus, by the same arguments as the $\mathcal N=1$ massless representation, $Q^A_2 = \overline Q^A_{\dot 2} = 0$. But then recall the anticommutator for the central charge,
% \begin{align}
%   \{Q^A_\alpha,Q^B_\beta\} &= \epsilon_{\alpha\beta}Z^{AB}.
% \end{align}
% Since $Q_2 = 0$ the right-hand side is always zero and the central charges play no role in the massless multiplet. We can now define $\mathcal N$ pairs of raising and lowering operators
% \begin{align}
%   a^A &= \frac 1{\sqrt{4E}} Q^A_1\\
%   a^{\dag A} &= \frac 1{\sqrt{4E}} \overline Q^A_{\dot 1},
% \end{align}
% with the anticommutation relation
% \begin{align}
%   \{a^A,a^\dag_B\} &= \delta^A_B.
% \end{align}
% Recall that the positions of the $A,B$ labels are irrelevant. By now you know what's coming. We define a base state $|\Omega\rangle$ such that $a^A|\Omega\rangle = 0$ and start building up our multiplet by acting with creation operators. With $\mathcal N$ different raising operators, counting states becomes an exercise in counting:
% 
%   \begin{center}
% % \begin{table}
% % \begin{tabular}{|cccccc|}
%   \begin{tabular}{lcccr}
%   \hline
%   State               &\quad& Helicity        &\quad& Degrees of Freedom \\ \hline
%   $|\Omega\rangle$    &\quad& $\lambda_0$ &\quad& 
%   $1 = \begin{pmatrix}\mathcal N \\0\end{pmatrix}$\\
%   $a^{\dag}_{A}|\Omega\rangle$        &\quad& $\lambda_0+\frac 12$    &\quad& 
%   $\mathcal N = \begin{pmatrix} \mathcal N\\1\end{pmatrix}$\\
%   $a^{\dag}_{A}a^{\dag}_{B}|\Omega\rangle$ &\quad& $\lambda_0+ 1$ &\quad& 
%   $\frac 12\mathcal N(\mathcal N-1) = \begin{pmatrix} \mathcal N\\2\end{pmatrix}$\\
%   $a^{\dag}_{A}a^{\dag}_{B} a^{\dag}_{C}|\Omega\rangle$   &\quad& $\lambda_0 +\frac 32$   &\quad& 
%   $\cdots = \begin{pmatrix} \mathcal N\\3\end{pmatrix}$\\
%   $\vdots$            &\quad& $\vdots$ &\quad& $\vdots$ 
%   \phantom{$=\begin{pmatrix} \mathcal N\\3\end{pmatrix}$}\\
%   $a^{\dag}_{1}\cdots a^{\dag}_{\mathcal N}|\Omega\rangle$ &\quad& $\lambda_0+\frac{\mathcal N}{2}$ &\quad& $1=\begin{pmatrix} \mathcal N\\\mathcal N\end{pmatrix}$\\
%   \end{tabular} 
% % \caption{MSSM superfield spectrum and quantum numbers.}\label{table:MSSM:MSSMfields}
% % Coems from p56 - 60 of Burgess and Moore
% % \end{table}
%   \end{center}
% %
% We see that the total number of states (number of degrees of freedom) is given by
% \begin{align}
%   \sum^{\mathcal N}_{k=0} \begin{pmatrix}
%       \mathcal N \\ k
%   \end{pmatrix} &= 2^{\mathcal N}.
% \end{align}
% 
% For $\mathcal N=2$ we can chart the supermultiplet. For example, for the $\mathcal N=2$ \textbf{vector multiplet}\index{vector multiplet!N=2@$\mathcal N=2$} has $\lambda_0=0$, we have:
% 
% \begin{center}
%   \begin{tikzpicture} 
%       [inner sep=2mm]
%   \node       (center)                        {};
%   \node       (top)       [above=of center]   {$\lambda_0=0$}; 
%   \node       (bot)       [below=of center]   {$\lambda=1$}; 
%   \node       (lef)       [left=of center]    {$\lambda=\frac 12$}; 
%   \node       (rig)       [right=of center]   {$\lambda=\frac 12$}; 
%   \draw       [->]        (top) to (lef);
%   \draw       [->]        (top) to (rig);
%   \draw       [->]        (lef) to (bot);
%   \draw       [->]        (rig) to (bot);
%   \begin{scope}[node distance =8mm and 8 mm]
%       \node       (tr)        [blue, above right=of center] {$a^{\dag}_{2}$};
%       \node       (bl)        [blue, below left=of center] {$a^{\dag}_{2}$};  
%   \end{scope}
%   %\node[draw=red, ellipse, fit=(top) (lef)] {} % See p 160 of PGF manual
%   \begin{scope}[node distance = 4mm and 4mm]
%       \node       (tl)        [red, above left=of center] {$a^{\dag 1}$};
%       \draw[red, very thick, rotate=35] (tl) ellipse (2.25 and 1);
%   %   \node       (tltl)      [above=of tl, rotate=35] {$\mathcal N=1$ Chiral};   
%       \node       (br)        [red, below right=of center] {$a^{\dag 1}$};
%       \draw[red, very thick, rotate=35] (br) ellipse (2.25 and 1);
%   \end{scope}
%   \begin{scope}[node distance=10mm and 10 mm]
%       \node   (ttl)   [red, above=of tl.west,rotate=35] {$\mathcal N=1$ Chiral};
%       \node   (bbr)   [red, below=of br.east,rotate=35] {$\mathcal N=1$ Vector};
%   \end{scope}
%   \end{tikzpicture}
% \end{center}
% 
% \noindent Notice that the $\mathcal N=2$ vector multiplet is composed of an $\mathcal N=1$ chiral multiplet and an $\mathcal N=1$ vector multiplet. We can draw the analogous diagram for the $\mathcal N=2$ \textbf{hypermultiplet}\index{hypermultiplet!N=2@$\mathcal N=2$}, which starts with $\lambda_0=-\frac 12$.
% 
% \begin{center}
%   \begin{tikzpicture} 
%       [inner sep=2mm]
%   \node       (center)                        {};
%   \node       (top)       [above=of center]   {$\lambda_0=-\frac 12$}; 
%   \node       (bot)       [below=of center]   {$\lambda=\frac 12$}; 
%   \node       (lef)       [left=of center]    {$\lambda=0$}; 
%   \node       (rig)       [right=of center]   {$\lambda=0$}; 
%   \draw       [->]        (top) to (lef);
%   \draw       [->]        (top) to (rig);
%   \draw       [->]        (lef) to (bot);
%   \draw       [->]        (rig) to (bot);
%   \begin{scope}[node distance =8mm and 8 mm]
%       \node       (tr)        [blue, above right=of center] {$a^{\dag}_{2}$};
%       \node       (bl)        [blue, below left=of center] {$a^{\dag}_{2}$};  
%   \end{scope}
%   %\node[draw=red, ellipse, fit=(top) (lef)] {} % See p 160 of PGF manual
%   \begin{scope}[node distance = 4mm and 4mm]
%       \node       (tl)        [red, above left=of center] {$a^{\dag 1}$};
%       \draw[red, very thick, rotate=35] (tl) ellipse (2.25 and 1);
%   %   \node       (tltl)      [above=of tl, rotate=35] {$\mathcal N=1$ Chiral};   
%       \node       (br)        [red, below right=of center] {$a^{\dag 1}$};
%       \draw[red, very thick, rotate=35] (br) ellipse (2.25 and 1);
%   \end{scope}
%   \begin{scope}[node distance=10mm and 10 mm]
%       \node   (ttl)   [red, above=of tl.west,rotate=35] {$\mathcal N=1$ Chiral};
%       \node   (bbr)   [red, below=of br.east,rotate=35] {$\mathcal N=1$ Chiral};
%   \end{scope}
%   \end{tikzpicture}
% \end{center}
% 
% \noindent This multiplet is composed of two $\mathcal N=1$ chiral multiplets of opposite helicity, hence the hypermultiplet has the nice feature of being $CPT$ self-conjugate.
% 
% 
% Next we can write out the $\mathcal N=4$ \textbf{vector multiplet}\index{vector multiplet!N=4@$\mathcal N=4$}, which has a base helicity of $\lambda_0=-1$. Let us write out the states:
% 
% \begin{center}
%   \begin{tabular}{l|c|c|c|c|c|}
%       \cline{2-6}
%   & $\lambda = -1$ & $\lambda = -\frac 12$ & $\lambda = 0$ & $\lambda = \frac 12$ & $\lambda = 1$\\ \hline
%   \multicolumn{1}{|l|}{\# of States} & 1 & 4 & 6 & 4 & 1\\
%   \hline
%   \end{tabular}   
% \end{center}
% 
% \noindent This is rather special as it is the \textit{only} multiplet for a renormalizable $\mathcal N=4$ SUSY theory. What about $\mathcal N=3$? The spectrum of $\mathcal N=3$ SUSY (with its $CPT$ conjugate) coincides exactly with the $\mathcal N=4$ vector multiplet and hence the quantum field theories are identical.
% 
% This brings us to a natural point to make some general comments about extended SUSY multiplets.
% \begin{itemize}
%   \item First of all, note that for every multiplet
%   \begin{align}
%       \lambda_\text{max} - \lambda_\text{min} = \mathcal N/2.
%   \end{align}
%   This is straightforward since each creation operator $a^{A\dag}$ raises the helicity by $+\frac 12$.
%   \item In quantum field theory, renormalizability imposes that the maximum helicity is $\lambda = 1$. Thus the maximum number of supersymmetries in a renormalizable theory is $\mathcal N=4$. (This is why we said that $\mathcal N=4$ is special.)
%   \item We have a ``strong belief'' that there are no massless particles of helicity $|\lambda|>2$. This is because there is no conserved current for such a particle to couple to. The general argument is that massless particles with $|\lambda|>\frac 12$ must couple at low momentum to conserved quantities. For example, $|\lambda|=1$ couples to the electric or color currents $j^\mu$. For $|\lambda|=2$, the graviton can couple to the energy-momentum tensor. Beyond this there are no conserved currents for a higher-spin particle to couple to. A further discussion of this can be found in Weinberg I, Section 13.1 \cite{Weinberg:1995mt}.
%   \item We also strongly believe that the maximum number of supersymmetries is $\mathcal N=8$, corresponding to one graviton and $\mathcal N=8$ gravitinos. If $\mathcal N>8$ then we would have an uncomfortably large number of gravitons. $\mathcal N=8$ SUSY has the following states:
%   \begin{center}
%       \begin{tabular}{l|c|c|c|c|c|}
%           \cline{2-6}
%       & $|\lambda| = 2$ & $|\lambda| = -\frac 32$ & $|\lambda| = 1$ & $|\lambda| = \frac 12$ & $|\lambda| = 0$\\ \hline
%       \multicolumn{1}{|l|}{\# of States} & 1 & 8 & 28 & 56 & 70\\
%       \hline
%       \end{tabular}   
%   \end{center}
%   \item Extended SUSY is usually not considered to be phenomenologically relevant at, say, the TeV scale since all $\mathcal N>1$ theories are non-chiral and hence would have difficulty reproducing the chiral nature of the Standard Model at low energies.
% \end{itemize} 
% 
% \subsection{Massive $\mathcal N>1$ Representations with $Z^{AB}=0$}
% 
% By now we're old pros at building multiplets. For the case where there are no central charges, we may follow the same steps that we took for the massive $\mathcal N=1$ multiplet, just being careful to account for the $\mathcal N>1$ different sets of SUSY generators. We boost into a rest frame $p_\mu=(m,0,0,0)$ and write out the anticommutation relation
% \begin{align}
%   \{Q^A_\alpha,\overline Q^B_{\dot\beta}\} &= 2(\sigma^0)_{\alpha\dot\beta}\, m\,\delta^A_B = 2m \begin{pmatrix}
%       1 &\quad 0\\ 0 &\quad 1
%   \end{pmatrix}\delta^A_B.
% \end{align}
% We find $2\mathcal N$ pairs of creation and annihilation operators,
% \begin{align}
%   a^A_{1,2} = \frac 1{\sqrt{2m}}Q^A_{1,2}\\
%   a^{\dag A}_{1,2} = \frac 1{\sqrt{2m}}\overline Q^A_{\dot 1,\dot 2}.
% \end{align}
% We thus have $2^{2\mathcal N}$ states of a given superspin $y$, and hence a total of $2^{2\mathcal N}\times (2y+1)$ states. Be careful with the 1,2 indices: recall from \Equations (\ref{eq:SUSYreps:JQ}) and (\ref{eq:SUSYreps:JQbar}) that these correspond to different helicities. In particular, $a^{\dag A}_1$ will \textit{raise} helicity by $\frac 12$ while $a^{\dag A}_2$ will \textit{lower} helicity by $\frac 12$.
% 
% Hence we can write out the example of the $\mathcal N=2$ multiplet for with $y=0$:
% 
% \begin{center}
%   \begin{tabular}{|rrl|}
%       \hline
%       $|\Omega\rangle$    &\quad  1 state &\quad spin-$0$\\ \hline
%       $a^{\dag A}_{1,2}|\Omega\rangle$    &\quad  4 states &\quad spin-$\frac 12$\\ \hline
%       $a^{\dag A}_{1,2}a^{\dag B}_{1,2}|\Omega\rangle$    &\quad  3 states &\quad spin-$0$\\
%       &\quad 3 states &\quad spin-$1$\\ \hline
%       $a^{\dag A}_{1,2}a^{\dag B}_{1,2}a^{\dag C}_{1,2}|\Omega\rangle$    &\quad  4 states &\quad spin-$\frac 12$\\ \hline
%       $a^{\dag A}_{1,2}a^{\dag B}_{1,2}a^{\dag C}_{1,2}a^{\dag D}_{1,2}|\Omega\rangle$    &\quad  1 states &\quad spin-$0$\\
%       \hline 
%   \end{tabular}   
% \end{center}
% 
% \noindent We end up with $16 = 2^4$ total states. Aside from being careful with the helicities being raised and lowered (as opposed to only raised), this follows straightforwardly from our previous analyses of the $\mathcal N=1$ massive representations and the $\mathcal N>1$ massless representations. 
% 
% \subsection{Massive $\mathcal N>1$ Representations with $Z^{AB}\neq 0$}
% 
% We get much more interesting properties in the case where there are central charges. Let us define the following objects
% \begin{align}
%   \mathcal H_{\phantom{a}} &\equiv (\overline \sigma^0)^{\dot\beta\alpha}\left\{Q^A_\alpha - \Gamma^A_\alpha, \overline Q_{\dot\beta A}-\overline \Gamma_{\dot\beta A}\right\}\\
%   \Gamma^A_\alpha &\equiv \epsilon_{\alpha\beta}\,U^{AB}\,\overline Q_{\dot\gamma B}(\overline\sigma^0)^{\dot\gamma \beta}.
% \end{align}
% Here $U$ is a unitary matrix, $U^\dag U = \mathbbm 1$. Thus $\Gamma^A_\alpha$ is essentially $\overline Q$ with objects contracted to change the index structure. Note further that $\mathcal H \geq 0$ since it is of the form $X\overline X = |X|^2$.
% 
% Now using the extended SUSY algebra, we can explicitly calculate 
% \begin{align}
%   \mathcal H &= \underbrace{8m\mathcal N}_{\text{from $\{Q,\overline Q\}$}} - \underbrace{2\Tr(ZU^\dag + UZ^\dag)}_{\text{from $\{Q,Q\}$ and $\{\overline Q,\overline Q\}$}}\geq 0.
% \end{align} 
% We may now polar decompose the matrix $Z=HV$, with $H$ \Hermitian and $V$ unitary. We choose $U=V$, so that
% \begin{align}
%   \mathcal H &= 8m\mathcal N - 4\Tr H \geq 0,
% \end{align}
% or in other words,
% \begin{align}
%   m &\geq \frac 1{2\mathcal N}\,\Tr H = \frac{1}{2\mathcal N}\,\Tr \sqrt{ZZ^\dag}.
% \end{align}
% This is the Bogomolnyi-Prasard-Sommerfeld (BPS)\index{BPS bound} bound on the masses and is something you should remember for the rest of your life. If the BPS bound is saturated, i.e.
% \begin{align}
%   m = \frac 1{2\mathcal N}\,\Tr \sqrt{ZZ^\dag},
% \end{align}
% then the states satisfying this condition are called \textbf{BPS states}\index{BPS state}. For such states we have
% \begin{align}
%   \mathcal H = 0 &\quad\Rightarrow\quad \{Q^A_\alpha-\Gamma^A_\alpha,\overline Q_{\dot\beta A}-\overline\Gamma_{\dot\beta A}\} = 0.\label{eq:SUSYreps:NmassiveZ}
% \end{align}
% Compare this to the massless multiplets we discussed earlier where we had $\{Q^A_2,\overline Q^A_{\dot 2}\} = 0$ implying $Q^A_2 = 0$ and hence we had fewer creation operators and fewer states. The exact same effect is occurring here, where \Equation (\ref{eq:SUSYreps:NmassiveZ}) is telling us that
% \begin{align}
%   Q^A_\alpha - \Gamma^A_\alpha = 0
% \end{align}
% and hence we have a reduced number of creation and annihilation operators. In fact, we have $\mathcal N$ pairs of $a$ and $a^\dag$ operators, which means we have $2^{\mathcal N}$ states. Compare this to the massive multiplets with no central charges in which we found there are $2^{2\mathcal N}$ states. The lesson is that BPS multiplets are shorter than non-BPS multiplets. 
% 
% For the case $\mathcal N = 2$, we may write
% \begin{align}
%   Z^{AB} &= 
%   \begin{pmatrix}
%       0 &\quad q_1\\
%       -q_1 &\quad 0
%   \end{pmatrix},
% \end{align}
% from which we find the BPS bound
% \begin{align}
%   m &\geq \frac 12 q.
% \end{align}
% 
% For $\mathcal N>2$ with $\mathcal N$ even, we can block-diagonalize $Z^{AB}$ and constrain our multiplets block-by-block.
% \begin{align}
%   Z^{AB} &= 
%   \begin{pmatrix}
%       0       & q_1   &  &            &   \\
%       -q_1    & 0     &  &            &   \\
%               &       & \ddots &    &     \\      
%               &       &  & 0  & q_{\mathcal N/2} \\
%               &       &  & -q_{\mathcal N/2} & 0
%   \end{pmatrix},
% \end{align}
% from which we have the BPS bound
% \begin{align}
%   m &\geq \frac 12 q_i.
% \end{align}
% If $k$ of the $q_i$ satisfy $q_i=2m$ then there exists $2\mathcal N - 2k$ creation and annihilation operators ($k<\mathcal N/2$), i.e. there are $2^{2(\mathcal N -k)}$ states. 
% 
% \Table \ref{table:SUSYreps:Nmultiplet} summarizes the representations of $\mathcal N>1$ SUSY.
% 
%   \begin{table}
%       \begin{center}
%           \begin{tabular}{|lllcl|}
%               \hline
%               \textbf{Mass} &Condition& \# States && Name\\ \hline
%               Massless &              & $2^\mathcal N$ && Massless Multiplet\\
%               Massive  & $Z^{AB}=0$   & $2^{2\mathcal N}$ && Massive Multiplet\\
%               Massive  & $k=0$        & $2^{2\mathcal N}$ && Long Multiplet\\
%               Massive  & $0<k<\frac{\mathcal N}2$ & $2^{2(\mathcal N-k)}$ && Short Multiplet\\
%               Massive  & $k=\frac{\mathcal N}2$ & $2^{\mathcal N}$ && Ultra-short Multiplet\\
%               \hline
%           \end{tabular}       \end{center}
%       \caption{Representations of $\mathcal N>1$ SUSY.}
%       \label{table:SUSYreps:Nmultiplet}
%   \end{table}
% 
% Some general remarks on BPS states are now in order to explain why all of this is important. 
% \begin{itemize}
%   \item BPS states and BPS bounds have their origin in soliton solutions of Yang-Mills systems. Solitons are nonperturbative field configurations that can be thought of as ``classical'' versions of particles.
%   \item The BPS bound refers to an energy bound.
%   \item BPS states are stable. They are the lightest objects that carry central charge.
%   \item The equivalence of charge and mass (up to a factor of 2) in BPS states i reminiscent of charged black holes. In fact, extremal black holes are stable BPS solutions to supergravity theories.
%   \item BPS states are important in strong/weak coupling dualities in string and field theory.
%   \item In string theory, $D$-branes are BPS states.
% \end{itemize}

\printindex

%% Bibliography
%% USING BIBLATEX, SKIP BIBTEX
%% Use inspireHEP bibtex entries when possible
% \bibliographystyle{utcaps} 	% arXiv hyperlinks, preserves caps in title
% \bibliography{bib title without .bib}


\end{document}