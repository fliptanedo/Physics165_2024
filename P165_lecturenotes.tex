%% LaTeX Paper Template, Flip Tanedo (flip.tanedo@ucr.edu)
%% GitHub: https://github.com/fliptanedo/paper-template-2022

% \documentclass[11pt]{article} %% Not for Lecture Notes
\documentclass[12pt, oneside]{report}    %% Has chapters

\input{FlipLectureMacros}       %% Lecture note formatting, load first
\input{FlipPreamble}			%% \usepackages, formatting
\input{FlipMacros}              %% Flip's standard macros
\input{FlipMacros_Comments}     %% Flip's macros for comments
\input{FlipMacros_Teaching}     %% Flip's macros for course notes
\input{Flip_listings}           %% Styling for code blocks
\input{FlipAdditionalHeader}    %% Modify this for each project
\input{FlipPreambleEnd}         %% packages that have to be at the end

%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% LECTURE NOTES SETTINGS %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \linenumbers                  %% print line numbers (lineno package)
\graphicspath{{figures/}}       %% figure folder
\addbibresource{FlipBib.bib}    %% Define BibLaTeX source(s)
\addbibresource{FlipSUSY.bib}

%% LEAVE THESE HERE 

\geometry{                      %% large margin for side notes
    paper=letterpaper, 
    hmargin={1cm,7.25cm},       %% 6.25cm space on right
    vmargin={2cm,2cm}, 
    marginparsep=.5cm, 
    marginparwidth=5.75cm
}

%% Def. full width; uses changepage package; 6.25cm to match hmargin difference;
\newenvironment{wide}{\begin{adjustwidth}{0cm}{-6.25cm}}{\end{adjustwidth}}


% Reset the sidenote number each section 
\let\oldsection\section
\def\section{%
  \setcounter{sidenote}{1}%
  \oldsection
}


\begin{document}

\newgeometry{margin=2cm}                   % plain geometry for frontmatter
\newcommand{\FlipTR}{UCR-TR-2024-FLIP-P165} % TR#, pdfsync may fail on 1st page
\thispagestyle{firststyle} 	               % TR#; otherwise use \thispagestyle{empty}
\pagenumbering{gobble}                     % no page number on first page 

%%%%%%%%%%%%%%%%%%%%%%%%
%%%  FRONTMATTER    %%%%
%%%%%%%%%%%%%%%%%%%%%%%%


\begin{center}
    {\large \textsf{UC Riverside Physics 165, Spring 2024} \par}
    {\huge \textbf{Introduction to Particle Physics} \par}\vspace{.5em}
    {\large {Kinematics and Dynamics of the Standard Model} \par}
    \vskip .5cm
\end{center}

\input{FlipAuthors}

\vspace{2em}\noindent
An introduction to elementary particle physics: the study of the fundamental constituents of matter and the forces that dictate their interactions. We focus on building a theoretical understanding of the Standard Model of particle physics based on Feynman diagrams. 

\vspace{5em}
\begin{center}
\includegraphics[width=.3\textwidth]{figures/P5BW.pdf}  
\end{center}  


% \vspace{2em}
\vspace*{\fill}

\noindent
\textsf{Last Compiled: \today}

\noindent
\textsf{Image: \acro{P5} Logo, Sandbox Studio}


\noindent
\textsf{CC BY-NC-SA 4.0}~\ccbyncsa 

\noindent % Course notes URL
% \url{https://github.com/fliptanedo/P231-2023-Math-Methods}

%% Front page logos
% \vspace*{\fill}
\begin{center}
\includegraphics[height=.1\textwidth]{figures/FlipAmbigram.png}
\hspace{5em}
\includegraphics[height=.1\textwidth]{figures/UCRPnA_banner.png}
\end{center}

\newpage

\small
\setcounter{tocdepth}{2}
\tableofcontents
\normalsize
\clearpage
\restoregeometry        %% Return to lecture note geometry 
\pagenumbering{arabic}  %% Turn on regular page numbers


%%%%%%%%%%%%%%%%%%%%%
%%%  THE CONTENT  %%%
%%%%%%%%%%%%%%%%%%%%%

% % \chapter{Things I'm working on}

% % \url{https://github.com/fmarotta/kaobook/issues/15}
% % % Because sidecite dosn't work
% % %\sidecite{Feng:2016ijc}

% % \input{examples_lecture}

% % % \chapter{Paper examples}

% % % Here are the standard examples I use for my \texttt{paper} template. I include them here to check that nothing has broken. These do not make use of the margin at all. You can see what happens when some text spills into the margin unintentionally.

% \input{examples}
% \input{examples_teaching}
% % % \input{examples_listings}
% \input{examples_bestpractices}
% \input{examples_refs}
% \input{examples_lecture}

% % %% CHAPTER SUBAPPENDIX %% if using report class
% % \begin{subappendices}
% % \section{Subappendix}\label{sec:subappendix:eg}
% % This chapter has its own special appendix.
% % \end{subappendices}

\chapter{The Course}

\section{Our Goal}

The goal of this course is to teach the \emph{theoretical framework} of particle physics. The underlying structure of this discipline is called \textbf{quantum field theory} and is the union of special relativity and quantum mechanics. Over one-quarter course we tell the story of leptons, quarks, and various gauge bosons---but what I \emph{really} want to convey to you is how quantum field theory works. 

Ordinarily, quantum field theory is a graduate-level course that you take after taking not only upper division quantum mechanics, but graduate-level quantum mechanics, electrodynamics, statistical mechanics/field theory, with smatterings of courses that hammer home special relativity (perhaps in general relativity course) and bits of complex analysis. Even then, the course has a reputation for being challenging because it demands a level of physical sophistication to appreciate.\sidenote[][-5em]{Usually we tell our graduate students to expect to take quantum field theory a few times in order to prepare to spend the rest of their research careers continuing to chip away at the frontier of human knowledge in this field. I am reminded of the [lightly paraprhased] quote by theorist Nima Arkani-Hamed: ``You can learn quantum mechanics in a few weeks. But you need to dedicate a lifetime of research to hope to understand quantum field theory.''} 

This course is an attempt to give a working knowledge of the big picture. You will see how Feynman diagrams are both a perturbative expansion of a transition amplitude \emph{and} a useful mnemonic for the story of particle scattering. You will see how indices are a physicist's crutch to mathematically implement symmetries. Along the way, you may come to appreciate corners of quantum mechanics and relativity that otherwise may slip the usual undergrad curriculum. 

Most of call, \emph{this course is a bridge}. For those who are interested in theoretical physics of any type\sidenote{In some sense, all theoretical physicists are quantum field theorists. Yes, even condensed matter theorists.} or those interested in particle physics of any type\sidenote{Including experimental particle physics and astro-particle physics.}: I want you to leave this course knowing how one \emph{uses} quantum field theory in particle physics so that if you go to graduate school, you will already have the bird's-eye-view of how different technical ideas come together. Alternatively, for those who know that their passions are not in this discipline: I want you to appreciate what the scaffolding of quantum field theory buys us as physicists, so that when you go off to become your future self, you are an informed ambassador of physics.

\section{What we miss}

This is \emph{not} a `modern physics course---what I mean by that are courses that are glorified ``physics for poets'' courses that offer ideas without mathematical rigor. Instead, this course is \emph{all about} understanding the mathematical rigor, even though we will not derive every step (leaning instead on analogies as appropriate) and even though the purpose of the course is not to see who can calculate the most tedious cross section.

A course like this can span multiple terms and focus on many different aspects of particle physics. Given that we have \emph{one} term and that we want to start by assuming the bare minimum, we have to make deliberate cuts to what we investigate. Rather than trying to do a little bit of everything, we will dive deeply into the theory and sacrifice the following:
\begin{itemize}
    \item The experimental foundation of particle physics. This is the biggest sacrifice because physics is ultimately an \emph{empirical} science and practitioners need to be grounded in experiment.\sidenote{Even theorists.} We excise this aspect in part because I would struggle to do it justice, but also because we are in a moment where the types of experiments that particle physicists do has evolved rapidly over the last decade.\sidenote{\tacro{UCR} students are encouraged to reach out to members of our experimental particle cosmology group to learn more about this.}
    \item The history of particle physics. I did not appreciate this as a student, but good physicists understand how those who came before them had their key \emph{aha!} moments: what what puzzles where they thinking about, how did they make progress?\sidenote{This is different from a hagiography of physics heroes. Most of our physics heroes are flawed human beings and most of the heroism is rooted in a broader collective of people than our stories usually tell.}
    \item Computational tools. Particle physicists were the original `big data' scientists with a huge throughput of data in particle colliders. Experience with some of the computational tools are a great way to get into undergraduate research in this field. I regret that this is something that we cannot fit into this course, but I encourage those interested in this field to be prepared to do computational work.
\end{itemize}

\section{Prerequisites}

I have done my best to minimize the prerequisite knowledge for this course. At the bare minimum, we require the following:
\begin{enumerate}
    \item This means you have had first-year physics and did well.\sidenote{At the very least, if you took first-year physics now you would ace it.}
    \item Analytical mechanics at the level of having some familiarity with Lagrangian mechanics and variational principles.
    \item At least two quarters of quantum mechanics so that you are familiar with bras, kets, operators, superposition, and amplitudes. You should be comfortable with angular momentum and spin.
    \item Some introduction to special relativity so that you are familiar with the principles of length contraction and time dilation.
    \item Linear algebra at the level of Physics 17 at \acro{UCR}.\sidenote{The course notes for Physics 17 may be a useful reference.\footnotemark}\footnotetext{\url{https://sites.google.com/ucr.edu/physics017/}}
\end{enumerate}

In a perfect world, you would also have the following background:
\begin{itemize}
    \item A solid background in linear algebra and some familiarity with how this relates to the representation of groups. It would help if you do not cringe at the word \emph{tensor}. It would be even better if you knew what makes a tensor a tensor as opposed to a multi-dimensional array of numbers.
    \item Some familiarity with the notion of a generator of a transformation and its exponentiation, for example from a quantum mechanics course.
    \item An idea of what a Green's function is.\sidenote{The course notes for Physics 231 may be a useful reference.\footnotemark}\footnotetext{\url{https://sites.google.com/ucr.edu/p231/}} We will not use this word too often, but understanding what it means usually correlates to a mathematics and physics background that will be helpful.
    \item Some introduction to relativistic quantum mechanics; for example, knowing the Dirac and the Klein-Gordon equations.
    \item Know what a cross section is from a mechanics course or, even better, Fermi's Golden Rule from a quantum mechanics course.
\end{itemize}
We do not live in a perfect world and it is much better to take the pioneering spirit of jumping in. As one of my undergraduate mentors told me, \emph{enthusiasm makes up for a lot of things.}\sidenote{Enthusiasm can be measured by how much time do you set aside to learn the \emph{extra} stuff that you need to best appreciate this course.}

\section{What it takes to succeed in this course}

\paragraph{Do your homework} I tell the Physics 39 classes that the best advice I can give is to \emph{do your homework}.\sidenote{Whenever I do this, I think about the Mary Schmich essay and Baz Luhrmann song, ``Wear Sunscreen.'' The song plays in the back of my head every time I talk about homework.\footnotemark}\footnotetext{\url{https://en.wikipedia.org/wiki/Wear_Sunscreen}} Trust me, I get no particular joy assigning or reviewing your homework---unlike many other topics I may teach, I actually know this shit. The value of homework is \emph{practice}.\footnote{\url{https://www.youtube.com/watch?v=p-BR1mXwtB0}} This is my commitment to you to cobble together an opportunity for \emph{you} check your understanding, to learn more (and more meaningfully), and to develop your own style of \emph{doing physics}. Part of my commitment to you is to create a space---our class---where we can work together on these meaningful exercises. I encourage you to do the homework, this is where you \emph{become a physicist}.

\paragraph{Ask questions} This course can be technical, it draws on different branches of physics, and even then it is just scratching the surface of some of the biggest open questions in science. If you engage with the material deeply enough, I \emph{expect you to be confused}. I am often confused. Do everyone a favor and ask during class. If you are embarrassed, I suggest phrasing your question as follows:
\begin{quote}
Is it obvious that...?
\end{quote}
When you ask it this way, the question is no longer about you being confused, it is about what is the most insightful way to think about a topic.

\paragraph{How to answer questions} The best part of a class is the community that we build together. I may be the person in the class who is most familiar with this material, but you and your classmates are the ones who are familiar with the journey that you're on---and there is a lot that I learn from your journey. As such, expect me to \emph{ask you questions}. This can be scary, but know that when I ask a question, I am not testing \emph{you} and what you have learned, I am testing \emph{me} and what I need to teach. If you find yourself on the business end of a question during class, consider the following options:
\begin{itemize}
    \item If you know the answer, give the answer and a justification.
    \item If you are not sure but think you know the answer, give the answer and a justification. You can even say that you are not sure and give reasons to be skeptical.\sidenote{This is part of the scientific method.} This is useful for me as well.
    \item If you have no idea what the answer is, then say so and explain what is confusing about the question. If you do not understand the question, then say that you do not understand the question and then ask a specific question for clarification. 
\end{itemize}% be ready to answer questions
% be critical: why are we doing this
% do your homework \url{https://www.youtube.com/watch?v=sTJ7AzBIJoI}


\section{Significant figures}

Most of the big ideas in this course do not require precise numbers. Usually we can get by with one significant figures---the mass of the proton is 1~\GeV{}. Sometimes we can get by with \emph{zero} significant figures---the Planck scale is on the order\sidenote{The `big-O' notation $\mathcal O$ means `order of magnitude. Because our study of particle physics spans the very small to the very large, you would be wise to be comfortable with this notation.} of $\mathcal O(10^{19}\,\text{\GeV{}})$. In fact, you should start every problem by thinking about the order of magnitude before you think about any significant figures. 

The only time where we will have to get into the weeds and sort one more than one significant figure is when we need to take the difference of two numbers and it matters whether the difference is positive or negative.\sidenote{Of course, this is simply saying that we care about the difference to one significant figure.}
\begin{example}
A good example of this is the mass of the proton versus the mass of the neutron. These, in turn, are due to small differences in the mass of the up versus the down quarks. The masses are:
\begin{align}
    m_\text{p} &= 938.3~\text{MeV}
    &
    m_\text{n} &= 939.6~\text{MeV}
\end{align}
and their mass difference is on the order of a percent of the masses. If proton were heavier than the neutron---a change in the at the \emph{third} significant figure---then the universe as you know it would be radically different. How different? For starters, instead of hydrogen atoms we would have neutrons---and we can say goodbye to chemistry.\sidenotemark
\end{example}\sidenotetext[][-7.5em]{This and related observations are described beautifully in Robert Cahn's article ``The eighteen arbitrary parameters of the standard model in your everyday life,'' which I strongly recommend that everyone read. Cahn is also the author of a great book on representation theory for those learning the subject on their own\footnotemark.}
\footnotetext{\cite{Cahn:1996ag}; and \cite{cahn2006semi}}


\section{These notes}

This is a first draft of these lecture notes. You can expect both outright errors and explanations that may not be fully satisfying. Please bring up any questions to me at your soonest convenience. 

I also have a tendency towards marginalia---sidenotes and footnotes. It is a habit I pick up from my favorite textbook authors (Tony Zee in particular); I feel like it brings a bit of the flavor of the course into the text. They also reflect my occasionally scatter-brained enthusiasm for this subject. If you are in a particular hurry, you can safely skip the side notes. I have tried to include references on the page that we use them rather than in a comprehensive bibliography in the back. Students who are especially dedicated to this subject are encouraged to pursue as many of these references as they are able to. 

\section{References}
Unfortunately there is not a perfect book on particle physics at this level.\sidenote{Jeff Richman at \acro{UCSB} is working on one that may be close. At the time of this writing that book is not yet complete.} Here are a few that you may consider. 

\subsection{Particle Physics}
\begin{itemize}
    \item \cite{Griffiths:2008zz}
    \item \cite{Larkoski:2019jnv}
    \item \cite{Peskin:2019iig}
    \item \cite{Cahn:1989by}
    \item \cite{Goldberg:2017dlc}
    \item \cite{Bettini:2008zz}
\end{itemize}

\subsection{Introductions to Quantum Field Theory}
Recently there has been an explosion in the number of ``quantum field theory for undergraduates'' textbooks. Here are a few that I think are particularly effective for further study. The books all start at the level assumed for this course, but each goes much deeper into the subject and wold be well suited for anyone interested in pursuing theoretical research in graduate school.
\begin{itemize}
    \item \cite{Schwichtenberg:2018dri}
    \item \cite{schwichtenberg2020no}
    \item \cite{Lancaster:2014pza}
    \item \cite{donoghue2022prelude}
    \item \cite{Zee:2010qce}
    % \item \cite{Perkins:2003pp}
    \item \cite{Feynman:1986er}
    \item \cite{Veltman:1994wz}
\end{itemize}

\subsection{Bird's eye view of particle physics}

\begin{itemize}
    \item The ``Pathways to Innovation and Discovery in Particle Physics'' Report of the 2023 Particle Physics Project Prioritization Panel is a great reference for the present state of the discipline.\footnote{\url{https://www.usparticlephysics.org/2023-p5-report/}}\sidenote{For those pursuing graduate study in particle physics: this document outlines scientific priorities of \acro{US} particle physics funding agencies. These priorities tend to align with the topics where research groups are looking for new graduate students. You may want to read the relevant parts carefully.}
    \item Fermilab and \acro{SLAC}, two of our flagship national laboratories in particle physics, have a for-the-public online magazine, \emph{Symmetry: Dimensions of Particle Physics}. This is a great starting point to dig a bit deeper into what is going in in particle physics.\footnote{\url{https://www.symmetrymagazine.org}} You may also find a discussion of more mathematical topics in some of the articles in \emph{Quanta Magazine}\footnote{\url{https://www.quantamagazine.org/physics/}}.
    \item There are a few well-known histories of particle physics ostensibly written for the general public. These include \emph{The Rise of the Standard Model}\autocite{hoddeson1997rise} and \emph{Inward Bound}\autocite{pais1988inward}. 
    \item In many ways, this field still exists in the shadow of the Superconducting Supercollider. The definitive history of this unfortunate saga is the book \emph{Tunnel Visions}\autocite{riordan2015tunnel}. YouTube documentarian BobbyBroccoli has an excellent movie-length three-part synopsis.\footnote{\url{https://www.youtube.com/watch?v=3xSUwgg1L4g}}
    \item There have been a few celebratory conference on the Standard Model. Steven Weinberg's 2003 talk\sidenote{\arXiv{hep-ph/0401010}} is a succinct history of both the successes and false directions---it is a nice chronological scaffolding to see how some of the big ideas in particle physics came to be. There is a great video archive of talks from the \acro{SM\@50} conference at Case Western in 2018\footnote{\url{https://www.youtube.com/playlist?list=PLBELrG1nZ2U6H3I1il4NhNVNcdUVUE5Ye}} and the 50 Years of \acro{QCD} conference at \acro{UCLA} in 2023\footnote{\url{https://www.youtube.com/playlist?list=PLjqOpQgpjtKoy21wrZ9hPnYM1KN97WYJH}}.
\end{itemize}
\begin{exercise}
Perhaps it is a bit silly that the celebration of 50 years of quantum chromodynamics---a \emph{part} of the Standard Model---was a few years after the celebration of the Standard Model. As an exercise, explain the chronology of what specific events were being celebrated at each event.
\end{exercise}

\chapter{Introduction}

This is a course on the theory of the Standard Model of particle physics. It is a theory so successful that it is called the \emph{Standard Model} with capital letters. Among its crowning achievements is the discovery of the Higgs boson~\autocite{CMS:2012zhx, ATLAS:2012ae} and the verification of the electron's anomalous magnetic moment~\autocite{Fan:2022eto}---the most precisely predicted and measured number in nature.\sidenote{The error is less than a part per trillion.}

This chapter is an \emph{amouse bouche} for the course. We review some of the key themes and big ideas to prepare you for a systematic study in subsequent chapters. This chapter may dip into some jargon and hint at some of the deeper undercurrents of quantum field theory. I include them here not to discourage you, but to whet your appetite for the journey ahead.

\section{What is Particle Physics}

Particle physics has had a few different names. It used to be called \emph{subatomic physics} because it is the study of things that are smaller than the atom. But then nuclear physics split off as a discipline\sidenote{By the end of this course, you may come to appreciate why this is the case.\footnotemark}\footnotetext{Nuclear physics works with \emph{effective theory} of hadrons at the \GeV{} scale. This theory is distinct from the Standard Model because it is precisely the regime where the theory of quarks is non-perturbative and alternative descriptions are necessary.} and what does it mean for a particle to be `smaller' anyway?

\begin{exercise}
If someone who is not a physicist asked you what the size of the electron is, what would you say? Go ahead and look up the radius of an electron. What does this number mean? What about a photon? What is the `size' of a quantum of light?\sidenotemark
\end{exercise}\sidenotetext[][-3em]{Confused? Good. You're thinking.}

Another historical name for particle physics is \emph{high-energy physics}. This is because our experimental apparatuses are traditionally colliders where we smash together particles at high energies. 
\begin{exercise}
What does it mean for a particle to have a ``high energy''? What is this energy being compared to? The kinetic energy of a mosquito flapping its wings is negligible for most human-scale activities, but it is quite substantial when smashing together two electrons.
\end{exercise}
This is because high energy colliders are actually microscopes. Go ahead and review Rutherford scattering in your favorite quantum mechanics book. Rutherford scattering is the famous experiment that lead to the discovery of nuclei by shining an electron beam onto a gold foil target. 
\begin{exercise}
How is the energy of the electron beam related to the spatial resolution of the experiment?
\end{exercise}
In this way, one may be forgiven for conflating particle physics with \emph{collider} physics. Indeed, particle physics is still a field that looks to the Large Hadron Collider as one of its Meccas. However, unlike the case even twenty years ago, modern particle physics is far more diverse than `just' high-energy [collider] physics.\sidenote[][-5em]{Theorist Hitoshi Murayama once said that this field stretches ``\emph{from the smallest scales to the largest, from the heavens to the hell}.'' By this he was referring to the most fundamental particles, the cosmological evolution of the entire universe, space-based telescopes, and underground detectors.} As of the time of this writing, a pretty good summary of the field is the 2023 Particle Physics Project Prioritization Panel (\acro{P5}) report.\footnote{\url{https://www.usparticlephysics.org/2023-p5-report/}} The report is the guiding document for the Department of Energy and National Science Foundation---the primary funding agencies for particle physics in the \acro{US}---for the key questions that particle physics seeks to answer over the coming decade.

So I am calling this field \textbf{particle physics}. Even this name is debatable: while the objects that we \emph{observe} are \emph{particles}---usually energy and momentum eigenstates, perhaps described by some sort of creation operator $a^\dag$---the underlying mathematical objects in our theory are \emph{quantum fields}. Even then, some phenomena in particle physics seem to probe the decidedly `wavey' limit of a quantum field.\footnote{See, for example, wave dark matter, \arXiv{2101.11735}.} You could call this ``applied quantum field theory,'' but applications of quantum field theory are much broader than particle physics. So for our purposes, let's call it particle physics and not get too hung up on minutiae.

So what is particle physics? \begin{quote}In this course, particle physics is the branch of science that seeks to build a model quantum field theory that describes the elementary constituents of nature and their fundamental interactions.\end{quote} We should parse a few key words here:
\begin{itemize}
    \item Quantum field theory is a theory-of-theories. The Standard Model of particle physics is \emph{a} quantum field theory in the same way that the hydrogen atom is a model quantum mechanical system. 
    \item We are building \emph{models}. A model is a mathematical description of an actual system. The mathematical description is usually idealized and hence simplified. The model is a way to learn about how underlying principles (usually symmetries) can lead to particular phenomena. See Fig.~\ref{fig:MilleniumFalcon}.
    \item We talk about the \emph{elementary constituents} of nature. In our model, these are quantum fields. Excitations of these fields are what we call elementary particles. The name is meant to evoke some sense of indivisibility, but this is not at all necessarily the case.\sidenote[][-3em]{I once read a story about a woman on a plane who was bragging about how brilliant her son is. When she saw her seatmate reading a book, \emph{Elementary Particle Physics}, she said ``hmph! Well, my son studies \emph{advanced} particle physics.''} For example, it can be convenient to write models where protons and neutrons are elementary, even though we know that they are not. 
    \item Finally, the \emph{fundamental interactions} between particles is conventionally what are called forces. We shall see in this class in particle physics, there is no strict distinction between particle and force---they are all described by quantum fields whose excitations are particles.\sidenote{In particle physics, everything is a particle. In contrast, to astronomers, subatomic scientists are either particle physicists or a metallurgists.\footnotemark}\footnotetext{\url{https://en.wikipedia.org/wiki/Metallicity}} 
\end{itemize}
\begin{figure}%[th]
    % \centering
    \sidecaption[][-2\baselineskip]{%
        What is the difference between these two? One is a screenshot of the Millennium Falcon from \emph{Wookiepedia}, the other is a picture of a \emph{model} of the Millenium Falcon from Lego. Physicists build models of nature. We hope that the model may illuminate principles of how nature works, but we do not confuse the model as a prescription for how nature must behave.
        \label{fig:MilleniumFalcon}
    }
    \includegraphics[width=\textwidth]{figures/MillenniumFalcon.png}
\end{figure}
These ingredients come together through a tool called a Feynman diagram.

\section{Diagrammar}

Fig.~\ref{fig:ee:gamma:gamma:example} is an example of a Feynman diagram.
\begin{marginfigure}%[th]
    \includegraphics[width=.8\textwidth]{figures/feyn_eegaga.pdf}
    \captionsetup{font={scriptsize,sf}}
    \caption{Example of a Feynman diagram. Here an electron and a positron annihilate into a pair of photons.}
    \label{fig:ee:gamma:gamma:example}
\end{marginfigure}
Feynman diagrams are a perturbative expansion of the quantum mechanical amplitude for a something to happen. You may recall that the quantum amplitude is a ``square root of the probability\footnote{This notion comes from quantum mechanics where the probability of observing a state $\ket{\Psi}$ is $\langle \Psi | \Psi\rangle = |\Psi|^2$. In quantum field theory we typically talk about \emph{cross sections}, $\sigma$. The relation between the amplitude $\mathcal M$ and cross section is $\sigma \sim |\mathcal M|^2$ and contains kinematic factors. We determine these kinematic factors in subsequent chapters.}.'' The statement that diagrams are a \emph{perturbative expansion} means that there is some small parameter for which we are performing a Taylor expansion\sidenote{Formally the amplitudes are complex and may contain singularities. It is thus more appropriate to say that this is a \emph{Laurent expansion}. One of the `deep' ideas in quantum field theory is the intimate relationship of \emph{analyticity} (complex differentiability) to physical properties. To dig deeper, see my Physics 231 notes.\footnotemark}\footnotetext{\url{https://sites.google.com/ucr.edu/p231/}}. In the standard case, this perturbative expansion is usually an expansion in couplings.

By \textbf{coupling} I mean a parameter of the theory that determines how much some particles interact with each other. When the coupling is large, the interaction is very strong. When the coupling is small, the interaction is very weak. One coupling that you may be familiar with is the electrodynamic coupling, $e$. You are probably most familiar seeing $e$ as an ingredient in the fine structure constant, 
\begin{align}
    \alpha = \frac{1}{\hbar c \varepsilon_0} \frac{e^2}{4\pi} \approx \frac{1}{137} \ .
\end{align}
The first factor of $(\hbar c \varepsilon_0)^{-1}$ are relics of using silly units. When we use natural units---see Sec.~\ref{sec:units:dimensions}---these are set to one. You can see that $1/137$ is a small number, so it at least makes sense that if we had some amplitude $\mathcal M(\alpha)$ that is a function of the electrodynamic couplings through $\alpha$ that we could imagine doing the perturbative expansion
\begin{align}
    \mathcal M = \mathcal M_0 + \alpha \mathcal M_1  + \alpha^2 \mathcal M_2 + \cdots \ ,
    \label{eq:amplitude:perturbative:expansion}
\end{align}
and then dropping any subleading terms since we expect them to be percent-level corrections. If the couplings are large, then this expansion breaks down because subsequent terms are not small. In fact, this is what happens with the strong interactions (quantum chromodynamics), the force that holds nuclei together. Thus there are regimes where the usual Feynman expansion fails: it seems like we should not use these diagrams to describe the interactions of the quarks and gluons that are `inside' a proton.
\begin{example}
I seem to have implied that Feynman diagrams do not work for the strong interaction. Despite this, collider physicists working on the Large Hadron Collider `speak' the language of Feynman diagrams. They'll even draw diagrams that involve the strong force. What gives? Apparently I haven't told you the whole story...
\end{example}
Note that I wrote \emph{couplings} not the common phrase \emph{coupling constants}. That is because---brace yourselves---these couplings are generally \emph{not} constant. In fact, they depend on the energy scale at which you probe them. If I smash together color-charged particles\sidenote[][]{In this class and in this field, we write \emph{colored} to mean color-charged, or charged with respect to the strong force. See Chapter~5 of \emph{The Disordered Cosmos} for an anthropological discussion.\footnotemark}\footnotetext{\cite{prescod2021disordered}} at high energies, the analogous fine structure parameter for the strong force, $\alpha_\textnormal{s} = g_\textnormal{s}^2/4\pi$ depends on the characteristic energy scale\footnote{We write $\sqrt{Q^2}$ rather than $E$ because $Q^2$ is a Lorentz-invariant quantity, as we explain below in our review of special relativity.} $\sqrt{Q^2}$ at which one probes the interaction, see Fig.~\ref{fig:aS:running:from:1604.08082}. 
\begin{marginfigure}%[th]
    \includegraphics[width=.8\textwidth]{figures/aSrun_1604.08082.png}
    \captionsetup{font={scriptsize,sf}}
    \caption{Approximate value of the strong force fine structure parameter, $\alpha_\textnormal{s}$. Lines correspond to slightly different calculations. The horizontal axis is the square of the characteristic energy scale at which $\alpha_\textnormal{s}$ is being measured. From Fig.~3.2 of \arXiv{1604.08082}.}
    \label{fig:aS:running:from:1604.08082}
\end{marginfigure}
This idea should be shocking the first time that you see it. The `coupling constants' are not constant at all. The meaning of this oddity is an idea called \emph{renormalization} and is rooted in making sense of what the \emph{actual} small parameter is in perturbation theory: it turns out not to be the fine structure constant, but the fine structure constant times a function of the kinematics of a process. This means that at sufficiently high energies, we can meaningfully talk about Feynman diagrams of quarks exchanging gluons. However, at low energies, these diagrams lose their meaning. If you were paying attention in the previous sub-section, this is the regime where particle physics becomes nuclear physics.
\begin{example}
This reminds me of the difference between a \emph{physicist} and a \emph{physics fan}. A physics fan is someone who thinks that $1/137$ is a fundamental constant of the universe and so should be tattooed on their body. A physicist stops to think: \emph{Where does this number come from?} and proceeds to learn about the scale-dependence of the electric coupling. In fact, in this course you will find that the electric coupling is not even a fundamental parameter but a combination of more fundamental parameters. I do not care whether or not you are a physics fan, but my goal is to train you as a physicist.
\end{example}

\begin{exercise}
On the subject of couplings: is the gravitational coupling \emph{large} or \emph{small} relative to the electromagnetic coupling? You may recall from popular physics that one of these is [surprisingly?] much stronger than the other. Try to make this quantitative by comparing two numbers. \textsc{Hint}: this is a bit of a trick question. Try writing out the gravitational fine structure constant and argue why it appears that you cannot meaningfully compare it to the electromagnetic coupling.
\end{exercise}

Feynman diagrams are graphs that represent a mathematical expression for a complex number. The graphs are trajectories in spacetime that we read from left to right. Each line in a diagram represents a particle. The lines may have decorations or labels that indicate their identity. In Fig.~\ref{fig:ee:gamma:gamma:example} the two lines on the left are an electron and a positron. The two wiggly lines on the right are each photons. Each vertex (intersection of lines) represents a factor of the coupling. In Fig.~\ref{fig:ee:gamma:gamma:example} the two vertices mean that this diagram contains two powers of the electric coupling, $e$. Thus this diagram contributes to the $\mathcal O(e^2) = \mathcal O(\alpha)$ term in the expansion of the amplitude $\mathcal M(e^+e^-\to \gamma\gamma)$ in \eqref{eq:amplitude:perturbative:expansion}. The notation $\mathcal M(e^+e^-\to \gamma\gamma)$ simply means the amplitude for an electron $e^-$ and a positron $e^+$ to turn into two photons, $\gamma\gamma$.

Something else that may be familiar from quantum mechanics: amplitudes sum together. This is the origin of quantum interference and all of the fun parts of quantum physics. Our perturbative expansion \eqref{eq:amplitude:perturbative:expansion} is one example of such a sum. However there are usually multiple diagrams that contribute at a given order in perturbation theory. One of the brilliant things about these diagrams is that they have a complementary interpretation: as a \emph{sum over histories}. This is an idea that we emphasize in our review of quantum mechanics, but the idea is this: 
\begin{quote}
The amplitude to go from some initial state to some final state is represented by the sum of all Feynman diagrams that connect the initial state to the final state. Each individual Feynman diagram in the sum represents a possible history that the initial state could have taken to reach the final state.
\end{quote}
This sum over histories interpretation is outrageous the first time you see it but is ultimately an extension of the principle of least time that underlies Snell's law in optics. The generalization to a principle of least action is the core of Lagrangian mechanics and was in fact Feynman's Ph.D thesis\autocite{feynman2005feynman}. 

The diagrams are simply a tool. Feynman's long time physics rival and co-Nobel prize winner, Julian Schwinger, was a master of calculating amplitudes in quantum field theory \emph{without} any diagrams. In one interpretation of history, Feynman's main contribution at this stage of physics history was bringing that calculational technology to the masses by giving each term an intuitive meaning.\sidenote{It is no surprise that he is also (mis-)attributed as the spokesperson of the ``shut up and calculate'' school of quantum physics.\footnotemark}\footnotetext{\cite{10.1063/1.1768652}} Veltman has a nice physics-oriented history of the spread of Feynman diagrams in his book \emph{Diagrammatica}\autocite{Veltman:1994wz}. This book should not be confused with a set of lecture notes he co-wrote with 
't~Hooft called ``Diagrammar\autocite{tHooft:1973wag},'' which inspired the name of this section.
% Not for this class, but also interesting: https://arxiv.org/abs/2109.06889
% Diagrammar of physical and fake particles and spectral optical theorem
%  Anselmi


As a final note: there is far more to quantum field theory than Feynman diagrams. As a perturbative expansion, Feynman diagrams represent the \emph{easiest} part of quantum field theory. But just as there are functions that cannot be meaningfully Taylor expanded\sidenote{Try expanding $\exp(-x^{-2})$ around the point $x_0 = 0$. Every term at every order vanishes, even though the function is well defined and non-zero away from the origin. The quantum field theory analog is something called an instanton and is beyond the scope of this course.}, there are vast swaths of field theory that are intrinsically \emph{non-perturbative}. Quantum chromodynamics at low energies---where we must turn to methods in nuclear physics---is one example. We make this caveat to emphasize that although we lean heavily on the diagrammatic interpretation of particle physics, we are still just scratching the surface.



% HW: muon shot. 
% Idea: every homework is a story



\section{Kinematics and Dynamics}

I may be the only person who makes a big deal about this, but we can separate our study of particle physics into two parallel tracks: {kinematics} and {dynamics}. You probably know that these words ``have to do with physics,'' but the distinction between them is rarely delineated. In fact, I suspect I may be making it up---in which case, here are the working definitions for this class. 

\textbf{Kinematics}\index{kinematics} has to do with the motion of particles through space and time. The kinematics of a scattering process relates to the momentum and energy of those particles. The conservation of energy and momentum are also kinematical facts\sidenote{Though their derivation through Noether's theorem is arguably a statement about dynamics.}. The thread of physics that is most relevant to this study is \emph{relativity}, and in particular the flat-spacetime version known as \emph{special relativity}.\sidenote{In contrast, general relativity is the study non-flat spacetimes. One can argue that it is the \emph{dynamics} of spacetime itself.}

\textbf{Dynamics}\index{dynamics}, on the other hand, has to do with the rules for how particles interact. When we talk about a theory or a model of particle physics, we usually mean a description of the dynamics. These are encoded in the action or Lagrangian of a theory. The dynamics of a theory draws primarily from the rules of \emph{quantum mechanics}.

Feynman diagrams are an output of the dynamics of a theory. However, a Feynman diagram is only physically meaningful if it obeys the rules of the kinematics of a theory. Kinematics are an additional consideration when we convert the squared amplitude into something physically measurable.
\begin{example}
You can draw a Feynman diagram for a process like $\gamma \to e^+e^-$ by which a photon decays into an electron--positron pair. You could even calculate the amplitude for this process to happen. However, this process is kinematically forbidden because it cannot simultaneously conserve energy and momentum. The amplitude is nonzero, but the decay rate is forced to be zero by kinematics.
\end{example}
\begin{exercise}
Show that both energy and momentum cannot be conserved in $\gamma \to e^+e^-$. There are many ways to do this, including some that are more slick than others. If you are stuck, come back to this exercise after our review of special relativity.
\end{exercise}

In this course, you can think of dynamics as the set of rules\sidenote{Called \emph{Feynman rules}.} that tell us how we may construct Feynman diagrams. These rules are an encoding of the Lagrangian of the theory.  You can think of kinematics as conditions on the energies and momenta of the initial and final states of an amplitude---these are the external lines of a diagram. Notably, kinematic constraints do not apply to the particles on the \emph{inside} of a Feynman diagram. Lines that obey the kinematic constraints are called \textbf{on shell}, while those that do not are called \textbf{off shell}.\sidenote{What is the \emph{shell}? It is the hypersurface the four-dimensional space of energy and momentum that satisfies the Einstein relation, $E^2 = m^2c^4 + p^2 c^2$ for a particle of mass $m$, energy $E$, and three-momentum $p$.} With this jargon, we say that external lines on a Feynman diagram represent parts of the initial or final states of a process and must be on shell. Internal lines are, in general, off shell.

\subsection{Symmetry}

The notion of \emph{symmetry} plays a central role for both the kinematics and the dynamics. The mathematical description of symmetry is called group theory and the way in which symmetries act on objects is called representation theory.\sidenote{I am name-dropping subjects because I am often asked what subjects should an aspiring theoretical physicist master.} The tables of Clebsch--Gordan coefficients that you may have invoked in your study of addition of angular momentum in quantum mechanics is an output of the representation theory of the group of three-dimensional rotations. In this course we are specifically interested in the representation theory of continuous groups---symmetries like rotations where you can transform by an arbitrary amount---called \emph{Lie groups}.\sidenote{Pronounced `lee.'} As humble physicists\sidenote{Oppenheimer: Well, if that’s how you treat a lieutenant colonel than I hate to see how you treat a humble physicist.\\Leslie Groves: If I ever meet one I'll let you know. (From \emph{Oppenheimer}, 2023)} the way we work with symmetries is to introduce indices. Objects that carry these indices are called \textbf{tensors}.

In special relativity (kinematics) the simplest tensors are four-vectors. They are called four-vectors because they are vectors that have four components. For example, the four-momentum of a particle may be written $p^\mu$. The index is $\mu$. There is a related object called $p_\mu$ with a lower index. These are related by a tensor called the metric tensor, which for our purposes we write $\eta_{\mu\nu}$. The metric gives us a way to define an inner product. This should all sound familiar from linear algebra because this \emph{is} linear algebra. In representation theory, the objects that get rotated\sidenote{By `rotate' I mean a general symmetry transformation. For the case of special relativity, one can have boosts in addition to rotations.} are vectors in a vector space. If you ever wonder why I teach Physics 17 the way that I do, it is because I want students to be primed to understand representation theory as it appears in physics.

Maybe the phrase `inner product' caught your ear. This is the same idea that comes up in quantum mechanics. In fact, now you may recall that quantum mechanics really boils down to complex linear algebra. In fact, many ideas in quantum mechanics are ultimately group theoretical. For example, the commutator is the natural multiplication operation between elements of a group.\sidenote{Check that while this may be surprising, it is sensible. The commutator of two operators is another operator in the same way that the multiplication of two things of a given type should be another thing of the same type.} Furthermore, finite transformations are the exponentiation of infinitesimal transformations. For example, the Hamiltonian $\hat H$ is the generator of translations in time. A finite translation in time is
\begin{align}
    \hat U(t) = e^{-i \hbar t\hat H} \ .
    \label{eq:Ut:time:H}
\end{align}
\flip{check the $\hbar$}
In particle physics we will meet several \textbf{internal symmetries} that mathematically describe the rotation of an object in different vector spaces. These do \emph{not} correspond to spacetime rotations or boosts. Instead, they may represent a rotation between quarks of different color charges.\sidenote{We define these carefully below where we discuss quantum chromodynamics. For this introduction just humor me and go with the flow to appreciate the big idea.} The infinitesimal generators of these transformations take the form\footnote{I am using `physicist' shorthand here and referring to a tensor by its components. Supercilious mathematicians sneer at us for this. Formally, $A\aij{i}{j}$ is not a matrix, it is the $i$--$j$ \emph{component} of a matrix A. Physicists justify our sloppiness because anyone who is paying attention should understand what we mean and, more importantly, by keeping the indices explicit we can see how the tensor transforms.}
\begin{align}
(T^A)\aij{i}{j}\ ,    
\end{align}
where we recognize three indices. The index $A$ is called an adjoint index and tells you which direction you are rotating. For the rotation group, $A$ takes values from 1 to 3 corresponding to rotations about the $x$, $y$, and $z$ axes. All other rotations are combinations of these. The other two indices, $i$ and $j$ depend on the \emph{representation} of the object that we are rotating. 
\begin{example}
In quantum chromodynamics we there are eight generators of so-called color symmetry. This means $A$ takes values from 1 through 8. This group is called \acro{SU(3)}, which stands for the set of $3\times 3$ special unitary matrices.\sidenotemark A quark has indices that I conventionally write with lowercase letters from the middle of the Roman alphabet that take values $m$ from 1 to 3 corresponding to red, blue, and green. The matrix $(T^4)\aij{m}{n}$ represents a particular rotation around the $A=4$ axis. A finite transformation by angle $\theta$ takes the form 
\begin{align}
    q^m \to \sum_n e^{i \theta (T^4)\aij{m}{n} } q^n \equiv \sum_n U(\theta)\aij{m}{n}q^n \ ,
\end{align}
where the sum over $n$ is what we expect from matrix multiplication.
\end{example}\sidenotetext[][]{Special means unit determinant. Unitary, as you may recall from quantum mechanics, means that the hermitian conjugate is its inverse.}

This is all to say that indices feature front-and-center in this course. They are a crutch for us to talk about the underlying symmetries that govern both the kinematics and dynamics of particle physics. We will spend a good chunk of this course building familiarity with how to interpret and manipulate indices. This is a mathematical skill that is far more general than particle physics itself.





\section{Natural Units}
\label{sec:units:dimensions}

By this stage of your physics career you are an expert at converting units. The trick is to multiply be one in different forms. Suppose you have some unit $x$ that is related to unit $y$ by some prefactor,
\begin{align}
    x = a y \ . \label{eq:unit:conversion}
\end{align}
Then you can derive that
\begin{align}
    1 = \frac{ay}{x} = {x}{ay} \ .
    \label{eq:multiply:by:one:unit:conversion}
\end{align}
Then if some quantity is, say, $3.4\,x$, you know that you can write it out in terms of $y$ simply by multiplying by one, cleverly written:
\begin{align}
    3.4\,x = 3.4\times 1 \times x = 3.1 \times \frac{ay}{\cancel{x}} \times \cancel{x}
    = (3.4a)\, y \ .
\end{align}
\eqref{eq:multiply:by:one:unit:conversion} tells us that there is a universal, unambiguous constant ratio that relates unit $x$ to unit $y$. 


\begin{example}
Suppose someone tells you the number of feet in a mile,
\begin{align}
    1~\text{mile} = 5280~\text{feet} \ .
\end{align}
This number just so happens to be the mass of the $B$ meson in \acro{MeV}.
You can derive that
\begin{align}
    1 = 5280~\frac{\text{feet}}{\text{mile}}
    = \frac{1}{5280}~\frac{\text{mile}}{\text{feet}} \ .
\end{align}
From this you can deduce that a distance of $1.5$ miles is
\begin{align}
    1.5\,\text{mile} = 
    1.5\,\cancel{\text{mile}} \times \left(5280~\frac{\text{feet}}{\cancel{\text{mile}}}\right) = 
    7920~\text{feet} 
    \approx 8000~\text{feet} 
    \ .
\end{align}
\end{example}

If this all looks completely simple then \emph{good}, it is supposed to. There is nothing deep or mysterious about changing units. Let us really put it to work. \textbf{Natural units}\index{natural units} are a convenient choice that boils down to the following identifications:
\begin{align}
    c &=1  &
    \hbar &= 1
    \ .
\end{align}
That's right. The speed of light $c$ and reduced Planck's constant $\hbar$ are set to one. This may bother you. After all, you know from past coursework that these are \emph{not} dimensionless quantities:
\begin{align}
    c &= 3\times 10^{8}\,\frac{\textnormal{m}}{\textnormal{s}}
    &
    \hbar &= 1\times 10^{-34}\,\frac{\textnormal{m}^2 \textnormal{kg}}{\textnormal{s}} \ .
    \label{eq:c:hbar:SI}
\end{align}
Setting $c = 1$ would then mean that there is an unambiguous way conversion between length and time, as if these were measuring the ``same thing.'' But length is measured by rulers and time is measured by clocks: how are these the same? They are the same \emph{precisely} because nature\sidenote{All our observations since the Michelson--Morley experiment are consistent with a constant speed of light and this is built into our theory of special relativity. Theoretically this is an aesthetic unification of space and time that laid the foundation of general relativity, which in turn has passed every experimental prediction.} gives us a universal, unambiguous constant ratio that relates units of length into units of time. This constant is the speed of light.
\begin{example}
A lightyear is a unit of distance. It is defined to be the distance traversed by a particle traveling at the speed of light,
\begin{align}
    \text{lightyear} = c\, \text{year} \ ,
\end{align}
where we see that the speed of light in natural units $c=1$ plays the role of a conversion factor in \eqref{eq:unit:conversion}. 
\end{example}
% Naive dimensional analysis
% \autocite{Manohar:1983md,Georgi:1986kr,Georgi:1992dw}
Identifying the speed of light as a conversion factor ends up relating another set of dimensionful quantities. All velocities in natural units are dimensionless. This is because we can simply write any velocity in units of the speed of light.
\begin{example}
The tangential speed of the Earth around the solar system is around $v = 200$\,km/s. In natural units this is a dimensionless number:
\begin{align}
v = 200\,\frac{ \textnormal{km} }{ \textnormal{s} }
=
2\times 10^{5} \, \frac{\textnormal{m}}{\textnormal{s}} 
\times 
\left(\frac{1}{3\times 10^8}\frac{\textnormal{s}}{\textnormal{m}}\right)
= 7 \times 10^{-3} \ .
\end{align}
In natural units, any sensible velocity has magnitude less than one. Otherwise something is traveling faster than the speed of light. 
\end{example}
\begin{exercise}
What goes wrong in physics if a particle can travel faster than the speed of light? \textsc{Hint}: review the relativity of simultaneity. 
\end{exercise}
Velocities are dimensionless in natural units. 
Recall that energy has the units of mass times velocity squared. You may recall this from from 
\begin{align}
    E_\textnormal{kinetic} = \frac{1}{2} mv^2 \ .
\end{align}
You may argue that this formula is only true for kinetic energy. That is true, energy---no matter what the form---is carries the same type of dimension. Because velocities are dimensionless, then the dimensions of energy and the dimensions of mass must be the same. In other words, mass and energy are ``the same thing.'' Given a particle of some mass---say the mass of a proton, $m_\textnormal{p}$---there is an associated energy that is $m_\textnormal{p} \times 1  = m_\textnormal{p} c^2$. This looks remarkably like the non-relativistic limit of the Einstein relation,
\begin{align}
    E = mc^2 \ .
\end{align}
Indeed, in that limit, the Einstein relation just tells us that mass and energy are the same thing. The square of the speed of light plays the role of a conversion factor between them. It is conventional for particle physicists using natural units to measure everything in units of energy. A particularly useful energy scale is 
\begin{align}
    m_\textnormal{p} = 1\,\text{\GeV{}} \ .
\end{align}
To one significant figure, the mass of the proton happens to be about one billion times an electron volt.  
\begin{exercise}
How much do you weigh in \GeV{}? 
\end{exercise}
Sometimes we lapse into other powers of electron volt. Some useful values are the mass of the electron and the mass of the Higgs boson\sidenote{We write $m_h$ to three significant figures because the Higgs is a big deal.}, and the center-of-mass energy of proton-proton collisions at the Large Hadron Collider:
\begin{align}
    m_e &= 0.5\,\text{MeV}
    &
    m_h &= 125\,\text{GeV}
    &
    E_\text{cm} &= 14\,\text{TeV} \ .
\end{align}



What about $\hbar = 1$? Planck's constant carries units of angular momentum\sidenote{These are also the units of action, $S=\int dt\,L$.}, or energy times time. Using the just-established equivalence of mass and energy in natural units, this tells us that
\begin{align}
    \hbar &= 7 \times 10^{-22}\,\textnormal{MeV}\,\textnormal{s}  \equiv 1 \ . 
\end{align}
% \begin{align}
%     \hbar = 10^{-34}\,\frac{\textnormal{m}^2 \textnormal{kg}}{\textnormal{s}}
%     \times 
%     \left(3\times 10^{8}\,\frac{\textnormal{m}}{\textnormal{s}}\right)^{-2}
%     = 
%     10^{-51}\,\textnormal{kg}\,\textnormal{s} \ .
% \end{align}
This means that the fundamental unit of ``quantum-ness'' tells us that time and inverse energy are ``the same thing.''
\begin{example}
How would you measure $\hbar$ to determine that it is a universal constant? Like measuring $c$, there are many options. You could look at the deflection of particles in a Stern--Gerlach experiment, measure distributions of position uncertainties given multiple measurements of a momentum eigenstate, the spectrum of hydrogen (and corrections thereof), etc. 
\end{example}
At this point, you can multiply and divide by $c$ and $\hbar$ as needed to write all dimensionful parameters in units of \GeV{} to some power. 
\begin{example}
An additional conversion is to set the Boltzmann factor, $k_\textnormal{B} =1$. This is the observation that thermal energy is energy and can be measured in \GeV{}.
\end{example}
We provide a useful table for conversions to one significant figure.
\begin{table}[ht]
    \renewcommand{\arraystretch}{1.3} % spacing between rows
    \centering
    \sidecaption[Useful conversions to natural units. Adapted from Palash Pal's website.][-2\baselineskip]{%
        Conversion of units using $\hbar = c = k_\textnormal{B} = 1$. The row heading is equal to the table entry times the column heading so that a \GeV{} is a small number of Planck masses, $M_\textnormal{Pl}$.  Adapted from Palash Pal's website.\footnotemark 
  %       \label{table:app:natural:unit:conversion}
    }
    \begin{tabular}{ @{} lllllll @{} } \toprule % @{} removes space
        & \GeV{} & g & K & cm$^{-1}$ & sec$^{-1}$ & M$_\textnormal{Pl}$
        \\ \midrule
        \GeV{} % col
        & % GeV
        & 1$\times 10^{-24}$ % g
        & 1$\times 10^{13}$% K
        & 5$\times 10^{13}$% cm-1
        & 2$\times 10^{24}$% s-1
        & 8$\times 10^{-20}$% Mpl
        \\
        g % col
        & 6$\times 10^{23}$% GeV
        & %$\times 10^{}$% g
        & 7$\times 10^{36}$% K
        & 3$\times 10^{37}$% cm-1
        & 9$\times 10^{47}$% s-1
        & 5$\times 10^{4}$% Mpl
        \\
        K% col
        & 9$\times 10^{-14}$% GeV
        & 2$\times 10^{-37}$% g
        & %$\times 10^{}$% K
        & 4%$\times 10^{}$% cm-1
        & 1$\times 10^{11}$% s-1
        & 7$\times 10^{-33}$% Mpl
        \\
        cm$^{-1}$ % col
        & 2$\times 10^{-14}$% GeV
        & 4$\times 10^{-38}$% g
        & 2$\times 10^{-1}$% K
        & %$\times 10^{}$% cm-1
        & 3$\times 10^{10}$% s-1
        & 2$\times 10^{-33}$% Mpl
        \\
        sec$^{-1}$ % col
        & 7$\times 10^{-25}$% GeV
        & 1$\times 10^{-48}$% g
        & 8$\times 10^{-12}$% K
        & 3$\times 10^{-11}$% cm-1
        & %\times 10^{}$% s-1
        & 5$\times 10^{-44}$% Mpl
        \\
        M$_\textnormal{Pl}$% col
        & 1$\times 10^{19}$% GeV
        & 2$\times 10^{-5}$% g
        & 1$\times 10^{32}$% K
        & 6$\times 10^{32}$% cm-1
        & 2$\times 10^{43}$% s-1
        & %$\times 10^{}$% Mpl
        \\ \bottomrule
    \end{tabular}
  %   \caption[Useful conversions to natural units. Adapted from Palash Pal's website.]
  %   {
  %       Conversion of units using $\hbar = c = k_\textnormal{B} = 1$. The row heading is equal to the table entry times the column heading so that a \GeV{} is a small number of Planck masses, $M_\textnormal{Pl}$.  Adapted from Palash Pal's website.\footnotemark 
        \label{table:app:natural:unit:conversion}
  % }
\end{table}\footnotetext{\url{https://www.saha.ac.in/theory/palashbaran.pal/conv.html}}

\begin{example}[Mnemonics]
You can use your favorite equations in physics as mnemonics for natural units. We already saw how $E=mc^2$ reminds us that energy and mass both carry the same units. You can also invoke Heiseinberg's uncertainty relations
\begin{align}
    \Delta x\,\Delta p &\sim \hbar 
    &
    \Delta E \Delta t &\sim \hbar
\end{align}
to remind us that momentum and distance carry reciprocal units, as do energy and time. Because $c=1$ tells us that distance and time are the same, we find
\begin{align}
    \text{length} \sim \text{time} \sim \frac{1}{\text{mass}} 
    \sim \frac{1}{\text{energy}} \ .
\end{align}
\end{example}

The great thing about natural units is that we just have to keep track of one unit, say \GeV{}. Dimensional analysis is very simple and we introduce the bracket notation:
\begin{align}
    [x] \defeq ``\text{dimensions of }x \ .''
\end{align}
$[x]$ means: what power of energy is the unit of quantity $x$?
\begin{example}
For a distance $\ell$, time $t$, mass $m$, and energy $E$:
\begin{align}
    [\ell] &= -1
    &
    [t] &= -1
    &
    [m] &= 1
    &
    [E] &= 1
    \ .
\end{align}
\end{example}
\begin{exercise}
What are the dimensions of the gravitational constant, $[G_\textnormal{N}]$? \textsc{Hint}: you can use the force law for gravity to figure out the \acro{SI} units of $G_\textnormal{N}$.
\end{exercise}

\begin{exercise}
Show that the units of action are the same as the units of angular momentum. \textsc{Hint}: use the expression for the action with your favorite choice of Lagrangian.
\end{exercise}

\begin{example}[Collider physics as microscopy]
The Large Hadron Collider is a microscope. The center of mass energy of the proton--proton collisions is $E = 10~\textnormal{TeV}$. To convert this into a length scale, we divide by \ .
\begin{align}
    \hbar c = 10^{21}\frac{1}{\textnormal{MeV}\,\textnormal{s}} \times 10^{-8} \frac{\textnormal{s}}{\textnormal{m}}
\end{align}
This gives us
\begin{align}
    E &= 10^7~\textnormal{MeV} \times 10^{21}\frac{1}{\textnormal{MeV}\,\textnormal{s}} \times 10^{-8} \frac{\textnormal{s}}{\textnormal{m}}
    \\
    &= \frac{1}{10^{-20}\,\textnormal{m}} \ .
\end{align}
The length scale associated with $10~\textnormal{TeV}$ is tiny: $10^{-20}~\textnormal{m}$. Compare this to the typical atomic length, $\text{\AA} = 0.1~\textnormal{nm} = 10^{-10}~\textnormal{m}$. The inverse relation $\ell \sim E^{-1}$ makes it clear that increasing the energy decreases the length scale. 
\end{example}

We can understand the $E \sim \ell^{-1}$ relation from ordinary optical microscopy. As we increase the energy of a photon, we increase its frequency and therefore decrease its wavelength, $\lambda$. We need the wavelength of the probe to be \emph{smaller} that the characteristic size features that we are studying, $\lambda \ll \Delta x$. Figure~\ref{fig:subfig:waves} demonstrates this idea by showing rocks of different sizes in a stream with water waves of uniform scale $\lambda$.

\begin{figure}%[th]
    \centering
    \begin{subfigure}{0.3\textwidth}
    \centering
        \includegraphics[width=\linewidth]{figures/waves_small.pdf}
        \caption{$\Delta x \ll \lambda$}
        \label{fig:subfig:waves:small}
    \end{subfigure}\;%
    \begin{subfigure}{0.3\textwidth}
    \centering
        \includegraphics[width=\linewidth]{figures/waves_med.pdf}
        \caption{$\Delta x \sim \lambda$}
        \label{fig:subfig:waves:med}
    \end{subfigure}\;%
    \begin{subfigure}{0.3\textwidth}
    \centering
        \includegraphics[width=\linewidth]{figures/waves_big.pdf}
        \caption{$\Delta x \gg \lambda$}
        \label{fig:subfig:waves:big}
    \end{subfigure}%
    \caption{The ability to probe features (like a rock) of typical scale $\Delta x$ depends on having a probe whose wavelength $\lambda$ is roughly on the order of $\Delta x$. If the scales are mismatched, then the waves are unable to resolve the $\mathcal O(\Delta x)$ features.}
    \label{fig:subfig:waves}
\end{figure}



\chapter{Rapid Review of Relativity}

We begin our study of particle physics with a lightning review of selected topics in special relativity and quantum mechanics.

\section{Kinematics}

The popular Einstein relation, $E = mc^2$, is actually the low [kinetic] energy limit of the `full' relation:
\begin{align}
    E^2 = m^2 c^4 + \vec{p}^2 c^2 \ .
    \label{eq:Einstein:relation:plus}
\end{align}
Equations that relate energy to momentum show up all over physics and have a special name: \textbf{dispersion relations}.\sidenote{As a student I always found this name intimidating because it would keep showing up in very different and increasingly advanced corners of physics. I felt like I must be missing something deep, especially since the word \emph{dispersion} did not seem to obviously fit. Historically, these relate wavelength to frequency. Recall that wave velocity is the product of wavelength and frequency---but wave velocity is purely a property in medium. Wavelength (or wave number) is directly related to momentum---think 
$\sin(kx)$---while frequency is directly related to energy---think $E=\hbar\omega$. These of these parameters are related to absorption (or decay) through complex analysis; these are the celebrated Kramers--Kr\"onig relations. We mention all of this to encourage you to look these ideas up and see how they connect; they are one of the deep threads in physics.} 
\begin{exercise}
It is obvious that \eqref{eq:Einstein:relation:plus} reproduces $E=mc^2$ when $\vec{p}=0$. Show that the leading order correction in the small-$\vec{p}$ limit is simply the non-relativistic kinetic energy of the particle. \textsc{Hint:} start by identifying the \emph{dimensionless} small parameter and Taylor expand.
\end{exercise}
In natural units we set $c=1$. In this relation, $m$ is the mass of a particle while $E$ and $\vec{p}$ are the energy and three-momentum respectively. Let us write this with the kinematic quantities on the same side of the equation:
\begin{align}
    m^2 = E^2 - \vec{p}^2 \ .
    \label{eq:on:shell}
\end{align}
A particle that satisfies this relation is said to be \textbf{on shell}\index{on shell} or \emph{physical}. Anticipating quantum mechanics, another way of saying this is that on shell particles are \emph{observable states}. Personally, I think of `on shell' states as being \emph{nice} states that are relatable to my ordinary human experiences. This is in contrast to \textbf{off shell} particles, which states that are \emph{not} on shell and are intrinsically quantum. Off shell states are not observable and do not make sense classically. 

A scattering process is one where some number of \emph{observed} initial state particles interact quantum mechanically and produce and \emph{observed} number of final state particles. These initial and final states must each be on shell and conserve energy and momentum. 
\begin{newrule}[Kinematics]
A \textbf{physical scattering process} is one with an on shell initial state and an on shell final state. This just means that each particle in the initial and final state are on shell. Furthermore, the total energy $E$ and total three-momentum $\vec{p}$ are conserved through the process. In equations:
\begin{align}
    E_\textnormal{in} &= E_\textnormal{out}
    &
    \vec{p}_\textnormal{in} &= \vec{p}_\textnormal{out}
    &
    m_i^2 = E_i^2 - \vec{p_i}^2 \ ,
\end{align}
where $i$ labels each of the external (initial or final) particles. Technically, we should also specify that $E_i>0$, but for us we can take this as an ``obvious'' fact.\sidenotemark Note that in this notation, $E_\textnormal{in}$ is the sum of the energies of all the initial state particles, and similarly for the other in/out quantities.
\end{newrule}\sidenotetext{From a group theory perspective, positive energy means that we are restricting to the \emph{orthochronus}\index{orthochronus} Lorentz group. This means that particles always move forward in time, no matter what reference frame we are in. The relation between energy positivity and direction in time should be clear from the time evolution operator, \eqref{eq:Ut:time:H} with $\hat H\to E$.}

Suppose you have a particle detector that measures the energy of a particle passing through it---this is called a \emph{calorimeter}. If you also know the mass of the particle, then you can also unambiguously determine the magnitude of the momentum, $|\vec{p}|$.  Alternatively, if you could separately measure the energy and the momentum of a particle, then you can unambiguously infer its mass. This is all obvious because you are using one Einstein relation to relate three variables---mass, energy, and momentum. 

\begin{exercise}
Suppose you have a process where one particle decays into two other particles; these particles do not necessarily have the same masses, but suppose you know all of the masses. You know the energy and momentum of the initial particle, $E_\textnormal{in}$ and $\vec{p}_\textnormal{in}$. You do not know, \emph{a priori}, the energies or momenta of the final state particles. How many unknown scalar quantities are there? How many constraint equations are there? \textsc{Hint}: recall that $\vec{p}$ is a vector with three separate quantities. Argue that there is generically \emph{no} solution to this system unless some parameters (e.g.\ the masses) are just right.
\end{exercise}

\begin{exercise}
Suppose you have a process where two particles come in, and two particles come out. The particles do not necessarily have the same mass, but you know all of the masses. If you know the energies of the initial particles, how many unknowns are there and how many constraint equations are there? Do you expect this system to have a solution? \textsc{Note}: for the purposes of this problem, assume that all energies are positive. This corresponds to satisfying the orthochronus constraint. If you are nervous about this, check that by increasing the energies of the initial particles you can make sure that the final state particles have positive energy. 
\end{exercise}


\section{Time Dilation and Length Contraction}

\begin{flipcomment}
This section is a very brief review of the main points. For a more systematic derivation, please see my Physics 17 lecture notes. 
\end{flipcomment}

My favorite refernece to appreciate the geometric structure of special relativity is the book \emph{Very Special Relativity}\autocite{bais2007very}.
\begin{marginfigure}%[th]
    \includegraphics[width=.8\textwidth]{figures/vsr_cover.png}
    \captionsetup{font={scriptsize,sf}}
    \caption{How to learn special relativity.}
    \label{fig:VSR:cover}
\end{marginfigure}
It looks like a miniature coffee table book, but it is a perfect book for physics students who have completed their lower-level coursework.\sidenote{If you can derive every result in the book then you are ready to take general relativity. You should be able to do this over a winter break.}\sidenote{Do not confuse the title of this book with the Cohen--Glashow hypothesis, \arXiv{hep-ph/0601236}, which is a rather different thing.} Once you have mastered this, you can pick up your favorite general relativity textbook for a bit more of the mathematical formalism. Some suggestions: Hartle\autocite{Hartle:2003yu}, Schutz\autocite{schutz2009first}, and Carroll\autocite{Carroll:2004st}. I would be remiss not to also mention the beautiful and elegant tome known lovingly as \acro{MSW}\autocite{misner2017gravitation}; a book so beloved that it had its own 50$^\textnormal{th}$ anniversary celebration.\footnote{\url{https://www.youtube.com/watch?v=a-4-IPBNV60}}
\begin{marginfigure}%[th]
    \includegraphics[width=.8\textwidth]{figures/MSW_cover.png}
    \captionsetup{font={scriptsize,sf}}
    \caption{Published 50 years ago---right around when the Standard Model was established---\tacro{MSW} is still one of the most insightful places to learn and re-learn relativity. }
    \label{fig:MTW:cover}
\end{marginfigure}

The key tenet of special relativity is that the speed of light is constant. You already know from \eqref{sec:units:dimensions} that this constant means that there is a natural conversion between space and time. Indeed, you should already be familiar with the two primary manifestations of this in mechanics:
\begin{itemize}
    \item Time dilation: We measure time to pass more slowly for objects moving relative to our reference frame.
    \item Length contraction: We measure the distance along the direction of motion to be shorter for objects moving relative to our reference frame. 
\end{itemize}
This is formalized with respect to the relative velocity\sidenote{In \tacro{SI} units we would say $\beta = v/c$.} $\beta = v$ and the factor
\begin{align}
    \gamma = \frac{1}{\sqrt{1-\beta^2}} \ .
\end{align}
\begin{exercise}
What is the range of allowed values of $\beta$? What is the range of allowed values for $\gamma$? What is the allowed range of the product $\gamma\beta$?
\end{exercise}
We, as observers, define a stationary reference frame with coordinates $t$ and $x$. For our purposes, let us assume a (1+1)-dimensional spacetime.\sidenote{This notation means one dimension of time and one dimension of space.} Suppose that there is another references frame that is moving at constant velocity relative to ours. Then an observer in that reference frame has a coordinate system $t'$ and $x'$. Fig.~\ref{fig:relativity:axes} plots the axes of this coordinate system on our coordinate system. 
\begin{marginfigure}%[th]
    \includegraphics[width=\textwidth]{figures/rel_axes.pdf}
    \captionsetup{font={scriptsize,sf}}
    \caption{Coordinates of a boosted observer relative to our coordinates.}
    \label{fig:relativity:axes}
\end{marginfigure}
\begin{exercise}
Compare Fig.~\ref{fig:relativity:axes} to the spatial $x$--$y$ plane and the $x'$--$y'$ plane where the primed coordinates are those of an observer rotated by angle $\theta$ relative to the unprimed observer.
\end{exercise}
the coordinates are related by
\begin{align}
    t' &= \gamma t - \gamma\beta x &
    x' &= \gamma x - \gamma\beta t \\
    t &= \gamma t' + \gamma\beta x' &
    x &= \gamma x' + \gamma\beta t' 
    \ .
    \label{eq:Lorentz:2D:in:equations}
\end{align}
We realize that this is a linear system of equations,\sidenote{Recall that system of equations is linear if a \emph{linear combination} of solutions is also a solutions.} so we can write this as a matrix multiplication:
\begin{align}
    \begin{pmatrix}
        t\\
        x
    \end{pmatrix}
    =
    \begin{pmatrix}
        \gamma & \gamma \beta \\
        \gamma \beta & \gamma
    \end{pmatrix}
    \begin{pmatrix}
        t'\\
        x'
    \end{pmatrix} \ .
    \label{eq:Lorentz:2D:prime:to:unprimed}
\end{align}
\begin{exercise}
Show that 
\begin{align}
    \begin{pmatrix}
        t'\\
        x'
    \end{pmatrix}
    =
    \begin{pmatrix}
        \gamma & -\gamma \beta \\
        -\gamma \beta & \gamma
    \end{pmatrix}
    \begin{pmatrix}
        t\\
        x
    \end{pmatrix} \ .
\end{align}
You can do this either ``read it off' \eqref{eq:Lorentz:2D:in:equations} or apply the matrix inverse to both sides of \eqref{eq:Lorentz:2D:prime:to:unprimed}. Show that the two matrices are, indeed, inverses of each other.
\end{exercise}
\begin{exercise}
Confirm that \eqref{eq:Lorentz:2D:prime:to:unprimed} maps $x'$ and $t'$ axes to the $x$ and $t$ plane as shown in Fig.~\ref{fig:relativity:axes}.
\end{exercise}

% \begin{example}
% Suppose the boosted observer has a stick that they measure to be length $\ell'$. Because the observer and the stick are at rest relative to each other, we say that $\ell'$ is the \textbf{proper length} of the stick. That means in a time slice $\Delta t' = 0$ it observes a distance interval $\Delta x' = \ell'$. In our frame, we measure
% \begin{align}
%     \Delta t &= \gamma \beta \,\Delta \ell'
%     &
%     \Delta x &= \gamma \,\Delta\ell' \ .
% \end{align}
% It is helpful to define an origin where the origins of both reference frames coincide: $t_1 = t_1' = 0$ and $x_1 = x_1=0$
% \end{example}


\section{Indexology of Special Relativity}

\subsection{Upper Index}\label{sec:index:upper}

The unification of space and time is manifest in the formalism of \textbf{four vectors}\index{four vector}. At one level, this is a simple generalization of three-component vectors to four-component vectors. For example, an \emph{event} is a position $\vec{x}$ and a time $t$ and we can write it as a four-vector with an upper index:
\begin{align}
    x^\mu \equiv (x^0, x^1, x^2, x^3) = (t,x,y,z) \ .
\end{align}
There are several caveats that we should make at this point since they are not often stated out loud in textbooks:
\begin{itemize}
    \item We use the usual physicist's abuse of notation where we identify an object $x$ with a generic component, $x^\mu$. 
    \item It is conventional to index time with $\mu=0$. Some old texts use the antiquated notation $x^4$. For this reason in theories of extra dimensions it is conventional to label the extra dimension as $x^5$. 
    \item There is no such thing as a \emph{position vector}.\sidenote{I know a mathematician who was confused when the physics students in his calculus class kept talking about position vectors, as if the students were talking about unicorns. This may seem like nit picking, but it this insight is part of the underlying geometric picture built on fiber bundles. See \arXiv{hep-th/0611201} for a pedagogical introduction that should be accessible to students of this class with a bit of work.} This is because vector spaces have a special point, the origin $x^\mu = 0$. There is no such special point in spacetime. However, relative positions, $\Delta x^\mu = x_A^\mu - x_B^\mu$, are well defined vectors. 
\end{itemize}
In particle physics we do not often deal with (relative) position four vectors because our states are typically momentum eigenstates. Just as time and space are unified by $c=1$, so too are energy and momentum. These are combined into a four-momentum,
\begin{align}
    p^\mu \equiv (p^0, p^1, p^2, p^3) = (E, p^x, p^y, p^z) \ .
    \label{eq:fourmomentum:upper}
\end{align}
$p^\mu$ is the Fourier transform of $x^\mu$. It should not surprise you that we work with momentum eigenstates: these are the states that are eigenstates of the Hamiltonian by virtue of having a well defined energy. The on shell condition \eqref{eq:on:shell} then gives a well defined three-momentum magnitude.

Like any other vector space, linear combinations of vectors are also vectors. Recall that a linear combination of vectors is a sum of vectors that each may have some rescaling by a real number. For two vectors, this is:
\begin{align}
   (\alpha\vec{v}+\beta\vec{w})^i = \alpha v^i + \beta w^i \ .
\end{align}
We read this relation as: the $i^\textnormal{th}$ component of the vector $(\alpha\vec{v}+\beta\vec{w})$ is equivalent to the number given by the sum of two rescaled vector components: $\alpha$ times $v^i$ and $\beta$ times $w^i$. The coefficients $\alpha$ and $\beta$ are any real numbers. In this example we used the index $i$ to show that this is true for \emph{any} vector space, not just the space for four-vectors. We call the $\mu$ index\sidenote{In our convention, lowercase letters from the middle of the Greek alphabet are Lorentz indices.} a \textbf{Lorentz index} because it indexes the four directions of spacetime.

\begin{example}
For example, this means that conservation of energy and momentum in an interaction
\begin{align}
    \sum_{i = \textnormal{incoming}} p_{(i)}^\mu -
    \sum_{i = \textnormal{outgoing}} p_{(i)}^\mu = 0
    % \sum_{i = \textnormal{external}} p_{(i)}^\mu = 0
    \label{eq:conservation:four:momentum}
\end{align}
where $p_{(i)}^\mu$ is the $\mu$ component of the four-momentum of the $i^\textnormal{th}$ particle in an interaction. By convention, incoming particles have positive signs and outgoing particles have negative signs.  Setting $\mu=0$ in \eqref{eq:conservation:four:momentum} tells us that the sum of all energies going into an interaction must match the sum of all energies coming out of the interaction. Similarly, setting $\mu=1$ tells us that momentum in the $x$-direction is conserved. 
\end{example}


Vectors with upper indices have equivalent names: column vectors, contravariant vectors, kets. To be very precise mathematically: the vector is the object $\vec{v}$, while $v^\mu$ is the $\mu^\textnormal{th}$ component of the vector. Physicists like to blur the line here and will write a \emph{generic component} of a vector $v^\mu$ to interchangeably mean the vector as a whole or the specific component.\footnote{Roger Penrose proposes formalizing this shorthand in what is called \emph{abstract index notation}. A good online discussion is this one: \url{https://math.stackexchange.com/questions/455478/}}\sidenote{What is implicit here is an understood set of basis vectors $\vec{e}_\mu$ such that $\vec{v} = v^\mu \vec{e}_{\mu}$. These basis vectors carry the abstract vector-ness of $\vec{v}$ while $v^\mu$ can be thought of as a set of numbers. Refer to my Physics 17 notes to see this exhaustively.}

\subsection{Lower Index}\label{sec:index:lower}

Upper index vectors also have lower-index counterparts. These also have many equivalent names: row vectors, covariant vectors, bras, one-forms. There is a mathematical machine called a \textbf{metric}\index{metric} that can raise or lower indices. For now let us assume that lower indexed objects exist. In fact, often momentum is written with a lower index:
\begin{align}
    p_\mu = (E, p_x, p_y, p_z) \ . 
    \label{eq:fourmomentum:lower}
\end{align}
As introduced, this as a separate object than the upper index four-momentum \eqref{eq:fourmomentum:upper}. However, the metric gives a concrete relation between the two:
\begin{align}
    p_\mu &\equiv (E, -p^x, -p^y, -p^z)
    &
    p^\mu &\equiv (E, -p_x, -p_y, -p_z) \ .
\end{align}
To go from upper to lower Lorentz index, evidently there is simply a minus sign on the spatial ($\mu=1,2,3$) components. 






\subsection{Summation Convention}

We adopt \textbf{summation convention}\index{summation convention} where:
\begin{newrule}[Summation convention]
In an expression where an upper and a lower index are written with the same character, it is \emph{understood} (left unwritten) that one should sum over these indices. We say that these indices are \textbf{contracted}\index{contract}.
\end{newrule}
The key example for us is the contraction of an upper-index four momentum and its lower-index counterpart:
\begin{align}
    p^\mu p_\mu = p_\mu p^\mu = E^2 - p_x^2 - p_y^2 - p_z^2 = E^2 - \vec{p}^2 \ .
\end{align}
Using this convention, the on shell condition \eqref{eq:on:shell} is\sidenote{Note that $p^2 = p_\mu p^\mu$ while $\vec{p}^2 = p_x^2 + p_y^2 + p_z^2$. }
\begin{align}
    p^2 \equiv p^\mu p_\mu = m^2 \ .
\end{align}
Contracted indices are effectively not indices: $p^2 = p^\mu p_\mu$ is a \emph{number} and not a four-vector or other type of tensorial object. 

Evidently the way we are writing our theory tells us that the unification of space and time (energy and momentum) is also a statement about the on shell condition for particles. 


The following examples are completely general for any type of linear transformation from a vector space to itself. 
\begin{example}
A linear transformation (``matrix'') $M\aij{i}{j}$ is a \emph{linear map} that takes vectors into vectors. For example, the transformation $M=M\aij{i}{j}$ acts on a vector $\vec{v} = v^i$ as $M\vec{v}$ with components given by
\begin{align}
    (M\vec{v})^i = \sum_k M\aij{i}{k}v^k = M\aij{i}{1}v^1 + M\aij{i}{2}v^2 + \cdots \ .
    \label{eq:matrix:on:vector:eg}
\end{align}
Observe that the matrix must have an upper index and a lower index. Summation convention tells us that the lower index allows the matrix to contract with the  index of the vector it acts on. The upper index of the matrix corresponds is `leftover' and is the free index of the resulting vector, $M\vec{v}$.
\end{example}


\begin{example}
In \eqref{eq:matrix:on:vector:eg} the index $k$ is contracted. We may rewrite this equation using summation convention as
\begin{align}
    (M\vec{v})^i = M\aij{i}{k}v^k \ .
\end{align}
\end{example}




\section{Lorentz Transformations}\label{sec:Lorentz:transformations}

How do you relate vector quantities between different reference frames? A particle may have some four momentum\sidenote{We write $p$ to mean the abstract four-vector without specifying its components. We skip the `physics notation' of writing $p^\mu$ for clarity.} $p$. The \emph{components} of $p$ depend on the reference frame of the observer. We measure the components to be $p^\mu = (p^0, p^1, p^2, p^3)$. Another observer in another reference frame measures components $p'^\mu=(p'^0, p'^1, p'^2, p'^3)$. These components are related by a \textbf{Lorentz transformation}\index{Lorentz transformation} \eqref{eq:Lorentz:2D:prime:to:unprimed}:
\begin{align}
    p^\mu = \Lambda\aij{\mu}{\nu}p'^\nu \ .
\end{align}
If we align the spatial parts of each observer's coordinate system so that their relative motion is in the $z$ direction, then the components of the Lorentz transformation are
\begin{align}
    \Lambda\aij{\mu}{\nu} =
    \begin{pmatrix}
        \gamma & & & \beta\gamma\\
        & 1 & &  \\
        & & 1 &  \\
        \beta\gamma &  &  & \gamma
    \end{pmatrix}
    \ . 
    \label{eq:Lorentz:in:z}
\end{align}
This is simply what we showed in \eqref{eq:Lorentz:2D:in:equations}, extended to the $4\times 4$ case. You should think about this as an analog of the rotation matrix in Euclidean space.\sidenote{The relation is as follows. Rotations are the isometries of Euclidean space: they are the transformations that preserve the dot product. Lorentz transformations are the isometries of Minkowski space: they are the transformations that preserve the metric. In both cases, the isometries are the allowed transformations that preserve the spacetime structure as encoded by the metric.} Here $\beta$ is the relative velocity between the two frames. 
\begin{exercise}
Check that \eqref{eq:Lorentz:in:z} is a transformation from frame $\mathcal O'$
 to frame $\mathcal O$, where $\mathcal O'$ is moving in the $+\hat{z}$ direction relative to the $\mathcal O$. Show that the inverse of $\Lambda$ simply swaps the sign of $\beta$. 
\end{exercise}
\begin{example}
A nice way to see the relation between Lorentz transformations and boosts is to note that we may write the boost parameter as \textbf{rapidity}\index{rapidity} $\eta$ defined through the identification:
\begin{align}
    \Lambda[\eta] = 
    \begin{pmatrix}
        \cosh \eta & \sinh \eta \\
        \sinh \eta & \cosh \eta
    \end{pmatrix}
    =
    \begin{pmatrix}
        \gamma & \beta\gamma \\
        \beta \gamma & \gamma
    \end{pmatrix} \ .
\end{align}
Compare this to a rotation matrix,
\begin{align}
    R(\theta) &=
    \begin{pmatrix}
        \phantom{+}\cos \theta & -\sin\theta \\
        \phantom{+}\sin \theta & \phantom{+}\cos\theta
    \end{pmatrix} \ .
    \label{eq:eg:rotations}
\end{align}
Observe the key relations:
\begin{align}
    \cosh^2 \eta - \sinh^2 \eta &= 1\\
    \cos^2 \theta + \sin^2 \theta &=1 \ .
\end{align}
Here we appreciate the critical minus sign that is the difference between space and time.\sidenotemark
\end{example}
\sidenotetext{The connection between Lorentz transformations and rotations is further explicit in the so called Pauli-metric formalism where the time-component of a four-vector is \emph{imaginary}. In that formalism the metric is proportional to the identity and both Lorentz transformations and rotations take the form \eqref{eq:eg:rotations}.}

What about the transformation of lower index objects, like $p_\mu$? We can motivate based on what we know physically. But first, it is useful to review the case of simple rotations:
% 
\begin{example}[Transformation of row vectors]\label{eg:row:vector:transform}
Consider a Euclidean three-vector $\vec{v} = (v^x, v^y, v^z)^\trans$ and a Euclidean row vector, $\row{w} = (w_x, w_y, w_z)$. You know that the contraction these two objects is a number that is \emph{invariant}.
\begin{align}
    \row{w}\vec{v} = w_xv^x + w_y v^y + w_z v^z .
\end{align}
In fact, if $\row{w} = \vec{w}^\trans$, then $\row{w}\vec{v}$ is simply the inner product $|\vec{w}||\vec{v}|\cos\theta$. At any rate, the contraction $w_i v^i$ carries no indices and is a pure scalar quantity. That means it does not transform under rotations. However, we know that $\vec{v}$ \emph{does transform under rotations},
\begin{align}
    \vec{v}&\to R(\theta)\vec{v} 
    \ ,
\end{align}
with $R(\theta)$ given in \eqref{eq:eg:rotations}.
That means $\row{w}$ should also transform in a way to compensate the $\vec{v}$ transformation and keep $\row{w}\vec{v}=w_iv^i$ constant. Call this transformation $S(\theta)$. By the rules of matrix multiplication, $S(\theta)$ must act from the right:
\begin{align}
    \row{w} \to \row{w}S(\theta) \ \,
\end{align}
but from the index perspective the order does not matter:
\begin{align}
    w_i \to w_i S(\theta)\aij{i}{j} =  S(\theta)\aij{i}{j} w_i \ .
    \label{eq:order:of:terms:in:summation}
\end{align}
This is because each term in the sums on the right-hand sides of \eqref{eq:order:of:terms:in:summation} are just multiplication of two numbers. \emph{Make sure you understand this.}

The statement that $\row{w}\vec{v}$ is constant under rotations is
\begin{align}
    \row{w}\vec{v} \to \row{w}S(\theta)R(\theta)\vec{v}
    = 
    R(\theta)\aij{i}{\ell} S(\theta)\aij{k}{i} w_k v^\ell
\end{align}
so that we requre:
\begin{align}
      R(\theta)\aij{i}{\ell} S(\theta)\aij{k}{i}
      =
      S(\theta)\aij{k}{i}R(\theta)\aij{i}{\ell}
      =
      \delta\aij{k}{l} \ ,
      \label{eq:SR:RS:inverses}
\end{align}
or in other words, as matrices, $S(\theta)R(\theta) = 1$. Note that while it turns out to also true that $R(\theta)S(\theta) = 1$, \eqref{eq:SR:RS:inverses} is \emph{only} telling us that $S(\theta)R(\theta) = 1$ because when we write this index contraction was a matrix multiplication, the order matters: we have to make sure contracted indices are consecutive.

We thus conclude that
\begin{align}
    S(\theta) = R(\theta)^{-1} = R(-\theta) = R(\theta)^\trans \ .
\end{align}
So we demonstrate something very important: row vectors like $\row{w}$ `rotate oppositely' from column vectors like $\vec{v}$.
\end{example}

The lesson from the above example is that lower indexed objects transform with the \emph{inverse transformation} as upper indexed objects. Thus if $p^\mu \to \Lambda\aij{\mu}{\nu}p^\nu$, we must have
\begin{align}
    p_\mu \to (\Lambda^{-1})\aij{\nu}{\mu} p^\nu\ .
\end{align}
Check to make sure that you agree with the position of the indices. It is $(\Lambda^{-1})\aij{\nu}{\mu}$, not $(\Lambda^{-1})_{\mu}^{\phantom{\mu}\nu}$. Refer back to Example~\ref{eg:row:vector:transform} if that is not clear.



\section{Example: Muon Decay}

Cosmic rays can produce muons when they hit the upper atmosphere about 10 kilometers above the surface of the Earth.\sidenote{This sub-section is copied from my Physics 17 (2023) notes and is adapted from an example in Griffiths.} These muons are highly relativistic, with a velocity of $\beta = 0.9999$. See Fig.~\ref{fig:muons}. We know from laboratory experiments that the lifetime of a muon \emph{at rest} is 2 microseconds. Based on the simple estimate $d=c\tau \approx 600$~meters, we would not expect any muons to reach the surface of the Earth. However, not only do large cosmic ray telescopes have dedicated muon detectors, but you can make your own citizen science muon detector\sidenote{\url{https://muonpi.org}}. What gives?
\begin{marginfigure}%[tb]
    \includegraphics[width=\textwidth]{figures/muon.pdf}
    \captionsetup{font={scriptsize,sf}}
    \caption{Very technical sketch of a muon produced in the upper atmosphere heading towards earth. \label{fig:muons}} 
\end{marginfigure}
Here are the facts:
\begin{itemize}
    \item Both the observer on Earth and the muon agree that their relative velocity is $|\beta| = 0.9999$. 
    \item The muon's lifetime is known in the muon's rest frame. 
    \item The distance from the surface of the Earth to the upper atmosphere is known in the Earth's rest frame. 
\end{itemize}
The Lorentz transformation between the muon frame and the observe frame mix up space and time separations. We can only express the distance or time that the muon travels by calculating in the same reference frame. 

% \begin{figure}[tb]
%     \centering
%     \includegraphics[width=.48\textwidth]{figures/rel_time_dil.pdf}
%     \quad
%     \includegraphics[width=.48\textwidth]{figures/rel_len_contractino.pdf}
%     \caption{Left: the muon's lifetime is time-dilated in the Earth's frame. Right: the distance from the surface of the Earth to the upper atmosphere is length contracted in the muon's frame. }
%     \label{fig:re:dilation}
% \end{figure}

First let us consider calculating everything in the Earth's reference frame. This is shown on the left of Fig.~\ref{fig:re:dilation}. This means we have to take the muon's lifetime in the muon's rest frame and convert it into a lifetime in the Earth's frame. In the muon's frame the lifetime is simply 
\begin{align}
    \Delta x'^\mu &= 
    \begin{pmatrix}
    \tau \\ 0     
    \end{pmatrix} \ 
    &
    \Delta x^\mu &=
    \begin{pmatrix}
    \gamma \tau \\ \gamma\beta \tau    
    \end{pmatrix} \ ,
\end{align}
where we have noticed that the muon lifetime is a displacement along the $t'$ axis used our results in \eqref{eq:Lorentz:2D:prime:to:unprimed}. We find that the lifetime in the Earth's frame is actually larger than the lifetime in the muon rest frame: $t = \gamma \tau$. There is also a spatial component, but this is no surprise: in the Earth frame the muon is moving, so when the muon decays it is in a different position. 

How much is the muon's lifetime \emph{time dilated}? We plug $\beta$ into the expression for $\gamma = (1-\beta^2)^{-1/2}$. We find\footnote{There's a cute trick here: $\beta^2 = (1-\epsilon)^2 \approx 1- 2\epsilon$ by Taylor expanding in the small number $\epsilon = 10^{-4}$.} that to one significant figure, $\gamma = 100$. This means that the time for the muon decay in the Earth's frame is $2\times 10^-4$~seconds, which means that it travels approximately $d=60~$km, which is larger than the distance from the upper atmosphere to the surface. As a sanity check: this is exactly the value in the spatial component of $\Delta x^\mu$.

Great: so one story is that relativistic muons have lifetimes that are much larger than their at-rest lifetime. This means that to the observer on earth, the muon simply lives longer than we would expect from measurements of muons at rest. There are, however, (at least) two sides to every good story. What does the muon see?

In the muon's rest frame, the muon \emph{knows} that it goes \emph{kaput} in 2~microseconds. It sees the surface of the Earth approaching it with velocity $\beta = 0.9999$. By now you can guess that must change: the measurement in the Earth's frame---that the height of the upper atmosphere is 10~km---must be different in the muon's frame. And in fact, the muon must measure the distance of the rapidly approaching Earth to be much smaller than 10~km. How does this \emph{length contraction} work? 

We show this on the right side of Fig.~\ref{fig:re:dilation}.
\begin{marginfigure}
\includegraphics[width=\textwidth]{figures/rel_len_contractino.pdf}
\captionsetup{font={scriptsize,sf}}
\caption{The distance from the surface of the Earth to the upper atmosphere is length contracted in the muon's frame.
    \label{fig:re:dilation}
}
\end{marginfigure}
Note that now we have a measurement in the Earth frame (a vertical line denoting a fixed distance) that we want to project onto the muon frame (red axes). In the Earth frame, we denote the distance by two unit ticks in the spatial direction. In the muon frame, this line intersects the $x'$ axis with \emph{less} than two ticks.

\begin{exercise}
Using the Lorentz transformation laws, show that the distance from the muon to the surface of the Earth at the moment of the muon's creation is $L'=L/\gamma$ where $L=10$~km is the distance in the Earth frame. 
\end{exercise}

\section{The metric tensor}

The \textbf{inner product} (or dot product) is a machine that takes two vectors and outputs a number. It is manifested by a tensor called the metric, which has two lower indices:
\begin{align}
    \langle p,q\rangle = p\cdot q = g_{\mu\nu}p^\mu q^\mu \ .
\end{align}
In special relativity the metric is conventionally written as $\eta_{\mu\nu}$ and has a simple form in Cartesian coordinates:
\begin{align}
    \eta_{\mu\nu} = 
    \begin{pmatrix}
        1 & & & \\
        & -1 & & \\
        & & -1 & \\
        & & & -1
    \end{pmatrix}
    = \textnormal{diag}(1,-1,-1,-1) \ .
\end{align}
Some physics tribes\sidenote{Particle physicists use the `West coast' or `mostly minus' notation. It is usually relativists and formal theorists who use the East coast/mostly plus convention. A third convention, the `Pauli convention' uses a metric proportional to the identity but with the timelike component imaginary $x^4 = ix^0$. In that notation, boosts look like complex rotations. See Appendix F of \emph{Diagrammatica}\footnotemark by Veltman for a discussion.}\footnotetext{\cite{Veltman:1994wz}} use a different convention, $\eta_{\mu\nu} = \text{diag}(-1,1,1,1)$. The choice of whether the spatial or temporal pieces pick up the minus sign is a convention---while the intermediate steps of any calculation differ by these annoying signs, any physical result is independent of the convention.\sidenote{I am hopelessly entrenched in the mostly minus tribe. If I were being honest, I think the mostly-plus metric is probably easier to start learn if you were starting from scratch. But I intend to run with team mostly-minus until I die.}


The metric has an inverse, $g^{\mu\nu}$ or $\eta^{\mu\nu}$ in special relativity. It has two upper indices and satisfies
\begin{align}
    g_{\mu\nu}g^{\mu\nu} = g^{\mu\nu}g_{\mu\nu} = \delta^\mu_\nu \ .
\end{align}
We do not bother writing $(g^{-1})^{\mu\nu}$ because the height of the indices indicates precisely whether you are using the metric or inverse metric. In special relativity, the components of $\eta_{\mu\nu}$ and $\eta^{\mu\nu}$ are identical. Also observe that the Kronecker-$\delta$ has no distinction between first and second indices:
\begin{align}
    \delta^\mu_\nu =
    \begin{cases}
    1 & \text{if } \mu = \nu \\
    0 & \text{otherwise} 
    \end{cases}
    \ .
\end{align}
The Kronecker-$\delta$ represents the components of the unit matrix, $\mathbbm{1}\aij{\mu}{\nu} = \delta^\mu_\nu$.


\section{Example: What does someone else measure?}
\label{sec:relativity:alien}


In special relativity there is an object called the four-velocity.\sidenote{This subsection borrows from my Physics 17 (2023) notes.} In our rest frame, our four velocity is
\begin{align}
    v^\mu = \begin{pmatrix}
        1\\ 0
    \end{pmatrix} \ .
    \label{eq:4:velocity:in:rest:Frame}
\end{align}
This literally means that when we are at rest, we are moving one second per second in the time direction. Objects moving relative to us have four velocities that are Lorentz transformations of the $v^\mu$ above. 

We notice that we can write the energy of a particle in a way that uses the inner product:
\begin{align}
    \langle v, p\rangle = p\cdot v = g_{\mu\nu} p^\mu v^\nu \ .
\end{align}
Of course, all this does is pick out the $p^0$ component, as we knew it had to. However, unlike writing $p^0$, the inner product $p\cdot v$ has no indices. It is a pure number and so it does not transform under Lorentz transformations. 

\begin{marginfigure}%[tb]
    \centering
    \includegraphics[width=\textwidth]{figures/alien.pdf}
    \captionsetup{font={scriptsize,sf}}
    \caption{You measure the four-momentum of a particle. What is the energy that an alien moving at some velocity $\beta$ relative to you measures?\label{fig:alien}}
\end{marginfigure}

At this point you wonder if we are simply reciting random facts that we have developed. Consider the following scenario illustrated in Fig.~\ref{fig:alien}.
%
% 
While you are measuring the particle energy $p^0 = E$, you notice an alien traveling relativistically with velocity $\beta$ relative to you. The alien has sophisticated equipment to measure the particle energy, and you know that the alien measures a different energy $E'$. How can you determine what the alien measures?

One way to do this is to calculate the full Lorentz transformation between your frame and the alien frame. That is tedious. It turns out that we can use the four-velocity as a useful trick. All objects with mass have a four-velocity equal to \eqref{eq:4:velocity:in:rest:Frame} in their rest frame. This means that the alien measures the particle to have energy $v_\text{alien}\cdot p_\text{alien}$, where the subscript `alien' means that these are all calculated in the alien's frame.

We now remember that $v_\text{alien}\cdot p_\text{alien}$ is a number. It does not matter what frame we calculate it in. Thus it is equivalent to the same dot product measured in our frame:
\begin{align}
E'=
    v_\text{alien}\cdot p_\text{alien} = v\cdot p \ ,
\end{align}
where the right-hand side is the alien four-velocity and the particle four-momentum as measured in our frame. The alien four-velocity is simply a Lorentz transformation of \eqref{eq:4:velocity:in:rest:Frame}. More practically, it is something that you can measure in your own frame. 


\begin{exercise}
Rephrase everything in this example in terms of the inner product in Minkowski space. Bonus if you use the word `projection.'
\end{exercise}






\section{Tensors: the meaning of indices}


The lightning-quick review of special relativity here is an example of tensor analysis in physics.\sidenote{Where can you learn more? I recommend my Physics 17 lecture notes. Want a more advanced version? Check out my Physics 231 lecture notes.} Tensors show up \emph{all over the place} in physics. Even in your lower division physics courses: did you ever wonder why it is called the moment of inertia \emph{tensor} and not the moment of inertia \emph{matrix}? Yes, there is a difference.\footnote{See e.g.\,\url{https://hepweb.ucsd.edu/ph110b/110b_notes/node24.html}}\sidenote{I am frustrated that few textbooks take a moment to explain the significance this difference.} For our purposes, we can think of a \textbf{tensor}\index{tensor} as an object that has an ordered number of indices. The indices each have a height, either upper or lower. 

The order of the indices matters; if you want it takes precedence over the height of the index: 
\begin{align}
    T^{ij\phantom{k}\ell}_{\phantom{ij}k} \neq
    T^{\phantom{k}ij\ell}_{k} \ .
\end{align}
If you have a metric, this is more clear since you can lower (or raise) all the indices, so that 
\begin{align}
    T^{ij\phantom{k}\ell}_{\phantom{ij}k} &= T^{ijm\ell}g_{mk}
    \\
    T^{\phantom{k}ij\ell}_{k}&=T^{mij\ell} g_{mk}
\end{align}
and you can see that $T^{mij\ell} \neq T^{ijm\ell}$.

There are some equivalent ways of thinking about tensors. The most formally correct way is to think about them as \emph{multilinear maps} between vector spaces (or tensor products\sidenote{Given a vector space $V$, a tensor product $V\otimes V$ is two copies of the vector space.} thereof). Perhaps more practically, a tensor is an object that encodes information that transforms according to the height of the indices. Generalizing our rules from Section~\ref{sec:Lorentz:transformations}:
% 
\begin{newrule}[Tensor transformation]\label{rule:tensor:transform}
If $T$ is a tensor with upper indices $i_1, \cdots, i_N$ and lower indices $j_1, \cdots, j_M$, then under a symmetry transformation $R(\theta)$, $T$ transforms as
\begin{align}
    T^{\cdots}_{\cdots} \to 
    R(\theta)^{i_1}_{\phantom{i_1} k_1} 
    \cdots 
    R(\theta)^{i_N}_{\phantom{i_N} k_N}
    (R(\theta)^{-1})^{\ell_1}_{\phantom{\ell_1}j_1} 
    \cdots 
    (R(\theta)^{-1})^{\ell_M}_{\phantom{\ell_M}j_M} T^{\cdots}_{\cdots} \ ,
\end{align}
where we have written $\cdots$ on the left hand side to mean `some arrangement of upper $i$ and lower $j$ indices,' while on the right the $\cdots$ mean `some arrangement of upper $k$ and lower $\ell$ indices.'

In other words:
\begin{itemize}
    \item For each upper index, multiply by a factor of $R(\theta)$ and contract with the lower index of $R(\theta)$.
    \item For each lower index, multiply by a factor of $R(\theta)^{-1}$ and contract with the upper index of $R(\theta)^{-1}$. Note that this is contraction with the \emph{first} index of $R(\theta)^{-1}$. 
\end{itemize}
\end{newrule}
To apply the rule for Lorentz transformations, simply replace $R$ with $\Lambda$ and convert the indices into $\mu$s and $\nu$s. 

We ultimately care about quantities that are \emph{invariant}\index{invariant} under Lorentz transformations. These are objects that everyone agrees upon, no matter what their reference frame. If you were to build a theory of nature, you would want the physical laws from that theory to be invariant with respect to reference frame---so the objects you would build that theory out of are naturally invariants. 





\subsection{Isometry}

How does one know that rotations are important symmetries in Euclidean space? This certainly comes from our own experience with physics---the laws of physics are rotationally invariant. In fact, we learn very quickly in our physics training to use rotational invariance to simplify problems. What about in special relativity? Historically, the Michelson--Morley non-observation\sidenote{Perhaps the most significant null result in science.} of aether---that is, the observation that the speed of light is constant---led us to realize that requirement that physics cannot depend on reference frame leads to a different class of symmetries. What characterizes these symmetries?

From a top-down perspective, rotations and their generalizations\sidenote{Such as Lorentz transformations in special relativity.} are \emph{isometries}. An \textbf{isometry} is a symmetry of \emph{the form of the metric}. Withour conventions, one of the laws of special relativity is that $\eta_{\mu\nu} = \text{diag}(+,-,-,-)$; this means that the metric takes this form in \emph{any} reference frame. This is 


... in light of Rule~\ref{rule:tensor:transform}

Now that we know how tensors transform and given that the metric $g_{\mu\nu}$ is a tensor, an isometry is a transformation $R$ such that
\begin{align}
    R\aij{\alpha}{\mu} R\aij{\beta}{\nu} g_{\alpha\beta} = g_{\mu\nu} \ .
\end{align}
All such symmetries preserve the inner product. This means that the scalar formed from $\row{w}\vec{v}$ is invariant under the transformation $R$.


\begin{exercise}[Isometries]
ddd
\end{exercise}

\begin{subappendices}

\section{Relativity by Thought Experiment}\label{sec:subappendix:relativity}
You can derive special relativity from the assumption that the speed of light is constant in any reference frame and then doing so called \emph{gedankenexperiments}.\sidenote{`Thought experiments' in German.} We continue our convention of using natural units where $c=1$, though it should be obvious that using any other units just throws in factors of $c$ all over the place.
\begin{exercise}
Rewrite all the equations in this appendix with the appropriate factors of $c$. Stop when it becomes obvious how to do this. 
\end{exercise}
I first saw this done in Chapter 15 of \emph{The Feynman Lectures on Physics}\footnote{\url{https://www.feynmanlectures.caltech.edu/I_15.html}}\sidenote{\emph{The Feynman Lectures on Physics} are beloved gems of freshman-level physics insight---but the consensus is largely that they are a bit too non-sequitur in style for physics students. In fact, you come to deeply enjoy the lectures only \emph{after} you already understand most of the material---then you can appreciate the little brilliant twists that Feynman makes compared to the usual pedagogy.} I refer you to that resource for a systematic derivation from the \emph{gedanken} approach. In this appendix, follow the the general idea and focus on a few subtle points that are not often explained carefully in the standard literature.\sidenote{I thank Matthew Lugatiman and Adam Green for talking through some of these subtleties with me.}

Just as the word \emph{gedankenexperiment} tells you where special relativity was developed, so too does the standard setting of the \emph{gedankenexperiment}: start by imagining a train moving with some velocity $v=\beta$ in the $x$ direction relative to our coordinate system. We are \emph{outside} the train. We are observers, $\mathcal O$ and our coordinate system is $(t,x)$. You can also imagine another observer, Oppie,\sidenote{This is \emph{not} a reference to Oppenheimer's nickname or a misspelling of Opie, Ron Howard's most famous character. Instead, it's a name that is reasonably close to $\mathcal O'$, ``oh-prime.''} who is \emph{in} the train and whose coordinate system carries primes: $(t',x')$. We say that Oppie is a \emph{comoving} observer with the train. We align our coordinate systems so that the origins coincide: 
\begin{align}
    (t=0,x=0) = (t'=0,x'=0) \ .
\end{align}
The above equation should be treated to mean \emph{the point that we call $(0,0)$ coincides with the point that Oppie calls $(0,0)$.} In this way, a generic point $(t,x)$ is really a \emph{separation} between that point and the origin.\sidenote{Recall our caveat in Chapter~\ref{sec:index:upper}: positions are not vectors, but differences in positions are vectors.}


\subsection{Time dilation}

First imagine that Oppie has a little gizmo that first emits a photon towards a mirror, then detects the reflected photon. See Fig.~\ref{fig:Feynman:photo:thing}
\begin{marginfigure}%[th]
    \includegraphics[width=.8\textwidth]{figures/FeynmanLec15_photodet.png}
    \captionsetup{font={scriptsize,sf}}
    \caption{From \emph{The Feynman Lectures on Physics}, Chapter 15.}
    \label{fig:Feynman:photo:thing}
\end{marginfigure}
The height of the gizmo is $D = \ell$, the height of the train. It is critical that the gizmo is aligned so that the photon moves \emph{perpendicular} to the direction of motion. We write $\ell$ for \emph{length} and to avoid ambiguities with [covariant] derivatives, $D$ mesons, and so forth. 

Like us, Oppie understands that the speed of light is $c=1$ and that this is true in any reference frame. At the origin ($t'=0$), Oppie turns ont he gizmo and measures the time $t'$ that it takes for the photon to traverse the distance $\ell$ and come back. 
\begin{align}
     t' = 2\ell/c = 2\ell \ .
     \label{eq:Feynman:train:updown}
\end{align}

What do we see? Like Oppie, we see the device turn on at the origin ($t=0$) and we see that the photon hits the roof of the train car and bounces back down. However, unlike Oppie, we also see the entire system move in direction of the train's motion. The trajectory is shown in Fig.~\ref{fig:Feynman:photo:thing:unprimed}.
\begin{figure}[ht]
\includegraphics[width=\textwidth]{FeynmanLec15_photodetside.png}
    \captionsetup{font={scriptsize,sf}}
    % \caption
    \sidecaption[][-7em]{Same as Fig.~\ref{fig:Feynman:photo:thing}, but as seen from observers who are not on the train. From \emph{The Feynman Lectures on Physics}, Chapter 15.
    \label{fig:Feynman:photo:thing:unprimed}
    }
\end{figure}
Because the motion of the train is perpendicular to the up-and-down direction, we assume that the height of the train is unchanged by relativistic effects: we measure this height to be $\ell$ just as Oppie does. We then measure that the photon takes times $t$ to hit the top of the train and return. This time is evenly split\sidenote{By symmetry.} between the upward-going time and downward-going time. During this time, the train has moved along the $x$ direction by an amount $\beta t$. From trigonometry, we thus have:
\begin{align}
    \left(\frac{t}{2}\right)^2
    &= 
    \left(\frac{\beta t}{2}\right)^2 + \ell^2
\end{align}
Plugging in Oppie's observation that that relates the height of the train to the time Oppie measures, \eqref{eq:Feynman:train:updown}, we have
\begin{align}
    (t')^2 = (1-\beta^2) t^2 =  \frac{t}{\gamma} \ .
\end{align}
That is to say, the time that we measure is related to the time that Oppie measures by
\begin{align}
    t = \gamma t' \ .
    \label{eq:time:dilation:derived}
\end{align}
Because $\gamma > 1$, we the time that we see is \emph{dilated} relative to what Oppie experiences. Because the gizmo is essentially an idealized clock, we say that observers see the events on the moving train moving  slower than they would expect by a factor $\gamma$. 




\subsection{Length contraction}

Having learned something about the passage of time, we can now figure out what motion does to the relative perception of space. To do this, let us do a second experiment where we turn the gizmo in Fig.~\ref{fig:Feynman:photo:thing} onto its side. Place the gizmo at the back of a train car and arrange it so that the photon first moves \emph{along the direction of the train's motion}, then reflects off of the mirror to go \emph{against the direction of the train for its return motion}. Let us now set the length of the gizmo to be the length of the train car: Ollie observes\sidenote{We write $\ell_0$ rather than $\ell'$ because Ollie is in the rest frame of the train. $\ell_0$ is called a \emph{proper length}, it is the length of an object to an observer for whom the object is not moving.} this to be $\ell_0$ while we observe it to be $\ell$. 

In pre-special relativity Galilean physics we would expect $\ell_0 = \ell$. However, the fact that $c=1$ is constant means that we cannot make this assumption. 
\begin{marginfigure}%[th]
    \includegraphics[width=\textwidth]{figures/spacetime_lengthcontraction.pdf}
    \captionsetup{font={scriptsize,sf}}
    \caption{The trajectory of the photon (dark blue) from the back of the train at $t=t'=0$ to the event $A$ then the event $B$ where it returns to the back of the train. Oppie's coordinate system is in red. \label{fig:spacetime:length:diagram}}
\end{marginfigure}
Points on a spacetime diagram are called \emph{events} because they are a place and a time. Figure~\ref{fig:spacetime:length:diagram} shows the experiment. Let the origin be the back of the train at time zero---where both we and Oppie synchronize our clocks. A photon is shot towards the end of the train. The two edge of the train correspond to the $t'$ axis and its parallel translation---this is because in Oppie's frame the train is not moving and so it stays at $x'=0$; similarly, the front of the strain stays at $x'=\ell_0$. 

The photon travels at the speed of light $c=1$, which is a 45$^\circ$ diagonal line on the way out, then a 135$^\circ$ line on the way back. The thought experiment is again simpler in Oppie's frame. Oppie measures that the total time for the back-and-forth journey is $t_2' = 2\ell'$. It is clear both from the thought experiment and the diagram that each leg of the journey takes the same amount of time $t_2' = 2t_1'$.

We see something a bit different. On the outbound journey the photon has to \emph{catch up} to the front train. If we could observe it, we would measure that it takes time $t_1$ for the photon to reach the mirror. After it reflects off the mirror at the front of the train, the photon and the back of the train are moving \emph{toward each other}. We observe that this total journey takes a time $t_2$. We also define $\Delta t_2 = t_2 - t_1$ to be just the time of the journey from the front of the train to the back again. Observe that $\Delta t_2 \neq t_1$; both logically and from Figure~\ref{fig:spacetime:length:diagram}. This means we have the relations:
\begin{align}
t_1 &= \ell + \beta t_1
&
\Delta t_2 &= \ell - \beta \Delta t_2 \ .
\end{align}
Here we recall that $\beta$ is the speed of the train and the different signs correspond to whether the train is moving with or against the photon. Since $t_1$ is already measured against the origin, there is no need to write $\Delta t_1 \equiv t_1 - 0 = t_1$. These give us the relations:
\begin{align}
    (1-\beta)t_1 &= \ell & (1+\beta)\Delta t_2 &= \ell
    \ .
\end{align}
The total time is then
\begin{align}
    t_2 = t_1 + \Delta t_2 = \frac{\left[(1 + \beta) + (1-\beta)\right]\ell}{1-\beta^2}
    = 2\gamma^2 \ell \ .
    \label{eq:gedanken:length:intermediate1}
\end{align}
\begin{exercise}
Prove \eqref{eq:gedanken:length:intermediate1}. It is worth doing.
\end{exercise}
Now we have to invoke time dilation in \eqref{eq:time:dilation:derived}. The total time for the round trip journey that we measure $t_2$ is related to the total time that Oppie measures $t_2'$ by
\begin{align}
    t_2 &= \gamma t_2'
    \\
    2\gamma^2 \ell &= 2\ell' 
    \\
    \ell = \frac{\ell'}{\gamma}
    \label{eq:length:contraction:derived}
    \ .
\end{align}
Because $\gamma > 1$, we find that what \emph{we} measure to be the length of the train is \emph{contracted} (smaller) relative to what Oppie measures in the comoving frame of the train.


\subsection{Confusion}

The lessons of this \emph{gedanken} appendix are simple. If the frame $\mathcal O'$ is moving relative to our frame, $\mathcal O$, then
\begin{itemize}
    \item From \eqref{eq:time:dilation:derived}: The time that we measure is \emph{dilated} (slower) compared to the time that is measured in $\mathcal O'$. 
    \item From \eqref{eq:length:contraction:derived}: Length along the direction of motion are \emph{contracted} (smaller) compared to the length along the direction of motion measured in $\mathcal O'$. 
\end{itemize}
Having established these, I leave it to you to explore some of the apparent paradoxes in special relativity such as the pole-in-barn paradox and the twin paradox. The spacetime diagrams that we draw are useful guides. As a hint, often the resolution to paradoxes is the observation that simultaneity is a frame-dependent notion.\sidenote{This has a manifestation for us: the locality of the fundamental interactions is a logical consequence of requiring causality in our theory. Interactions must happen at a single \emph{event} rather than over a finite separation in order for there to be a clear \emph{cause} that precedes an \emph{effect} in any valid reference frame.}

Thus far, everything we have discussed in this appendix is standard fare in a decent treatment of first-year modern physics. Let us focus on some of the conceptual hiccups that are not always explained carefully.

\paragraph{Could we derive length contraction without using time dilation?} You should feel unsatisfied. In relativity, space and time have equal footing. However, \emph{every} thought-experiment based derivation of special relativity starts by deriving time dilation and \emph{then} uses that result to derive length contraction. The reason for this asymmetry is that the time dilation thought experiment did not depend on the directions perpendicular to the train's motion: both the $\mathcal O$ and $\mathcal O'$ frame measured the height of the train to be $\ell$. On the other hand, the length contraction thought experiment had both spatial displacement $\ell$ \emph{and} a time displacement $t_2$ that needed to be measured in each reference frame. To say it differently: the time dilation experiment allowed us to ignore part of the spatial configuration. However, in the length contraction experiment you \emph{cannot} ignore the time separation because all experiments evolve in time.\sidenote{Philosophically: we perceive the universe as a sequence in time. We can imagine experiences where we are stationary in space, but we have no experiment---\emph{gedanken} or otherwise---where we are stationary in time.} Rest assured, the geometry \emph{does} respect the symmetry between space and time.

\paragraph{If they are so useful, why did we not draw a spacetime diagram for the time dilation experiment?} The time dilation experiment made use of a third dimension of spacetime, the height of the train. It is a bit of a pain to draw, and you still end up drawing the same right triangles in Fig.~\ref{fig:Feynman:photo:thing:unprimed}


\paragraph{Was it necessary for the photon to complete a full loop?} In these thought experiments, the the photon is emitted and detected by the same device: the trajectory is an `out and back' in runners parlance. For the time dilation experiment, it is obviously sufficient to consider only the trajectory from the origin to the ceiling. What about for the length contraction experiment? This is also possible. 
\begin{exercise}
Derive time dilation using the same thought experiment, but without the `return journey' to the back of the train. 
\end{exercise}
That this is possible is obvious for those with experience with relativity. However, it is useful pedagogically to have the photon perform a round trip journey because this way all observations are performed by the same observer. I can say that \emph{Oppie} emits a photon and \emph{Oppie} observes its return. Then we can identify the event where we observe Oppie emitting a photon and the event where we observe Oppie observing the photon.\sidenote{Given the subtleties of spacetime separated events with regard to simultaneity, I can appreciate this pedagogical choice.}

\paragraph{I tried calculating this using Lorentz transformations and I got stuck.} Here is a common error. Suppose we know that Oppie measures the train car to have length $\ell_0$ and that Oppie measures this at some time slice $t'=0$. Then we can perform a Lorentz transformation:
\begin{align}
    \begin{pmatrix}
        t\\
        \ell
    \end{pmatrix}
    =
    \begin{pmatrix}
        \gamma &\gamma\beta\\
        \gamma \beta & \gamma
    \end{pmatrix}
    \begin{pmatrix}
        0\\
        \ell_0
    \end{pmatrix}
    = 
    \begin{pmatrix}
        \gamma\beta\ell_0
        \gamma \ell_0
    \end{pmatrix} \ .
\end{align}
From this we believe that $\ell = \gamma \ell_0$, i.e.\ length is \emph{also} dilated---which is \emph{incorrect}! What went wrong here? Recall that the \emph{event} that we are using to measure the length of the train is a photon hitting the back of the train. That is labeled event $A$ in Fig.~\ref{fig:spacetime:length:diagram}. This occurs on the light cone where $t=x$ (and also $t'=x'$). That means that we need to Lorentz transform the separation between the \emph{event} $(t_1'=\ell_0, x'=\ell_0)$. This gives
\begin{align}
    \begin{pmatrix}
        t_1\\
        \ell
    \end{pmatrix}
    =
    \begin{pmatrix}
        \gamma &\gamma\beta\\
        \gamma \beta & \gamma
    \end{pmatrix}
    \begin{pmatrix}
        \ell_0\\
        \ell_0
    \end{pmatrix}
    = 
    \begin{pmatrix}
        \gamma(1+\beta)\ell_0\\
        \gamma(1+\beta)\ell_0
    \end{pmatrix} 
    \ .
\end{align}
We can use the first component and our time dilation result to find:
\begin{align}
    t_1 \equiv \ell &= \gamma (1+\beta)(1-\beta) \ell' 
    \\ &= \frac{\ell'}{\gamma}
    \ .
\end{align}
We have used the definition that $\gamma = (1-\beta^2)^{-1}$. 
From this we indeed confirm $\ell = \ell'/\gamma$ and that length is \emph{contracted}. 




\section{More examples in relativity}

\subsection{%Example: 
The electromagnetic field strength}
% motivate this from the unification of magnetism and electricity
% transformation laws

\begin{figure}[tb]
    \centering
    \includegraphics[width=\textwidth]{figures/EMcurrent.pdf}
    \caption{\textsc{Left}: an electron moves near a current. The current has no net electric charge. In the absence of magnetism, we expect the electron to move in a straight line. \textsc{Right}: if we boost into the electron frame, the particles in the current moving in the opposite direction are length-contracted. This means that the charge density increases. The stationary electron now feels a net electric force. This implies that something is missing in the picture on the left.}
    \label{fig:current}
\end{figure}

Another place where special relativity rears its head is in electrodynamics. Electricity and magnetism are two manifestations of the same electromagnetic phenomenon.\sidenote{Unification of apparently unrelated forces is a big theme of this course. Electromagnetism is the example that you already know.} This is illustrated in Fig.~\ref{fig:current}. If you did not know about magnetism, you would find a paradox when you consider a charged particle moving along a current. In one frame, the current is an equal number of positive and negative charges moving in opposite directions.\sidenote{I suppose more realistically the negative charges move while the positive charges stay put---that does not change the conclusion.} If you boost to the external charged particle's rest frame, length contraction forces one species of the current particles to increase their charge density relative to the other species. This creates a net electric field that acts on the stationary external particle. Without magnetism, the first frame is missing this additional force. 

The electric and magnetic fields are unified in the \emph{electromagnetic field strength}, which is a two-index tensor:
\begin{align}
    F^{\mu\nu}
    &=
    \begin{pmatrix}
        0&-E^x&-E^y&-E^z\\
        E^x&0&-B^z&B^y\\
        E^y&B^z&0&-B_x\\
        E^z&-B^y&B^x&0
    \end{pmatrix} %\ .
    &
    F_{\mu\nu}
    &=
    \begin{pmatrix}
        0&E^x&E^y&E^z\\
        -E^x&0&-B^z&B^y\\
        -E^y&B^z&0&-B_x\\
        -E^z&-B^y&B^x&0
    \end{pmatrix} \ .
\end{align}
We see that electricity and magnetism are unified in that their components mix into one another under a Lorentz transformation. 
\begin{exercise}
Confirm that $F_{\mu\nu} =g_{\mu \alpha}g_{\nu\beta} F^{\alpha\beta}$ with the (3+1)-dimensional Minkowski metric $g_{\mu\nu}$. 
\end{exercise}
\begin{exercise}
Find the components of $F'^{\mu\nu}$ under a boost along the $z$-direction. 
\end{exercise}


\subsection{%Example: 
Simultaneity}
\label{eq:simultaneity}

One of the key ideas in special relativity is that we sacrifice our notion of simultaneity for objects that are not observed at the same spacetime point. We may reuse our diagram in Fig.~\ref{fig:re:dilation}. Consider two different points on the $x'$ axis. These are simultaneous with respect to the primed observer: they both occur at $t'=9$. However, these two points  obviously do \emph{not} have the same $t$ coordinate to the unprimed observer. This observation helps clear up several apparent paradoxes that may show up in relativity. More importantly, it completely upends our notion of causality.

One of the unwritten-but-understood laws of physics is that the cause precedes the effect. I have to drop my mug before I hear the sound of the ceramic shattering. This notion is imperiled if in some other reference frame someone else would have heard the shattering before they observe the mug being dropped. One deduction of this is that the laws of physics should be \emph{local} in spacetime. A consequence of this observation is that the laws of physics should be written with derivatives.


\subsection{%Example: 
Discrete isometries}

Isometries are symmetries of the metric.
% 
The Minkowski metric has a parity isometry that acts as a discrete symmetry. In matrix form the action of parity is a Lorentz transformation
\begin{align}
    P = \begin{pmatrix}
        1 & & &\\
         & -1& &\\
         & & -1 &\\
         & & & -1
    \end{pmatrix}\ .
\end{align}
This symmetry is \emph{discrete} in contrast to continuous symmetries. Rotations are a continuous symmetry because you can rotate by any real number amount, $\theta$. They parameterize an infinite number of Lorentz transformations. Discrete symmetries, on the other hand, represent a countable number of Lorentz transformation. In fact, because $P^2 = \mathbbm{1}$, there is only one such Lorentz transformation. 

There is a second discrete transformation called \textbf{time reversal}:
\begin{align}
    T = 
    \begin{pmatrix}
        -1 & & &\\
        & 1 & &\\
        &  & 1 &\\
        &  & & 1
    \end{pmatrix} \ .
\end{align}
This one sounds rather dramatic, doesn't it?\sidenote{One of my mentors in graduate school once told the story that he was preparing a lecture on particle physics at the pub. When his friends asked him what the topic of the lecture would be, he said ``time reversal.'' The bar crowd suddenly grew silent until the bartender quietly asked: ``... we can do that?''} It should be clear that $T$ indeed reverses the direction of time. This, however, does not mean that time reversal is something we can do.\sidenote{Time reversal is a major part of \emph{The Legend of Zelda: Tears of the Kingdom}. Before this, there was the ground-breaking independent computer game \emph{Braid} that pioneered this mechanic. The latter has an additional connection to physics in that the story is largely understood to be a parable about the development of atomic weapons.} Our understanding of causality breaks if we allow time reversal. However, mathematically time reversal is a clear isometry of the Minkowski metric. 

In fact, there is something `deep' to say that the classical laws of physics are time reversal invariant. If you run a video backwards, everything that happens obeys the laws of physics. The sign of the gravitational force may swap, but the dynamics of such an ``anti-gravity'' force law follows Newtonian mechanics. Entropy may decrease rather than increase, but there is no sense in which the microscopic transition from one configuration to the next would violate any laws of microphysics.\sidenote{This is to say that the ``arrow of time'' from statistical mechanics is not a statement about microscopic interactions nor is it a statement about what is not \emph{possible}, only about what is increasingly \emph{improbable}.} Though, to be fair, we also do not know how to take a right-handed person and do a parity transformation on them to turn them left-handed. 


In order to restrict to sensible isometries, we say that valid observers in special relativity are those that are related by isometries that are \emph{connected to the identity}. This means that one may write the isometry with respect to a continuous parameter and that for some value of that parameter, the isometry is simply the identity matrix. In this way, we restrict our physical isometries to those that maintain the direction of time. 

There is one more discrete symmetry that is often mentioned along with parity and time reversal: charge inversion. Unlike the other two, charge inversion is \emph{not} a spacetime symmetry since it acts only on particles (fields). Charge inversion takes every particle and flips their charges. For now you may think about flipping the \emph{electric} charge of the particle---but this actually holds for all of the types of charges that we examine in this course.\sidenote{Charges are conserved quantities. Remember that conserved quantities come from symmetries of the action. Unlike the spacetime symmetries of this chapter, those charges are related to \emph{internal} symmetries.} There are two combinations of these discrete symmetries that are notable:
\begin{itemize}
    \item The combination $CP$ (charge--parity) is the transformation that takes a particle to its anti-particle.
    \item The combination $CPT \equiv \mathbbm{1}$. That is: if we perform all three discrete symmetries, we return to the same state.\sidenote{I leave this here with no proof. I know such proofs exist, but they are largely in the domain of a construction called axiomatic quantum field theory, which I know nothing about. You can learn more about this in\footnotemark}\footnotetext{\cite{Blum:2022eol}}
\end{itemize}
Because these are all parities---in the sense that $C^2 = P^2 = T^2 = \mathbbm{1}$---we see an relation between the antimatter transformation $CP$ and the idea of moving backward in time. You may want to remember then when our Feynman diagram notation makes it \emph{look like} antiparticles are particles moving backward in time.\sidenote{To be clear, this is \emph{not} what is happening.}


\section{Bird's eye view of tensors}

The reason why we make a big deal about tensors and the `indexology' view of particle physics is that this perspective is particularly helpful in physics. Table~\ref{table:vectors:conventions}, borrowed from my Physics 17 lecture notes, gives a hint of this. Column and row vectors have a few equivalent names:
\begin{itemize}
    \item Upper index: [column] vector, contravariant vector, ket,
    \item Lower index: row/dual/covariant vector, covector, bra, one-form \ .
\end{itemize}
These are all fancy names for the \emph{same} idea. A row vector\sidenote{Here we stick to the simplest-sounding name.} $\row{w}$ is a \emph{linear function}\index{linear} on vectors to numbers. This means that given two vectors $\vec{v}$ and $\vec{u}$ and two numbers $\alpha$ and $\beta$:
\begin{align}
    \row{w}\left(\alpha\vec{v}+\beta\vec{u}\right)
    &=
    \alpha\row{w}(\vec{v}) + \beta\row{w}(\vec{u}) \ .
\end{align}
\begin{example}
To make it clear that this really is a simple statement, let us try it out for a two-dimensional real vector space in matrix notation:
\begin{align}
    \begin{pmatrix}
        w_1 & w_2
    \end{pmatrix}
    \left(
    \alpha
    \begin{pmatrix}
        v^1\\ v^2
    \end{pmatrix}
    + 
    \beta
    \begin{pmatrix}
        u^1 \\ u^2
    \end{pmatrix}
    \right)
    =
    \alpha(w_1v^1 + w_2v^2)
    + \beta(w_1u^1 + w_2u^2) \ .
\end{align}
\end{example}
\begin{example}
Here is an even sillier example in a \emph{one}-dimensional real vector space, $\mathbbm{R}$. In this case, vectors are just numbers $v^1 = x$. Row vectors are linear functions, $f$ characterized by one component, $a$. They satisfy:
\begin{align}
    f(\alpha x + \beta y) = \alpha x + \beta y \ .
\end{align}
Even though $\alpha$, $\beta$, $x$, and $y$ are practically all numbers, we should recognize that $x$ and $y$ are `vectors' while $\alpha$ and $\beta$ are `numbers' in the sense of rescaling. 
\end{example}
\begin{exercise}
By our definition of linear, show that the general equation for a line in the Cartesian plane, $f(x)=ax+b$ is \emph{not} linear.
\end{exercise}

Of course, you can equivalently think about $\vec{v}$ acting on $\row{w}$,
\begin{align}
    \vec{v}(\row{w}) \defeq v^iw_i = w_iv^i = \row{w}(\vec{v}) \ .
\end{align}
Here we see why it helps to think about indices rather than matrices as arrays of numbers that have some multiplication rule. Given a column and a row vector, there is one obvious way to form a number. If you treat one of the objects as a `function' and the other object as an `argument,' then the function is linear in the argument. In this sense, we say that the column and row vectors are \emph{dual} to one another. They encode the same structure relative to each other.\sidenote{This notion of duality is completely independent of physical dualities or parity symmetries of physical systems. However, it is true that if a particle has \emph{internal} symmetries that are described by, say, upper indices, then its antiparticle has these indices lowered.}

The bras and kets of quantum mechanics are also simply column and row vectors. This is obvious for simple finite-dimensional systems, like the spin states of an electron. After all, did we not write spinors as columns of two numbers?\sidenote{They were kind of weird because they obviously were not vectors in Euclidean two dimensional space---but they \emph{are} vectors in a different space. See Appendix~\ref{sec:Poincare:Algebra} for a discussion---note: that appendix is significantly more advanced than most of this course.} There are also systems with countably-infinite dimensions, like the hydrogen atom. There we wrote our states as eigenvectors of energy and angular momentum, $\ket{E,\ell,m}$, where these \emph{quantum numbers} take discrete-but-unbounded values. You will recall that these states also have bras  $\bra{E', \ell', m'}$ whose wavefunctions are related by a complex conjuate to the associated ket. There are also uncountably infinite quantum systems\sidenote{You may object that plane waves are not normalizable states.} like plane waves where a `quantum'-number like the wave momentum can take on any value, $e^{i\vec{p}\cdot\vec{x}}$ where the `infiniteness' of the vector space means that it does not make sense to use a discrete index for the components---instead, the components are part of a continuum. As a taste for how these all come together, present Table~\ref{table:vectors:conventions} reproduced from my Physics 17 course. 


\begin{table*}
    \renewcommand{\arraystretch}{1.3} % spacing between rows
    % \centering
    \begin{tabular}{ @{} llll @{} } \toprule % @{} removes space
        Vector Space & $\RR$ & $\CC$ & $\infty$-dimensional
        \\ \hline
        Vector/ket 
            & $\vec{v} = \ket{v}$ 
            & $\vec{v} = \ket{v}$
            & $f$
            \\
        Basis vector
            & $\bas{e}_i = \ket{i}$ 
            & $\bas{e}_i = \ket{i}$ 
            & $\hat{e}_i(x)$
            \\
            & 
            & 
            & $\hat{e}_p(x)$
            \\
        Components
            & $v^i \in \RR$
            & $v^i \in \CC$
            & $f^i, \tilde{f}(p) \in \CC$
            \\
        % Components
            & $\vec{v} = v^i\bas{e}_i = v^i\ket{i}$
            & $\vec{v} = v^i\bas{e}_i = v^i\ket{i}$
            & $f(x) = f^i\, \hat{e}_i(x) $
            \\
            & 
            & 
            & $f(x) = \int \dbar p\,\tilde f(p) e_p(x)$
        \\
        Row vector/bra
            & $\row{w} = w_i\rbas{e}^i = w_i\bra{i}$
            & $\row{w} = w_i\rbas{e}^i = w_i\bra{i}$
            & distribution, e.g.~$\delta(x)$
        \\
        Matrix
            & $A = A\aij{i}{j}\ket{i}\bra{j}$
            & $A = A\aij{i}{j}\ket{i}\bra{j}$
            & operator, e.g.~$\frac{d^2}{dx^2}$
        \\
        Inner Product
            & $\la v, w \ra = g_{ij}v^iw^j$
            & $\la v, w \ra$
            & $\la f, g \ra = \int dx\, f^*(x)g(x)$        
            \\
        % Inner Product
            & $\la v, w \ra = \la w,v\ra$
            & $\la v, w \ra = \la w,v\ra^*$
            & $\la f, g \ra = \la g,f\ra^*$
        \\
        Adjoint
            & Transpose
            & Hermitian Conjugate
            & Integration by parts
        \\
        % Adjoint
            & $(A^T)\aij{i}{j} = g_{jk}A\aij{k}{\ell}g^{\ell i}$
            & $(A^\dag)\aij{i}{j}= [(A^T)\aij{i}{j}]^*$
            & e.g.~$\left(\frac{d}{dx}\right)^\dag = -\left(\frac{d}{dx}\right)$
        \\
        Self-adjoint
            & Symmetric
            & Hermitian
            & Sturm--Liouville
        \\
        % Self-adjoint
            & $A^T = A$
            & $A^\dag = A$
            & $\mathcal O^\dag = \mathcal O$
        \\
        % Self-adjoint
            & $\RR$ Eigenvalues
            & $\RR$ Eigenvalues
            & $\RR$ Eigenvalues
        \\
        % Self-adjoint
            & $\perp$ Eigenvectors
            & $\perp$ Eigenvectors
            & $\perp$ Eigenvectors
        \\
        Isometry, e.g.
            & Rotations, Boosts
            & Unitary Matrices
            & Change of variable
        \\ \bottomrule
    \end{tabular}
    \caption{
        Terms and notation in real, complex, and infinite-dimensional vector spaces. From my Physics 17 notes.
        \label{table:vectors:conventions}
  }
\end{table*}



\end{subappendices}













\chapter{Closing Thoughts}




\section*{Acknowledgments}

\acro{PT}\ thanks 
all the people who taught him quantum field theory and particle physics over the years. In particular, courses from Scott Thomas, Pat Burchat, Savas Dimopoulos, Aaron Roodman, Michael Peskin, Shamit Kachru, David Tong, Maciej Dunajski, Ben Allanach, Hugh Osborn, Fernando Quevedo, Silvia Pascoli, Csaba Cs\'aki, Maxim Perelstein, and Yuval Grossman. I am further indebted to those who were (and are still) on this journey to figure this all out---those are too many to list explicitly, but I especially thank my postdoctoral mentors Tim Tait and Jonathan Feng, and everyone who has ever shared an office or done problem sets with me. My approach to writing and pedagogy is inspired by the writing of Sidney Coleman, Anthony Zee, David Tong, and Matthew Strassler---the physicists who you read if they have ever written anything vaguely related to whatever it is you are trying to learn.
%
% \acro{PT} thanks 
%     the Aspen Center for Physics (\acro{NSF} grant \acro{\#1066293})
%     % and the Kavli Institute for Theoretical Physics (\acro{NSF} grant \acro{PHY-1748958})`'
%     for 
%     its 
%     % their
%     hospitality during a period where part of this work was completed. 
% %
% \acro{PT} is supported by the \acro{DOE} grant \acro{DE-SC}/0008541.
\acro{PT} is supported by a \acro{NSF CAREER} award (\#2045333).

%% Appendices
\appendix
% \chapter{Proper appendix}
% index that follows this chapter.

% \section{Things to work on}

% It may be nice to incorporate something like \texttt{classicthesis}\footnote{\url{https://www.ctan.org/tex-archive/macros/latex/contrib/classicthesis/}}

\chapter{Notation and Conventions}

\section{Spacetime Conventions}
\label{app:spacetime:conventions}


\acro{4D} Minkowski indices are written with lower-case Greek letters from the middle of the alphabet, $\mu, \nu, \cdots$. \acro{5D} indices are written in capital Roman letters from the middle of the alphabet, $M, N, \cdots$. Tangent space indices are written in lower-case Roman letters from the beginning of the alphabet, $a,b, \cdots$. Flavor indices are written in lower-case Roman letters near the beginning of the alphabet, $i,j,\cdots$.

% We use the particle physics (`West Coast,' mostly-minus) metric for Minkowski space, $(+,-,-,-)$. We will also use the conformally flat AdS$_5$ metric,
% \begin{align}
%   ds^2= \left(\frac{R}{z}\right)^2 \left(\eta_{\mu\nu}dx^\mu dx^\nu - dz^2\right).
% \end{align} 
Dirac spinors $\Psi$ are related to left- and right-chiral Weyl spinors ($\chi, \bar\psi$ respectively) via
\begin{align}
    \Psi = \begin{pmatrix}
        \chi \\
        \bar\psi
    \end{pmatrix}.
\end{align}
Note that sometimes we will write $\Psi=(\psi,\bar\chi)^T$. The point is that un-barred Weyl spinors are---by convention---left-handed while barred spinors are right-handed. 
Our convention for $\sigma^0$ and the three Pauli matrices $\vec\sigma$ is
\begin{align}
    \sigma^0 = 
    \begin{pmatrix}
        1 & 0\\
        0 & 1
    \end{pmatrix}
    \quad
    \sigma^1 = 
    \begin{pmatrix}
        0 & 1\\
        1 & 0
    \end{pmatrix}
    \quad
    \sigma^2 = 
    \begin{pmatrix}
        0 & -i\\
        i & 0
    \end{pmatrix}
    \quad
    \sigma^3 = 
    \begin{pmatrix}
        1 & 0\\
        0 & -1
    \end{pmatrix}
\end{align}
with the flat-space $\gamma$ matrices given by
\begin{align}
    \gamma^\mu =
    \begin{pmatrix}
        0 & \sigma^\mu \\
        \bar\sigma^\mu & 0 
    \end{pmatrix}
    \quad\quad\quad\quad
    \gamma^5=
    \begin{pmatrix}
        i\mathbbm{1} & 0 \\
        0 & -i\mathbbm{1}
    \end{pmatrix},
\end{align}
where $\bar\sigma^\mu = (\sigma^0, -\vec\sigma)$.
This convention for $\gamma^5$ gives us the correct Clifford Algebra. (Note that this differs from the definition of $\gamma^5$ in Peskin \& Schroeder.)

\input{APP_PoincareGroup}


\printindex

%% Bibliography
%% USING BIBLATEX, SKIP BIBTEX
%% Use inspireHEP bibtex entries when possible
% \bibliographystyle{utcaps} 	% arXiv hyperlinks, preserves caps in title
% \bibliography{bib title without .bib}


\end{document}